[2022-04-11 02:50:41.126] corpus.train_file_list: 2
[2022-04-11 02:50:41.126]         ../data/sample_500k/cbt_train.txt
[2022-04-11 02:50:41.126]         ../data/sample_500k/adolescent_train.txt
[2022-04-11 02:50:41.126] corpus.valid_file_list: 2
[2022-04-11 02:50:41.126]         ../data/sample_500k/cbt_valid.txt
[2022-04-11 02:50:41.126]         ../data/sample_500k/adolescent_valid.txt
[2022-04-11 02:50:41.126] corpus.test_file_list: 3
[2022-04-11 02:50:41.127]         ../data/sample_500k/adult_test.txt
[2022-04-11 02:50:41.127]         ../data/sample_500k/adolescent_valid.txt
[2022-04-11 02:50:41.127]         ../data/sample_500k/cbt_valid.txt
[2022-04-11 02:50:41.127] corpus.subword_vocab_size: 1000
[2022-04-11 02:50:41.127] corpus.subword_model.train(4 files)...
[2022-04-11 02:50:41.127]         ../data/sample_500k/cbt_train.txt
[2022-04-11 02:50:41.127]         ../data/sample_500k/adolescent_train.txt
[2022-04-11 02:50:41.127]         ../data/sample_500k/cbt_valid.txt
[2022-04-11 02:50:41.127]         ../data/sample_500k/adolescent_valid.txt
[2022-04-11 02:50:41.820] corpus.subword_model.train(4 files)...Done
[2022-04-11 02:50:41.820] corpus tokenize...
[2022-04-11 02:50:43.939]         train tokens: 744541  ../data/sample_500k/cbt_train.txt
[2022-04-11 02:50:47.120]         train tokens: 851519  ../data/sample_500k/adolescent_train.txt
[2022-04-11 02:50:47.572]         valid tokens: 164419  ../data/sample_500k/cbt_valid.txt
[2022-04-11 02:50:48.273]         valid tokens: 197155  ../data/sample_500k/adolescent_valid.txt
[2022-04-11 02:50:50.587]         test  tokens: 1103609  ../data/sample_500k/adult_test.txt
[2022-04-11 02:50:51.277]         test  tokens: 197155  ../data/sample_500k/adolescent_valid.txt
[2022-04-11 02:50:51.721]         test  tokens: 164419  ../data/sample_500k/cbt_valid.txt
[2022-04-11 02:50:51.722] corpus.ntokens      : 996
[2022-04-11 02:50:51.722] corpus.char_count   : 120
[2022-04-11 02:50:51.722] corpus.char_cnt_dict: 120
[2022-04-11 02:50:51.722] corpus.char_id_dict : 120
[2022-04-11 02:50:51.753] corpus.batchify(2 files, batch_size=20)...
[2022-04-11 02:50:51.753]         tokens_all: 1596060
[2022-04-11 02:50:51.753]         batched   :  79803
[2022-04-11 02:50:51.753]         ../data/sample_500k/cbt_train.txt
[2022-04-11 02:50:51.753]         ../data/sample_500k/adolescent_train.txt
[2022-04-11 02:50:51.761] corpus.batchify(2 files, batch_size=20)...
[2022-04-11 02:50:51.762]         tokens_all: 361574
[2022-04-11 02:50:51.762]         batched   :  18078
[2022-04-11 02:50:51.762]         ../data/sample_500k/cbt_valid.txt
[2022-04-11 02:50:51.762]         ../data/sample_500k/adolescent_valid.txt
[2022-04-11 02:50:51.774] corpus.batchify(1 files, batch_size=20)...
[2022-04-11 02:50:51.774]         tokens_all: 1103609
[2022-04-11 02:50:51.774]         batched   :  55180
[2022-04-11 02:50:51.774]         ../data/sample_500k/adult_test.txt
[2022-04-11 02:50:51.779] corpus.batchify(1 files, batch_size=20)...
[2022-04-11 02:50:51.779]         tokens_all: 197155
[2022-04-11 02:50:51.779]         batched   :   9857
[2022-04-11 02:50:51.779]         ../data/sample_500k/adolescent_valid.txt
[2022-04-11 02:50:51.783] corpus.batchify(1 files, batch_size=20)...
[2022-04-11 02:50:51.783]         tokens_all: 164419
[2022-04-11 02:50:51.783]         batched   :   8220
[2022-04-11 02:50:51.783]         ../data/sample_500k/cbt_valid.txt
[2022-04-11 02:50:51.796] RNNModel.rnn_type: LSTM
[2022-04-11 02:50:51.796] RNNModel.ntoken  : 996
[2022-04-11 02:50:51.797] RNNModel.ninp    : 200
[2022-04-11 02:50:51.797] RNNModel.nhid    : 200
[2022-04-11 02:50:51.797] RNNModel.nlayers : 2
[2022-04-11 02:50:51.797] RNNModel.dropout : 0.2
[2022-04-11 02:50:51.797] RNNModel.tie_weights: False
[2022-04-11 02:50:51.797] RNNModel.char_mode  : 
[2022-04-11 02:50:51.797] RNNModel.char_cnt   : 121
[2022-04-11 02:50:51.797] RNNModel.char_emsize: 25
[2022-04-11 02:50:51.797] RNNModel.char_nhid  : 200
[2022-04-11 02:50:51.797] RNNModel will not use char-encoding
[2022-04-11 02:50:51.799] Epoch 001/40 ==================================================
[2022-04-11 02:50:55.381] E001 |   200/2280 batches | lr 20.0000 | loss  5.874 | ppl    355.71
[2022-04-11 02:50:58.884] E001 |   400/2280 batches | lr 20.0000 | loss  5.455 | ppl    233.86
[2022-04-11 02:51:02.425] E001 |   600/2280 batches | lr 20.0000 | loss  5.009 | ppl    149.71
[2022-04-11 02:51:05.968] E001 |   800/2280 batches | lr 20.0000 | loss  4.729 | ppl    113.13
[2022-04-11 02:51:09.513] E001 |  1000/2280 batches | lr 20.0000 | loss  4.596 | ppl     99.09
[2022-04-11 02:51:13.034] E001 |  1200/2280 batches | lr 20.0000 | loss  4.422 | ppl     83.29
[2022-04-11 02:51:16.563] E001 |  1400/2280 batches | lr 20.0000 | loss  4.350 | ppl     77.45
[2022-04-11 02:51:20.105] E001 |  1600/2280 batches | lr 20.0000 | loss  4.217 | ppl     67.86
[2022-04-11 02:51:23.657] E001 |  1800/2280 batches | lr 20.0000 | loss  4.135 | ppl     62.46
[2022-04-11 02:51:27.174] E001 |  2000/2280 batches | lr 20.0000 | loss  4.116 | ppl     61.30
[2022-04-11 02:51:30.704] E001 |  2200/2280 batches | lr 20.0000 | loss  4.032 | ppl     56.35
[2022-04-11 02:51:32.101] E001 |  2280/2280 batches | lr 20.0000 | loss  4.015 | ppl     55.41
[2022-04-11 02:51:38.535] End E001 | valid loss  4.421; ppl     83.22 | accu 0.1796 = 64929/361540
[2022-04-11 02:51:58.102] End E001 |  test loss  7.051; ppl   1153.44 | accu 0.0429 = 47370/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 02:52:01.606] End E001 |  test loss  4.339; ppl     76.63 | accu 0.1805 = 35584/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 02:52:04.516] End E001 |  test loss  4.613; ppl    100.81 | accu 0.1732 = 28465/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 02:52:04.516] Save: model.pt... 
[2022-04-11 02:52:04.529] Save: model.pt...Done. best_val_loss: 4.4214
[2022-04-11 02:52:04.529] Epoch 002/40 ==================================================
[2022-04-11 02:52:08.148] E002 |   200/2280 batches | lr 20.0000 | loss  4.018 | ppl     55.57
[2022-04-11 02:52:11.719] E002 |   400/2280 batches | lr 20.0000 | loss  4.025 | ppl     55.97
[2022-04-11 02:52:15.300] E002 |   600/2280 batches | lr 20.0000 | loss  3.949 | ppl     51.87
[2022-04-11 02:52:18.882] E002 |   800/2280 batches | lr 20.0000 | loss  3.921 | ppl     50.47
[2022-04-11 02:52:22.412] E002 |  1000/2280 batches | lr 20.0000 | loss  3.917 | ppl     50.27
[2022-04-11 02:52:25.958] E002 |  1200/2280 batches | lr 20.0000 | loss  3.841 | ppl     46.59
[2022-04-11 02:52:29.510] E002 |  1400/2280 batches | lr 20.0000 | loss  3.861 | ppl     47.53
[2022-04-11 02:52:33.068] E002 |  1600/2280 batches | lr 20.0000 | loss  3.810 | ppl     45.16
[2022-04-11 02:52:36.664] E002 |  1800/2280 batches | lr 20.0000 | loss  3.787 | ppl     44.13
[2022-04-11 02:52:40.228] E002 |  2000/2280 batches | lr 20.0000 | loss  3.815 | ppl     45.37
[2022-04-11 02:52:43.769] E002 |  2200/2280 batches | lr 20.0000 | loss  3.777 | ppl     43.70
[2022-04-11 02:52:45.265] E002 |  2280/2280 batches | lr 20.0000 | loss  3.791 | ppl     44.32
[2022-04-11 02:52:51.638] End E002 | valid loss  4.201; ppl     66.75 | accu 0.2137 = 77247/361540
[2022-04-11 02:53:11.304] End E002 |  test loss  5.964; ppl    389.10 | accu 0.0946 = 104438/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 02:53:14.827] End E002 |  test loss  3.973; ppl     53.17 | accu 0.2344 = 46209/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 02:53:17.882] End E002 |  test loss  4.584; ppl     97.87 | accu 0.1808 = 29716/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 02:53:17.883] Save: model.pt... 
[2022-04-11 02:53:17.895] Save: model.pt...Done. best_val_loss: 4.2010
[2022-04-11 02:53:17.895] Epoch 003/40 ==================================================
[2022-04-11 02:53:21.477] E003 |   200/2280 batches | lr 20.0000 | loss  3.802 | ppl     44.80
[2022-04-11 02:53:25.015] E003 |   400/2280 batches | lr 20.0000 | loss  3.827 | ppl     45.91
[2022-04-11 02:53:28.538] E003 |   600/2280 batches | lr 20.0000 | loss  3.774 | ppl     43.53
[2022-04-11 02:53:32.183] E003 |   800/2280 batches | lr 20.0000 | loss  3.771 | ppl     43.41
[2022-04-11 02:53:35.867] E003 |  1000/2280 batches | lr 20.0000 | loss  3.780 | ppl     43.82
[2022-04-11 02:53:39.408] E003 |  1200/2280 batches | lr 20.0000 | loss  3.708 | ppl     40.77
[2022-04-11 02:53:42.930] E003 |  1400/2280 batches | lr 20.0000 | loss  3.735 | ppl     41.91
[2022-04-11 02:53:46.475] E003 |  1600/2280 batches | lr 20.0000 | loss  3.701 | ppl     40.50
[2022-04-11 02:53:50.028] E003 |  1800/2280 batches | lr 20.0000 | loss  3.693 | ppl     40.15
[2022-04-11 02:53:53.550] E003 |  2000/2280 batches | lr 20.0000 | loss  3.730 | ppl     41.67
[2022-04-11 02:53:57.037] E003 |  2200/2280 batches | lr 20.0000 | loss  3.697 | ppl     40.33
[2022-04-11 02:53:58.443] E003 |  2280/2280 batches | lr 20.0000 | loss  3.714 | ppl     41.01
[2022-04-11 02:54:04.812] End E003 | valid loss  3.929; ppl     50.84 | accu 0.2349 = 84937/361540
[2022-04-11 02:54:24.359] End E003 |  test loss  4.895; ppl    133.58 | accu 0.1527 = 168519/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 02:54:28.097] End E003 |  test loss  3.972; ppl     53.10 | accu 0.2315 = 45641/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 02:54:31.056] End E003 |  test loss  3.936; ppl     51.19 | accu 0.2335 = 38382/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 02:54:31.057] Save: model.pt... 
[2022-04-11 02:54:31.070] Save: model.pt...Done. best_val_loss: 3.9287
[2022-04-11 02:54:31.070] Epoch 004/40 ==================================================
[2022-04-11 02:54:34.644] E004 |   200/2280 batches | lr 20.0000 | loss  3.727 | ppl     41.57
[2022-04-11 02:54:38.254] E004 |   400/2280 batches | lr 20.0000 | loss  3.759 | ppl     42.90
[2022-04-11 02:54:41.796] E004 |   600/2280 batches | lr 20.0000 | loss  3.712 | ppl     40.93
[2022-04-11 02:54:45.339] E004 |   800/2280 batches | lr 20.0000 | loss  3.708 | ppl     40.76
[2022-04-11 02:54:48.859] E004 |  1000/2280 batches | lr 20.0000 | loss  3.723 | ppl     41.38
[2022-04-11 02:54:52.416] E004 |  1200/2280 batches | lr 20.0000 | loss  3.653 | ppl     38.58
[2022-04-11 02:54:56.022] E004 |  1400/2280 batches | lr 20.0000 | loss  3.689 | ppl     40.01
[2022-04-11 02:54:59.541] E004 |  1600/2280 batches | lr 20.0000 | loss  3.653 | ppl     38.58
[2022-04-11 02:55:03.124] E004 |  1800/2280 batches | lr 20.0000 | loss  3.646 | ppl     38.34
[2022-04-11 02:55:06.662] E004 |  2000/2280 batches | lr 20.0000 | loss  3.689 | ppl     40.01
[2022-04-11 02:55:10.212] E004 |  2200/2280 batches | lr 20.0000 | loss  3.659 | ppl     38.83
[2022-04-11 02:55:11.648] E004 |  2280/2280 batches | lr 20.0000 | loss  3.679 | ppl     39.61
[2022-04-11 02:55:18.053] End E004 | valid loss  3.947; ppl     51.77 | accu 0.2320 = 83881/361540
[2022-04-11 02:55:37.460] End E004 |  test loss  5.607; ppl    272.43 | accu 0.1009 = 111381/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 02:55:40.939] End E004 |  test loss  4.062; ppl     58.08 | accu 0.2212 = 43602/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 02:55:43.832] End E004 |  test loss  3.812; ppl     45.26 | accu 0.2446 = 40201/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 02:55:43.832] Epoch 005/40 ==================================================
[2022-04-11 02:55:47.412] E005 |   200/2280 batches | lr 10.0000 | loss  3.670 | ppl     39.24
[2022-04-11 02:55:50.937] E005 |   400/2280 batches | lr 10.0000 | loss  3.684 | ppl     39.80
[2022-04-11 02:55:54.459] E005 |   600/2280 batches | lr 10.0000 | loss  3.624 | ppl     37.50
[2022-04-11 02:55:57.986] E005 |   800/2280 batches | lr 10.0000 | loss  3.618 | ppl     37.26
[2022-04-11 02:56:01.546] E005 |  1000/2280 batches | lr 10.0000 | loss  3.611 | ppl     37.01
[2022-04-11 02:56:05.068] E005 |  1200/2280 batches | lr 10.0000 | loss  3.540 | ppl     34.48
[2022-04-11 02:56:08.686] E005 |  1400/2280 batches | lr 10.0000 | loss  3.567 | ppl     35.40
[2022-04-11 02:56:12.229] E005 |  1600/2280 batches | lr 10.0000 | loss  3.525 | ppl     33.96
[2022-04-11 02:56:15.795] E005 |  1800/2280 batches | lr 10.0000 | loss  3.522 | ppl     33.84
[2022-04-11 02:56:19.413] E005 |  2000/2280 batches | lr 10.0000 | loss  3.552 | ppl     34.88
[2022-04-11 02:56:22.988] E005 |  2200/2280 batches | lr 10.0000 | loss  3.524 | ppl     33.91
[2022-04-11 02:56:24.413] E005 |  2280/2280 batches | lr 10.0000 | loss  3.539 | ppl     34.42
[2022-04-11 02:56:30.858] End E005 | valid loss  3.865; ppl     47.72 | accu 0.2510 = 90745/361540
[2022-04-11 02:56:50.313] End E005 |  test loss  5.581; ppl    265.40 | accu 0.1388 = 153186/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 02:56:53.794] End E005 |  test loss  4.008; ppl     55.05 | accu 0.2374 = 46803/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 02:56:56.698] End E005 |  test loss  3.722; ppl     41.35 | accu 0.2655 = 43635/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 02:56:56.698] Save: model.pt... 
[2022-04-11 02:56:56.711] Save: model.pt...Done. best_val_loss: 3.8653
[2022-04-11 02:56:56.711] Epoch 006/40 ==================================================
[2022-04-11 02:57:00.285] E006 |   200/2280 batches | lr 10.0000 | loss  3.570 | ppl     35.51
[2022-04-11 02:57:03.803] E006 |   400/2280 batches | lr 10.0000 | loss  3.604 | ppl     36.76
[2022-04-11 02:57:07.323] E006 |   600/2280 batches | lr 10.0000 | loss  3.561 | ppl     35.20
[2022-04-11 02:57:10.874] E006 |   800/2280 batches | lr 10.0000 | loss  3.556 | ppl     35.04
[2022-04-11 02:57:14.533] E006 |  1000/2280 batches | lr 10.0000 | loss  3.564 | ppl     35.31
[2022-04-11 02:57:18.108] E006 |  1200/2280 batches | lr 10.0000 | loss  3.495 | ppl     32.94
[2022-04-11 02:57:21.726] E006 |  1400/2280 batches | lr 10.0000 | loss  3.527 | ppl     34.02
[2022-04-11 02:57:25.279] E006 |  1600/2280 batches | lr 10.0000 | loss  3.492 | ppl     32.86
[2022-04-11 02:57:28.806] E006 |  1800/2280 batches | lr 10.0000 | loss  3.490 | ppl     32.77
[2022-04-11 02:57:32.324] E006 |  2000/2280 batches | lr 10.0000 | loss  3.525 | ppl     33.94
[2022-04-11 02:57:35.854] E006 |  2200/2280 batches | lr 10.0000 | loss  3.501 | ppl     33.14
[2022-04-11 02:57:37.267] E006 |  2280/2280 batches | lr 10.0000 | loss  3.520 | ppl     33.78
[2022-04-11 02:57:43.681] End E006 | valid loss  3.813; ppl     45.30 | accu 0.2575 = 93079/361540
[2022-04-11 02:58:03.200] End E006 |  test loss  4.785; ppl    119.72 | accu 0.1740 = 191981/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 02:58:06.699] End E006 |  test loss  3.964; ppl     52.69 | accu 0.2442 = 48136/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 02:58:09.617] End E006 |  test loss  3.672; ppl     39.32 | accu 0.2697 = 44331/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 02:58:09.618] Save: model.pt... 
[2022-04-11 02:58:09.630] Save: model.pt...Done. best_val_loss: 3.8132
[2022-04-11 02:58:09.630] Epoch 007/40 ==================================================
[2022-04-11 02:58:13.240] E007 |   200/2280 batches | lr 10.0000 | loss  3.541 | ppl     34.52
[2022-04-11 02:58:16.812] E007 |   400/2280 batches | lr 10.0000 | loss  3.582 | ppl     35.94
[2022-04-11 02:58:20.326] E007 |   600/2280 batches | lr 10.0000 | loss  3.530 | ppl     34.11
[2022-04-11 02:58:23.846] E007 |   800/2280 batches | lr 10.0000 | loss  3.532 | ppl     34.18
[2022-04-11 02:58:27.372] E007 |  1000/2280 batches | lr 10.0000 | loss  3.537 | ppl     34.38
[2022-04-11 02:58:30.919] E007 |  1200/2280 batches | lr 10.0000 | loss  3.471 | ppl     32.18
[2022-04-11 02:58:34.455] E007 |  1400/2280 batches | lr 10.0000 | loss  3.508 | ppl     33.38
[2022-04-11 02:58:37.996] E007 |  1600/2280 batches | lr 10.0000 | loss  3.469 | ppl     32.11
[2022-04-11 02:58:41.556] E007 |  1800/2280 batches | lr 10.0000 | loss  3.474 | ppl     32.28
[2022-04-11 02:58:45.177] E007 |  2000/2280 batches | lr 10.0000 | loss  3.505 | ppl     33.28
[2022-04-11 02:58:48.698] E007 |  2200/2280 batches | lr 10.0000 | loss  3.485 | ppl     32.62
[2022-04-11 02:58:50.131] E007 |  2280/2280 batches | lr 10.0000 | loss  3.504 | ppl     33.25
[2022-04-11 02:58:56.527] End E007 | valid loss  3.697; ppl     40.32 | accu 0.2702 = 97693/361540
[2022-04-11 02:59:15.958] End E007 |  test loss  4.738; ppl    114.17 | accu 0.1766 = 194922/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 02:59:19.439] End E007 |  test loss  3.754; ppl     42.71 | accu 0.2671 = 52656/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 02:59:22.343] End E007 |  test loss  3.662; ppl     38.95 | accu 0.2699 = 44369/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 02:59:22.344] Save: model.pt... 
[2022-04-11 02:59:22.352] Save: model.pt...Done. best_val_loss: 3.6967
[2022-04-11 02:59:22.352] Epoch 008/40 ==================================================
[2022-04-11 02:59:25.908] E008 |   200/2280 batches | lr 10.0000 | loss  3.522 | ppl     33.85
[2022-04-11 02:59:29.419] E008 |   400/2280 batches | lr 10.0000 | loss  3.554 | ppl     34.97
[2022-04-11 02:59:32.951] E008 |   600/2280 batches | lr 10.0000 | loss  3.511 | ppl     33.48
[2022-04-11 02:59:36.532] E008 |   800/2280 batches | lr 10.0000 | loss  3.516 | ppl     33.64
[2022-04-11 02:59:40.086] E008 |  1000/2280 batches | lr 10.0000 | loss  3.524 | ppl     33.93
[2022-04-11 02:59:43.618] E008 |  1200/2280 batches | lr 10.0000 | loss  3.456 | ppl     31.69
[2022-04-11 02:59:47.430] E008 |  1400/2280 batches | lr 10.0000 | loss  3.491 | ppl     32.82
[2022-04-11 02:59:51.535] E008 |  1600/2280 batches | lr 10.0000 | loss  3.458 | ppl     31.76
[2022-04-11 02:59:55.124] E008 |  1800/2280 batches | lr 10.0000 | loss  3.460 | ppl     31.82
[2022-04-11 02:59:58.794] E008 |  2000/2280 batches | lr 10.0000 | loss  3.491 | ppl     32.83
[2022-04-11 03:00:02.412] E008 |  2200/2280 batches | lr 10.0000 | loss  3.472 | ppl     32.19
[2022-04-11 03:00:03.826] E008 |  2280/2280 batches | lr 10.0000 | loss  3.494 | ppl     32.91
[2022-04-11 03:00:10.217] End E008 | valid loss  3.688; ppl     39.98 | accu 0.2719 = 98308/361540
[2022-04-11 03:00:29.646] End E008 |  test loss  4.696; ppl    109.47 | accu 0.1820 = 200887/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:00:33.147] End E008 |  test loss  3.735; ppl     41.89 | accu 0.2683 = 52895/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:00:36.053] End E008 |  test loss  3.640; ppl     38.09 | accu 0.2745 = 45125/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:00:36.053] Save: model.pt... 
[2022-04-11 03:00:36.065] Save: model.pt...Done. best_val_loss: 3.6883
[2022-04-11 03:00:36.065] Epoch 009/40 ==================================================
[2022-04-11 03:00:39.613] E009 |   200/2280 batches | lr 10.0000 | loss  3.507 | ppl     33.34
[2022-04-11 03:00:43.177] E009 |   400/2280 batches | lr 10.0000 | loss  3.539 | ppl     34.42
[2022-04-11 03:00:46.702] E009 |   600/2280 batches | lr 10.0000 | loss  3.501 | ppl     33.15
[2022-04-11 03:00:50.228] E009 |   800/2280 batches | lr 10.0000 | loss  3.502 | ppl     33.19
[2022-04-11 03:00:53.752] E009 |  1000/2280 batches | lr 10.0000 | loss  3.510 | ppl     33.43
[2022-04-11 03:00:57.267] E009 |  1200/2280 batches | lr 10.0000 | loss  3.439 | ppl     31.15
[2022-04-11 03:01:00.812] E009 |  1400/2280 batches | lr 10.0000 | loss  3.478 | ppl     32.38
[2022-04-11 03:01:04.403] E009 |  1600/2280 batches | lr 10.0000 | loss  3.446 | ppl     31.38
[2022-04-11 03:01:07.939] E009 |  1800/2280 batches | lr 10.0000 | loss  3.448 | ppl     31.42
[2022-04-11 03:01:11.476] E009 |  2000/2280 batches | lr 10.0000 | loss  3.483 | ppl     32.56
[2022-04-11 03:01:15.092] E009 |  2200/2280 batches | lr 10.0000 | loss  3.461 | ppl     31.84
[2022-04-11 03:01:16.498] E009 |  2280/2280 batches | lr 10.0000 | loss  3.485 | ppl     32.63
[2022-04-11 03:01:22.887] End E009 | valid loss  3.768; ppl     43.30 | accu 0.2654 = 95936/361540
[2022-04-11 03:01:42.306] End E009 |  test loss  4.726; ppl    112.85 | accu 0.1822 = 201032/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:01:45.800] End E009 |  test loss  3.991; ppl     54.12 | accu 0.2460 = 48498/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:01:48.701] End E009 |  test loss  3.636; ppl     37.93 | accu 0.2770 = 45534/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:01:48.701] Epoch 010/40 ==================================================
[2022-04-11 03:01:52.279] E010 |   200/2280 batches | lr 5.0000 | loss  3.494 | ppl     32.91
[2022-04-11 03:01:55.815] E010 |   400/2280 batches | lr 5.0000 | loss  3.522 | ppl     33.84
[2022-04-11 03:01:59.334] E010 |   600/2280 batches | lr 5.0000 | loss  3.469 | ppl     32.09
[2022-04-11 03:02:02.856] E010 |   800/2280 batches | lr 5.0000 | loss  3.472 | ppl     32.19
[2022-04-11 03:02:06.375] E010 |  1000/2280 batches | lr 5.0000 | loss  3.463 | ppl     31.90
[2022-04-11 03:02:09.899] E010 |  1200/2280 batches | lr 5.0000 | loss  3.394 | ppl     29.80
[2022-04-11 03:02:13.459] E010 |  1400/2280 batches | lr 5.0000 | loss  3.424 | ppl     30.68
[2022-04-11 03:02:17.010] E010 |  1600/2280 batches | lr 5.0000 | loss  3.396 | ppl     29.83
[2022-04-11 03:02:20.603] E010 |  1800/2280 batches | lr 5.0000 | loss  3.391 | ppl     29.69
[2022-04-11 03:02:24.118] E010 |  2000/2280 batches | lr 5.0000 | loss  3.419 | ppl     30.54
[2022-04-11 03:02:27.659] E010 |  2200/2280 batches | lr 5.0000 | loss  3.394 | ppl     29.80
[2022-04-11 03:02:29.060] E010 |  2280/2280 batches | lr 5.0000 | loss  3.413 | ppl     30.37
[2022-04-11 03:02:35.442] End E010 | valid loss  3.664; ppl     39.00 | accu 0.2790 = 100884/361540
[2022-04-11 03:02:54.969] End E010 |  test loss  4.680; ppl    107.74 | accu 0.1874 = 206814/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:02:58.455] End E010 |  test loss  3.806; ppl     44.96 | accu 0.2656 = 52358/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:03:01.383] End E010 |  test loss  3.585; ppl     36.04 | accu 0.2863 = 47064/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:03:01.383] Save: model.pt... 
[2022-04-11 03:03:01.396] Save: model.pt...Done. best_val_loss: 3.6635
[2022-04-11 03:03:01.396] Epoch 011/40 ==================================================
[2022-04-11 03:03:04.993] E011 |   200/2280 batches | lr 5.0000 | loss  3.443 | ppl     31.29
[2022-04-11 03:03:08.538] E011 |   400/2280 batches | lr 5.0000 | loss  3.483 | ppl     32.57
[2022-04-11 03:03:12.148] E011 |   600/2280 batches | lr 5.0000 | loss  3.437 | ppl     31.10
[2022-04-11 03:03:15.683] E011 |   800/2280 batches | lr 5.0000 | loss  3.443 | ppl     31.28
[2022-04-11 03:03:19.235] E011 |  1000/2280 batches | lr 5.0000 | loss  3.439 | ppl     31.16
[2022-04-11 03:03:22.804] E011 |  1200/2280 batches | lr 5.0000 | loss  3.376 | ppl     29.25
[2022-04-11 03:03:26.338] E011 |  1400/2280 batches | lr 5.0000 | loss  3.407 | ppl     30.17
[2022-04-11 03:03:29.868] E011 |  1600/2280 batches | lr 5.0000 | loss  3.380 | ppl     29.38
[2022-04-11 03:03:33.439] E011 |  1800/2280 batches | lr 5.0000 | loss  3.379 | ppl     29.35
[2022-04-11 03:03:37.009] E011 |  2000/2280 batches | lr 5.0000 | loss  3.406 | ppl     30.16
[2022-04-11 03:03:40.493] E011 |  2200/2280 batches | lr 5.0000 | loss  3.387 | ppl     29.59
[2022-04-11 03:03:41.891] E011 |  2280/2280 batches | lr 5.0000 | loss  3.411 | ppl     30.29
[2022-04-11 03:03:48.258] End E011 | valid loss  3.705; ppl     40.66 | accu 0.2763 = 99900/361540
[2022-04-11 03:04:07.698] End E011 |  test loss  4.679; ppl    107.71 | accu 0.1883 = 207841/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:04:11.186] End E011 |  test loss  3.949; ppl     51.87 | accu 0.2546 = 50191/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:04:14.080] End E011 |  test loss  3.573; ppl     35.62 | accu 0.2884 = 47400/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:04:14.080] Epoch 012/40 ==================================================
[2022-04-11 03:04:17.663] E012 |   200/2280 batches | lr 2.5000 | loss  3.435 | ppl     31.04
[2022-04-11 03:04:21.179] E012 |   400/2280 batches | lr 2.5000 | loss  3.472 | ppl     32.19
[2022-04-11 03:04:24.772] E012 |   600/2280 batches | lr 2.5000 | loss  3.422 | ppl     30.62
[2022-04-11 03:04:28.333] E012 |   800/2280 batches | lr 2.5000 | loss  3.429 | ppl     30.83
[2022-04-11 03:04:31.888] E012 |  1000/2280 batches | lr 2.5000 | loss  3.418 | ppl     30.52
[2022-04-11 03:04:35.415] E012 |  1200/2280 batches | lr 2.5000 | loss  3.356 | ppl     28.66
[2022-04-11 03:04:38.942] E012 |  1400/2280 batches | lr 2.5000 | loss  3.381 | ppl     29.40
[2022-04-11 03:04:42.457] E012 |  1600/2280 batches | lr 2.5000 | loss  3.355 | ppl     28.66
[2022-04-11 03:04:45.987] E012 |  1800/2280 batches | lr 2.5000 | loss  3.349 | ppl     28.48
[2022-04-11 03:04:49.508] E012 |  2000/2280 batches | lr 2.5000 | loss  3.375 | ppl     29.22
[2022-04-11 03:04:53.030] E012 |  2200/2280 batches | lr 2.5000 | loss  3.354 | ppl     28.62
[2022-04-11 03:04:54.450] E012 |  2280/2280 batches | lr 2.5000 | loss  3.377 | ppl     29.29
[2022-04-11 03:05:00.835] End E012 | valid loss  3.687; ppl     39.94 | accu 0.2799 = 101189/361540
[2022-04-11 03:05:20.259] End E012 |  test loss  4.667; ppl    106.40 | accu 0.1916 = 211472/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:05:23.726] End E012 |  test loss  3.944; ppl     51.64 | accu 0.2574 = 50748/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:05:26.645] End E012 |  test loss  3.549; ppl     34.78 | accu 0.2925 = 48076/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:05:26.646] Epoch 013/40 ==================================================
[2022-04-11 03:05:30.195] E013 |   200/2280 batches | lr 1.2500 | loss  3.419 | ppl     30.53
[2022-04-11 03:05:33.727] E013 |   400/2280 batches | lr 1.2500 | loss  3.456 | ppl     31.68
[2022-04-11 03:05:37.304] E013 |   600/2280 batches | lr 1.2500 | loss  3.406 | ppl     30.15
[2022-04-11 03:05:40.870] E013 |   800/2280 batches | lr 1.2500 | loss  3.411 | ppl     30.30
[2022-04-11 03:05:44.413] E013 |  1000/2280 batches | lr 1.2500 | loss  3.407 | ppl     30.17
[2022-04-11 03:05:47.956] E013 |  1200/2280 batches | lr 1.2500 | loss  3.338 | ppl     28.16
[2022-04-11 03:05:51.501] E013 |  1400/2280 batches | lr 1.2500 | loss  3.368 | ppl     29.02
[2022-04-11 03:05:55.092] E013 |  1600/2280 batches | lr 1.2500 | loss  3.337 | ppl     28.12
[2022-04-11 03:05:58.653] E013 |  1800/2280 batches | lr 1.2500 | loss  3.336 | ppl     28.10
[2022-04-11 03:06:02.221] E013 |  2000/2280 batches | lr 1.2500 | loss  3.358 | ppl     28.72
[2022-04-11 03:06:05.804] E013 |  2200/2280 batches | lr 1.2500 | loss  3.334 | ppl     28.05
[2022-04-11 03:06:07.209] E013 |  2280/2280 batches | lr 1.2500 | loss  3.359 | ppl     28.75
[2022-04-11 03:06:13.663] End E013 | valid loss  3.661; ppl     38.91 | accu 0.2828 = 102237/361540
[2022-04-11 03:06:33.439] End E013 |  test loss  4.675; ppl    107.19 | accu 0.1928 = 212763/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:06:36.957] End E013 |  test loss  3.833; ppl     46.19 | accu 0.2673 = 52698/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:06:39.858] End E013 |  test loss  3.539; ppl     34.44 | accu 0.2943 = 48370/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:06:39.858] Save: model.pt... 
[2022-04-11 03:06:39.870] Save: model.pt...Done. best_val_loss: 3.6611
[2022-04-11 03:06:39.871] Epoch 014/40 ==================================================
[2022-04-11 03:06:43.444] E014 |   200/2280 batches | lr 1.2500 | loss  3.398 | ppl     29.91
[2022-04-11 03:06:47.075] E014 |   400/2280 batches | lr 1.2500 | loss  3.442 | ppl     31.23
[2022-04-11 03:06:50.610] E014 |   600/2280 batches | lr 1.2500 | loss  3.394 | ppl     29.78
[2022-04-11 03:06:54.198] E014 |   800/2280 batches | lr 1.2500 | loss  3.397 | ppl     29.88
[2022-04-11 03:06:57.797] E014 |  1000/2280 batches | lr 1.2500 | loss  3.394 | ppl     29.78
[2022-04-11 03:07:01.361] E014 |  1200/2280 batches | lr 1.2500 | loss  3.328 | ppl     27.87
[2022-04-11 03:07:04.917] E014 |  1400/2280 batches | lr 1.2500 | loss  3.357 | ppl     28.70
[2022-04-11 03:07:08.465] E014 |  1600/2280 batches | lr 1.2500 | loss  3.327 | ppl     27.87
[2022-04-11 03:07:12.012] E014 |  1800/2280 batches | lr 1.2500 | loss  3.332 | ppl     27.98
[2022-04-11 03:07:15.563] E014 |  2000/2280 batches | lr 1.2500 | loss  3.352 | ppl     28.56
[2022-04-11 03:07:19.119] E014 |  2200/2280 batches | lr 1.2500 | loss  3.340 | ppl     28.21
[2022-04-11 03:07:20.542] E014 |  2280/2280 batches | lr 1.2500 | loss  3.353 | ppl     28.58
[2022-04-11 03:07:26.946] End E014 | valid loss  3.615; ppl     37.15 | accu 0.2872 = 103840/361540
[2022-04-11 03:07:46.404] End E014 |  test loss  4.679; ppl    107.71 | accu 0.1932 = 213193/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:07:49.879] End E014 |  test loss  3.821; ppl     45.65 | accu 0.2687 = 52972/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:07:52.793] End E014 |  test loss  3.535; ppl     34.30 | accu 0.2947 = 48442/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:07:52.793] Save: model.pt... 
[2022-04-11 03:07:52.806] Save: model.pt...Done. best_val_loss: 3.6150
[2022-04-11 03:07:52.806] Epoch 015/40 ==================================================
[2022-04-11 03:07:56.415] E015 |   200/2280 batches | lr 1.2500 | loss  3.391 | ppl     29.69
[2022-04-11 03:07:59.960] E015 |   400/2280 batches | lr 1.2500 | loss  3.430 | ppl     30.87
[2022-04-11 03:08:03.500] E015 |   600/2280 batches | lr 1.2500 | loss  3.385 | ppl     29.50
[2022-04-11 03:08:07.036] E015 |   800/2280 batches | lr 1.2500 | loss  3.394 | ppl     29.80
[2022-04-11 03:08:10.584] E015 |  1000/2280 batches | lr 1.2500 | loss  3.387 | ppl     29.58
[2022-04-11 03:08:14.123] E015 |  1200/2280 batches | lr 1.2500 | loss  3.328 | ppl     27.87
[2022-04-11 03:08:17.620] E015 |  1400/2280 batches | lr 1.2500 | loss  3.355 | ppl     28.66
[2022-04-11 03:08:21.145] E015 |  1600/2280 batches | lr 1.2500 | loss  3.324 | ppl     27.78
[2022-04-11 03:08:24.645] E015 |  1800/2280 batches | lr 1.2500 | loss  3.328 | ppl     27.89
[2022-04-11 03:08:28.168] E015 |  2000/2280 batches | lr 1.2500 | loss  3.351 | ppl     28.54
[2022-04-11 03:08:31.694] E015 |  2200/2280 batches | lr 1.2500 | loss  3.334 | ppl     28.05
[2022-04-11 03:08:33.104] E015 |  2280/2280 batches | lr 1.2500 | loss  3.352 | ppl     28.57
[2022-04-11 03:08:39.566] End E015 | valid loss  3.577; ppl     35.78 | accu 0.2910 = 105198/361540
[2022-04-11 03:08:59.032] End E015 |  test loss  4.674; ppl    107.13 | accu 0.1932 = 213211/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:09:02.552] End E015 |  test loss  3.772; ppl     43.47 | accu 0.2731 = 53827/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:09:05.464] End E015 |  test loss  3.532; ppl     34.19 | accu 0.2955 = 48567/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:09:05.464] Save: model.pt... 
[2022-04-11 03:09:05.477] Save: model.pt...Done. best_val_loss: 3.5775
[2022-04-11 03:09:05.478] Epoch 016/40 ==================================================
[2022-04-11 03:09:09.030] E016 |   200/2280 batches | lr 1.2500 | loss  3.384 | ppl     29.50
[2022-04-11 03:09:12.560] E016 |   400/2280 batches | lr 1.2500 | loss  3.426 | ppl     30.75
[2022-04-11 03:09:16.128] E016 |   600/2280 batches | lr 1.2500 | loss  3.379 | ppl     29.35
[2022-04-11 03:09:19.654] E016 |   800/2280 batches | lr 1.2500 | loss  3.393 | ppl     29.75
[2022-04-11 03:09:23.187] E016 |  1000/2280 batches | lr 1.2500 | loss  3.383 | ppl     29.47
[2022-04-11 03:09:26.718] E016 |  1200/2280 batches | lr 1.2500 | loss  3.320 | ppl     27.66
[2022-04-11 03:09:30.251] E016 |  1400/2280 batches | lr 1.2500 | loss  3.347 | ppl     28.40
[2022-04-11 03:09:33.763] E016 |  1600/2280 batches | lr 1.2500 | loss  3.323 | ppl     27.73
[2022-04-11 03:09:37.295] E016 |  1800/2280 batches | lr 1.2500 | loss  3.327 | ppl     27.86
[2022-04-11 03:09:40.815] E016 |  2000/2280 batches | lr 1.2500 | loss  3.351 | ppl     28.53
[2022-04-11 03:09:44.337] E016 |  2200/2280 batches | lr 1.2500 | loss  3.332 | ppl     27.99
[2022-04-11 03:09:45.784] E016 |  2280/2280 batches | lr 1.2500 | loss  3.353 | ppl     28.60
[2022-04-11 03:09:52.221] End E016 | valid loss  3.646; ppl     38.33 | accu 0.2845 = 102849/361540
[2022-04-11 03:10:11.664] End E016 |  test loss  4.662; ppl    105.87 | accu 0.1938 = 213839/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:10:15.157] End E016 |  test loss  3.812; ppl     45.24 | accu 0.2693 = 53083/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:10:18.081] End E016 |  test loss  3.530; ppl     34.14 | accu 0.2954 = 48563/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:10:18.082] Epoch 017/40 ==================================================
[2022-04-11 03:10:21.676] E017 |   200/2280 batches | lr 0.6250 | loss  3.384 | ppl     29.50
[2022-04-11 03:10:25.193] E017 |   400/2280 batches | lr 0.6250 | loss  3.426 | ppl     30.76
[2022-04-11 03:10:28.716] E017 |   600/2280 batches | lr 0.6250 | loss  3.377 | ppl     29.28
[2022-04-11 03:10:32.255] E017 |   800/2280 batches | lr 0.6250 | loss  3.385 | ppl     29.51
[2022-04-11 03:10:35.816] E017 |  1000/2280 batches | lr 0.6250 | loss  3.376 | ppl     29.26
[2022-04-11 03:10:39.368] E017 |  1200/2280 batches | lr 0.6250 | loss  3.320 | ppl     27.66
[2022-04-11 03:10:42.912] E017 |  1400/2280 batches | lr 0.6250 | loss  3.341 | ppl     28.24
[2022-04-11 03:10:46.440] E017 |  1600/2280 batches | lr 0.6250 | loss  3.315 | ppl     27.53
[2022-04-11 03:10:49.964] E017 |  1800/2280 batches | lr 0.6250 | loss  3.317 | ppl     27.57
[2022-04-11 03:10:53.533] E017 |  2000/2280 batches | lr 0.6250 | loss  3.339 | ppl     28.19
[2022-04-11 03:10:57.087] E017 |  2200/2280 batches | lr 0.6250 | loss  3.324 | ppl     27.77
[2022-04-11 03:10:58.498] E017 |  2280/2280 batches | lr 0.6250 | loss  3.343 | ppl     28.32
[2022-04-11 03:11:04.950] End E017 | valid loss  3.572; ppl     35.60 | accu 0.2919 = 105530/361540
[2022-04-11 03:11:24.425] End E017 |  test loss  4.671; ppl    106.76 | accu 0.1940 = 214070/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:11:27.924] End E017 |  test loss  3.765; ppl     43.16 | accu 0.2741 = 54023/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:11:30.843] End E017 |  test loss  3.526; ppl     33.99 | accu 0.2967 = 48775/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:11:30.843] Save: model.pt... 
[2022-04-11 03:11:30.856] Save: model.pt...Done. best_val_loss: 3.5722
[2022-04-11 03:11:30.856] Epoch 018/40 ==================================================
[2022-04-11 03:11:34.396] E018 |   200/2280 batches | lr 0.6250 | loss  3.377 | ppl     29.30
[2022-04-11 03:11:37.937] E018 |   400/2280 batches | lr 0.6250 | loss  3.418 | ppl     30.52
[2022-04-11 03:11:41.454] E018 |   600/2280 batches | lr 0.6250 | loss  3.375 | ppl     29.21
[2022-04-11 03:11:45.017] E018 |   800/2280 batches | lr 0.6250 | loss  3.383 | ppl     29.47
[2022-04-11 03:11:48.570] E018 |  1000/2280 batches | lr 0.6250 | loss  3.374 | ppl     29.19
[2022-04-11 03:11:52.063] E018 |  1200/2280 batches | lr 0.6250 | loss  3.315 | ppl     27.51
[2022-04-11 03:11:55.625] E018 |  1400/2280 batches | lr 0.6250 | loss  3.338 | ppl     28.17
[2022-04-11 03:11:59.141] E018 |  1600/2280 batches | lr 0.6250 | loss  3.308 | ppl     27.34
[2022-04-11 03:12:02.750] E018 |  1800/2280 batches | lr 0.6250 | loss  3.316 | ppl     27.56
[2022-04-11 03:12:06.275] E018 |  2000/2280 batches | lr 0.6250 | loss  3.337 | ppl     28.13
[2022-04-11 03:12:09.813] E018 |  2200/2280 batches | lr 0.6250 | loss  3.320 | ppl     27.66
[2022-04-11 03:12:11.234] E018 |  2280/2280 batches | lr 0.6250 | loss  3.342 | ppl     28.27
[2022-04-11 03:12:17.603] End E018 | valid loss  3.605; ppl     36.77 | accu 0.2892 = 104561/361540
[2022-04-11 03:12:37.099] End E018 |  test loss  4.669; ppl    106.63 | accu 0.1941 = 214252/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:12:40.589] End E018 |  test loss  3.803; ppl     44.84 | accu 0.2716 = 53535/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:12:43.495] End E018 |  test loss  3.524; ppl     33.94 | accu 0.2968 = 48787/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:12:43.495] Epoch 019/40 ==================================================
[2022-04-11 03:12:47.274] E019 |   200/2280 batches | lr 0.3125 | loss  3.380 | ppl     29.36
[2022-04-11 03:12:50.886] E019 |   400/2280 batches | lr 0.3125 | loss  3.417 | ppl     30.48
[2022-04-11 03:12:54.861] E019 |   600/2280 batches | lr 0.3125 | loss  3.368 | ppl     29.03
[2022-04-11 03:12:58.765] E019 |   800/2280 batches | lr 0.3125 | loss  3.378 | ppl     29.33
[2022-04-11 03:13:02.447] E019 |  1000/2280 batches | lr 0.3125 | loss  3.370 | ppl     29.07
[2022-04-11 03:13:05.976] E019 |  1200/2280 batches | lr 0.3125 | loss  3.312 | ppl     27.45
[2022-04-11 03:13:09.523] E019 |  1400/2280 batches | lr 0.3125 | loss  3.334 | ppl     28.06
[2022-04-11 03:13:13.053] E019 |  1600/2280 batches | lr 0.3125 | loss  3.303 | ppl     27.20
[2022-04-11 03:13:16.564] E019 |  1800/2280 batches | lr 0.3125 | loss  3.314 | ppl     27.49
[2022-04-11 03:13:20.340] E019 |  2000/2280 batches | lr 0.3125 | loss  3.331 | ppl     27.98
[2022-04-11 03:13:23.852] E019 |  2200/2280 batches | lr 0.3125 | loss  3.317 | ppl     27.58
[2022-04-11 03:13:25.293] E019 |  2280/2280 batches | lr 0.3125 | loss  3.340 | ppl     28.21
[2022-04-11 03:13:31.720] End E019 | valid loss  3.566; ppl     35.37 | accu 0.2928 = 105851/361540
[2022-04-11 03:13:51.192] End E019 |  test loss  4.670; ppl    106.73 | accu 0.1944 = 214588/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:13:54.668] End E019 |  test loss  3.640; ppl     38.09 | accu 0.2848 = 56142/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:13:57.566] End E019 |  test loss  3.522; ppl     33.84 | accu 0.2976 = 48925/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:13:57.566] Save: model.pt... 
[2022-04-11 03:13:57.579] Save: model.pt...Done. best_val_loss: 3.5659
[2022-04-11 03:13:57.579] Epoch 020/40 ==================================================
[2022-04-11 03:14:01.209] E020 |   200/2280 batches | lr 0.3125 | loss  3.375 | ppl     29.23
[2022-04-11 03:14:04.736] E020 |   400/2280 batches | lr 0.3125 | loss  3.415 | ppl     30.41
[2022-04-11 03:14:08.282] E020 |   600/2280 batches | lr 0.3125 | loss  3.371 | ppl     29.11
[2022-04-11 03:14:11.827] E020 |   800/2280 batches | lr 0.3125 | loss  3.378 | ppl     29.32
[2022-04-11 03:14:15.685] E020 |  1000/2280 batches | lr 0.3125 | loss  3.368 | ppl     29.03
[2022-04-11 03:14:19.228] E020 |  1200/2280 batches | lr 0.3125 | loss  3.312 | ppl     27.45
[2022-04-11 03:14:22.795] E020 |  1400/2280 batches | lr 0.3125 | loss  3.332 | ppl     28.01
[2022-04-11 03:14:26.470] E020 |  1600/2280 batches | lr 0.3125 | loss  3.305 | ppl     27.24
[2022-04-11 03:14:30.012] E020 |  1800/2280 batches | lr 0.3125 | loss  3.313 | ppl     27.47
[2022-04-11 03:14:33.608] E020 |  2000/2280 batches | lr 0.3125 | loss  3.333 | ppl     28.03
[2022-04-11 03:14:37.146] E020 |  2200/2280 batches | lr 0.3125 | loss  3.319 | ppl     27.63
[2022-04-11 03:14:38.622] E020 |  2280/2280 batches | lr 0.3125 | loss  3.339 | ppl     28.20
[2022-04-11 03:14:44.954] End E020 | valid loss  3.565; ppl     35.34 | accu 0.2927 = 105821/361540
[2022-04-11 03:15:04.398] End E020 |  test loss  4.668; ppl    106.45 | accu 0.1945 = 214686/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:15:07.886] End E020 |  test loss  3.638; ppl     38.01 | accu 0.2848 = 56137/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:15:10.787] End E020 |  test loss  3.521; ppl     33.82 | accu 0.2977 = 48936/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:15:10.787] Save: model.pt... 
[2022-04-11 03:15:10.799] Save: model.pt...Done. best_val_loss: 3.5650
[2022-04-11 03:15:10.799] Epoch 021/40 ==================================================
[2022-04-11 03:15:14.425] E021 |   200/2280 batches | lr 0.3125 | loss  3.371 | ppl     29.11
[2022-04-11 03:15:18.006] E021 |   400/2280 batches | lr 0.3125 | loss  3.410 | ppl     30.27
[2022-04-11 03:15:21.565] E021 |   600/2280 batches | lr 0.3125 | loss  3.367 | ppl     28.98
[2022-04-11 03:15:25.110] E021 |   800/2280 batches | lr 0.3125 | loss  3.377 | ppl     29.27
[2022-04-11 03:15:28.642] E021 |  1000/2280 batches | lr 0.3125 | loss  3.367 | ppl     28.99
[2022-04-11 03:15:32.167] E021 |  1200/2280 batches | lr 0.3125 | loss  3.311 | ppl     27.41
[2022-04-11 03:15:35.708] E021 |  1400/2280 batches | lr 0.3125 | loss  3.330 | ppl     27.93
[2022-04-11 03:15:39.247] E021 |  1600/2280 batches | lr 0.3125 | loss  3.305 | ppl     27.26
[2022-04-11 03:15:42.798] E021 |  1800/2280 batches | lr 0.3125 | loss  3.309 | ppl     27.36
[2022-04-11 03:15:46.354] E021 |  2000/2280 batches | lr 0.3125 | loss  3.329 | ppl     27.91
[2022-04-11 03:15:49.880] E021 |  2200/2280 batches | lr 0.3125 | loss  3.317 | ppl     27.57
[2022-04-11 03:15:51.292] E021 |  2280/2280 batches | lr 0.3125 | loss  3.334 | ppl     28.06
[2022-04-11 03:15:57.631] End E021 | valid loss  3.564; ppl     35.32 | accu 0.2931 = 105980/361540
[2022-04-11 03:16:17.011] End E021 |  test loss  4.667; ppl    106.40 | accu 0.1945 = 214628/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:16:20.492] End E021 |  test loss  3.638; ppl     38.01 | accu 0.2852 = 56227/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:16:23.395] End E021 |  test loss  3.520; ppl     33.80 | accu 0.2983 = 49028/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:16:23.396] Save: model.pt... 
[2022-04-11 03:16:23.404] Save: model.pt...Done. best_val_loss: 3.5644
[2022-04-11 03:16:23.404] Epoch 022/40 ==================================================
[2022-04-11 03:16:27.199] E022 |   200/2280 batches | lr 0.3125 | loss  3.373 | ppl     29.16
[2022-04-11 03:16:30.986] E022 |   400/2280 batches | lr 0.3125 | loss  3.410 | ppl     30.26
[2022-04-11 03:16:34.494] E022 |   600/2280 batches | lr 0.3125 | loss  3.363 | ppl     28.86
[2022-04-11 03:16:38.083] E022 |   800/2280 batches | lr 0.3125 | loss  3.369 | ppl     29.06
[2022-04-11 03:16:41.629] E022 |  1000/2280 batches | lr 0.3125 | loss  3.363 | ppl     28.87
[2022-04-11 03:16:45.190] E022 |  1200/2280 batches | lr 0.3125 | loss  3.308 | ppl     27.34
[2022-04-11 03:16:48.728] E022 |  1400/2280 batches | lr 0.3125 | loss  3.328 | ppl     27.89
[2022-04-11 03:16:52.295] E022 |  1600/2280 batches | lr 0.3125 | loss  3.305 | ppl     27.25
[2022-04-11 03:16:55.794] E022 |  1800/2280 batches | lr 0.3125 | loss  3.310 | ppl     27.39
[2022-04-11 03:16:59.309] E022 |  2000/2280 batches | lr 0.3125 | loss  3.331 | ppl     27.96
[2022-04-11 03:17:02.858] E022 |  2200/2280 batches | lr 0.3125 | loss  3.316 | ppl     27.55
[2022-04-11 03:17:04.260] E022 |  2280/2280 batches | lr 0.3125 | loss  3.332 | ppl     28.00
[2022-04-11 03:17:10.636] End E022 | valid loss  3.563; ppl     35.28 | accu 0.2932 = 106020/361540
[2022-04-11 03:17:30.065] End E022 |  test loss  4.669; ppl    106.55 | accu 0.1945 = 214662/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:17:33.544] End E022 |  test loss  3.603; ppl     36.72 | accu 0.2884 = 56853/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:17:36.450] End E022 |  test loss  3.520; ppl     33.78 | accu 0.2982 = 49016/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:17:36.451] Save: model.pt... 
[2022-04-11 03:17:36.463] Save: model.pt...Done. best_val_loss: 3.5633
[2022-04-11 03:17:36.463] Epoch 023/40 ==================================================
[2022-04-11 03:17:40.031] E023 |   200/2280 batches | lr 0.3125 | loss  3.364 | ppl     28.92
[2022-04-11 03:17:43.596] E023 |   400/2280 batches | lr 0.3125 | loss  3.404 | ppl     30.09
[2022-04-11 03:17:47.128] E023 |   600/2280 batches | lr 0.3125 | loss  3.364 | ppl     28.90
[2022-04-11 03:17:50.670] E023 |   800/2280 batches | lr 0.3125 | loss  3.373 | ppl     29.16
[2022-04-11 03:17:54.248] E023 |  1000/2280 batches | lr 0.3125 | loss  3.362 | ppl     28.84
[2022-04-11 03:17:57.860] E023 |  1200/2280 batches | lr 0.3125 | loss  3.309 | ppl     27.36
[2022-04-11 03:18:01.386] E023 |  1400/2280 batches | lr 0.3125 | loss  3.331 | ppl     27.98
[2022-04-11 03:18:04.921] E023 |  1600/2280 batches | lr 0.3125 | loss  3.304 | ppl     27.22
[2022-04-11 03:18:08.493] E023 |  1800/2280 batches | lr 0.3125 | loss  3.308 | ppl     27.32
[2022-04-11 03:18:12.191] E023 |  2000/2280 batches | lr 0.3125 | loss  3.332 | ppl     27.99
[2022-04-11 03:18:15.703] E023 |  2200/2280 batches | lr 0.3125 | loss  3.317 | ppl     27.58
[2022-04-11 03:18:17.118] E023 |  2280/2280 batches | lr 0.3125 | loss  3.332 | ppl     28.00
[2022-04-11 03:18:23.486] End E023 | valid loss  3.563; ppl     35.29 | accu 0.2933 = 106054/361540
[2022-04-11 03:18:42.882] End E023 |  test loss  4.668; ppl    106.48 | accu 0.1945 = 214651/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:18:46.368] End E023 |  test loss  3.605; ppl     36.80 | accu 0.2884 = 56844/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:18:49.262] End E023 |  test loss  3.519; ppl     33.76 | accu 0.2984 = 49044/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:18:49.263] Epoch 024/40 ==================================================
[2022-04-11 03:18:52.821] E024 |   200/2280 batches | lr 0.1562 | loss  3.368 | ppl     29.02
[2022-04-11 03:18:56.400] E024 |   400/2280 batches | lr 0.1562 | loss  3.409 | ppl     30.25
[2022-04-11 03:18:59.936] E024 |   600/2280 batches | lr 0.1562 | loss  3.362 | ppl     28.86
[2022-04-11 03:19:03.588] E024 |   800/2280 batches | lr 0.1562 | loss  3.370 | ppl     29.07
[2022-04-11 03:19:07.162] E024 |  1000/2280 batches | lr 0.1562 | loss  3.360 | ppl     28.80
[2022-04-11 03:19:10.735] E024 |  1200/2280 batches | lr 0.1562 | loss  3.305 | ppl     27.24
[2022-04-11 03:19:14.277] E024 |  1400/2280 batches | lr 0.1562 | loss  3.326 | ppl     27.83
[2022-04-11 03:19:17.831] E024 |  1600/2280 batches | lr 0.1562 | loss  3.300 | ppl     27.12
[2022-04-11 03:19:21.480] E024 |  1800/2280 batches | lr 0.1562 | loss  3.307 | ppl     27.30
[2022-04-11 03:19:25.054] E024 |  2000/2280 batches | lr 0.1562 | loss  3.326 | ppl     27.84
[2022-04-11 03:19:28.589] E024 |  2200/2280 batches | lr 0.1562 | loss  3.312 | ppl     27.45
[2022-04-11 03:19:30.039] E024 |  2280/2280 batches | lr 0.1562 | loss  3.330 | ppl     27.95
[2022-04-11 03:19:36.524] End E024 | valid loss  3.552; ppl     34.87 | accu 0.2944 = 106435/361540
[2022-04-11 03:19:56.139] End E024 |  test loss  4.664; ppl    106.10 | accu 0.1948 = 214957/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:19:59.634] End E024 |  test loss  3.596; ppl     36.46 | accu 0.2890 = 56961/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:20:02.562] End E024 |  test loss  3.517; ppl     33.70 | accu 0.2988 = 49121/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:20:02.563] Save: model.pt... 
[2022-04-11 03:20:02.575] Save: model.pt...Done. best_val_loss: 3.5516
[2022-04-11 03:20:02.575] Epoch 025/40 ==================================================
[2022-04-11 03:20:06.150] E025 |   200/2280 batches | lr 0.1562 | loss  3.367 | ppl     28.99
[2022-04-11 03:20:09.677] E025 |   400/2280 batches | lr 0.1562 | loss  3.409 | ppl     30.23
[2022-04-11 03:20:13.212] E025 |   600/2280 batches | lr 0.1562 | loss  3.361 | ppl     28.82
[2022-04-11 03:20:16.749] E025 |   800/2280 batches | lr 0.1562 | loss  3.371 | ppl     29.10
[2022-04-11 03:20:20.297] E025 |  1000/2280 batches | lr 0.1562 | loss  3.362 | ppl     28.86
[2022-04-11 03:20:23.830] E025 |  1200/2280 batches | lr 0.1562 | loss  3.304 | ppl     27.22
[2022-04-11 03:20:27.371] E025 |  1400/2280 batches | lr 0.1562 | loss  3.329 | ppl     27.90
[2022-04-11 03:20:30.916] E025 |  1600/2280 batches | lr 0.1562 | loss  3.302 | ppl     27.18
[2022-04-11 03:20:34.548] E025 |  1800/2280 batches | lr 0.1562 | loss  3.305 | ppl     27.24
[2022-04-11 03:20:38.105] E025 |  2000/2280 batches | lr 0.1562 | loss  3.328 | ppl     27.88
[2022-04-11 03:20:41.651] E025 |  2200/2280 batches | lr 0.1562 | loss  3.313 | ppl     27.47
[2022-04-11 03:20:43.052] E025 |  2280/2280 batches | lr 0.1562 | loss  3.330 | ppl     27.95
[2022-04-11 03:20:49.430] End E025 | valid loss  3.547; ppl     34.69 | accu 0.2950 = 106660/361540
[2022-04-11 03:21:08.883] End E025 |  test loss  4.669; ppl    106.61 | accu 0.1947 = 214827/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:21:12.404] End E025 |  test loss  3.594; ppl     36.39 | accu 0.2894 = 57040/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:21:15.319] End E025 |  test loss  3.517; ppl     33.69 | accu 0.2990 = 49147/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:21:15.319] Save: model.pt... 
[2022-04-11 03:21:15.332] Save: model.pt...Done. best_val_loss: 3.5466
[2022-04-11 03:21:15.332] Epoch 026/40 ==================================================
[2022-04-11 03:21:18.978] E026 |   200/2280 batches | lr 0.1562 | loss  3.362 | ppl     28.86
[2022-04-11 03:21:22.705] E026 |   400/2280 batches | lr 0.1562 | loss  3.402 | ppl     30.03
[2022-04-11 03:21:26.243] E026 |   600/2280 batches | lr 0.1562 | loss  3.359 | ppl     28.76
[2022-04-11 03:21:29.800] E026 |   800/2280 batches | lr 0.1562 | loss  3.369 | ppl     29.06
[2022-04-11 03:21:33.385] E026 |  1000/2280 batches | lr 0.1562 | loss  3.357 | ppl     28.71
[2022-04-11 03:21:36.991] E026 |  1200/2280 batches | lr 0.1562 | loss  3.304 | ppl     27.23
[2022-04-11 03:21:40.536] E026 |  1400/2280 batches | lr 0.1562 | loss  3.327 | ppl     27.86
[2022-04-11 03:21:44.096] E026 |  1600/2280 batches | lr 0.1562 | loss  3.300 | ppl     27.12
[2022-04-11 03:21:47.656] E026 |  1800/2280 batches | lr 0.1562 | loss  3.306 | ppl     27.29
[2022-04-11 03:21:51.298] E026 |  2000/2280 batches | lr 0.1562 | loss  3.329 | ppl     27.92
[2022-04-11 03:21:54.874] E026 |  2200/2280 batches | lr 0.1562 | loss  3.313 | ppl     27.46
[2022-04-11 03:21:56.303] E026 |  2280/2280 batches | lr 0.1562 | loss  3.329 | ppl     27.92
[2022-04-11 03:22:02.776] End E026 | valid loss  3.561; ppl     35.20 | accu 0.2936 = 106165/361540
[2022-04-11 03:22:22.556] End E026 |  test loss  4.668; ppl    106.52 | accu 0.1947 = 214880/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:22:26.115] End E026 |  test loss  3.601; ppl     36.62 | accu 0.2887 = 56903/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:22:29.082] End E026 |  test loss  3.517; ppl     33.68 | accu 0.2989 = 49135/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:22:29.083] Epoch 027/40 ==================================================
[2022-04-11 03:22:32.658] E027 |   200/2280 batches | lr 0.0781 | loss  3.366 | ppl     28.97
[2022-04-11 03:22:36.276] E027 |   400/2280 batches | lr 0.0781 | loss  3.407 | ppl     30.16
[2022-04-11 03:22:39.803] E027 |   600/2280 batches | lr 0.0781 | loss  3.361 | ppl     28.81
[2022-04-11 03:22:43.354] E027 |   800/2280 batches | lr 0.0781 | loss  3.368 | ppl     29.03
[2022-04-11 03:22:46.891] E027 |  1000/2280 batches | lr 0.0781 | loss  3.358 | ppl     28.72
[2022-04-11 03:22:50.442] E027 |  1200/2280 batches | lr 0.0781 | loss  3.304 | ppl     27.22
[2022-04-11 03:22:53.964] E027 |  1400/2280 batches | lr 0.0781 | loss  3.326 | ppl     27.83
[2022-04-11 03:22:57.508] E027 |  1600/2280 batches | lr 0.0781 | loss  3.295 | ppl     26.98
[2022-04-11 03:23:01.041] E027 |  1800/2280 batches | lr 0.0781 | loss  3.306 | ppl     27.28
[2022-04-11 03:23:04.574] E027 |  2000/2280 batches | lr 0.0781 | loss  3.326 | ppl     27.83
[2022-04-11 03:23:08.105] E027 |  2200/2280 batches | lr 0.0781 | loss  3.316 | ppl     27.56
[2022-04-11 03:23:09.520] E027 |  2280/2280 batches | lr 0.0781 | loss  3.329 | ppl     27.90
[2022-04-11 03:23:15.947] End E027 | valid loss  3.545; ppl     34.65 | accu 0.2951 = 106701/361540
[2022-04-11 03:23:35.823] End E027 |  test loss  4.665; ppl    106.21 | accu 0.1947 = 214842/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:23:39.421] End E027 |  test loss  3.592; ppl     36.30 | accu 0.2895 = 57061/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:23:42.362] End E027 |  test loss  3.516; ppl     33.65 | accu 0.2991 = 49158/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:23:42.362] Save: model.pt... 
[2022-04-11 03:23:42.375] Save: model.pt...Done. best_val_loss: 3.5453
[2022-04-11 03:23:42.376] Epoch 028/40 ==================================================
[2022-04-11 03:23:46.049] E028 |   200/2280 batches | lr 0.0781 | loss  3.362 | ppl     28.85
[2022-04-11 03:23:49.675] E028 |   400/2280 batches | lr 0.0781 | loss  3.408 | ppl     30.22
[2022-04-11 03:23:53.465] E028 |   600/2280 batches | lr 0.0781 | loss  3.358 | ppl     28.72
[2022-04-11 03:23:57.547] E028 |   800/2280 batches | lr 0.0781 | loss  3.367 | ppl     29.00
[2022-04-11 03:24:01.317] E028 |  1000/2280 batches | lr 0.0781 | loss  3.363 | ppl     28.89
[2022-04-11 03:24:04.957] E028 |  1200/2280 batches | lr 0.0781 | loss  3.302 | ppl     27.16
[2022-04-11 03:24:08.668] E028 |  1400/2280 batches | lr 0.0781 | loss  3.329 | ppl     27.91
[2022-04-11 03:24:12.393] E028 |  1600/2280 batches | lr 0.0781 | loss  3.297 | ppl     27.04
[2022-04-11 03:24:16.072] E028 |  1800/2280 batches | lr 0.0781 | loss  3.308 | ppl     27.32
[2022-04-11 03:24:19.736] E028 |  2000/2280 batches | lr 0.0781 | loss  3.327 | ppl     27.87
[2022-04-11 03:24:23.420] E028 |  2200/2280 batches | lr 0.0781 | loss  3.314 | ppl     27.50
[2022-04-11 03:24:24.968] E028 |  2280/2280 batches | lr 0.0781 | loss  3.335 | ppl     28.07
[2022-04-11 03:24:31.634] End E028 | valid loss  3.545; ppl     34.65 | accu 0.2951 = 106693/361540
[2022-04-11 03:24:51.732] End E028 |  test loss  4.667; ppl    106.33 | accu 0.1948 = 214930/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:24:55.270] End E028 |  test loss  3.593; ppl     36.35 | accu 0.2894 = 57046/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:24:58.207] End E028 |  test loss  3.516; ppl     33.64 | accu 0.2990 = 49150/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:24:58.208] Epoch 029/40 ==================================================
[2022-04-11 03:25:01.837] E029 |   200/2280 batches | lr 0.0391 | loss  3.361 | ppl     28.81
[2022-04-11 03:25:05.455] E029 |   400/2280 batches | lr 0.0391 | loss  3.402 | ppl     30.03
[2022-04-11 03:25:09.024] E029 |   600/2280 batches | lr 0.0391 | loss  3.357 | ppl     28.70
[2022-04-11 03:25:12.614] E029 |   800/2280 batches | lr 0.0391 | loss  3.369 | ppl     29.05
[2022-04-11 03:25:16.184] E029 |  1000/2280 batches | lr 0.0391 | loss  3.357 | ppl     28.69
[2022-04-11 03:25:19.752] E029 |  1200/2280 batches | lr 0.0391 | loss  3.302 | ppl     27.16
[2022-04-11 03:25:23.347] E029 |  1400/2280 batches | lr 0.0391 | loss  3.326 | ppl     27.83
[2022-04-11 03:25:26.967] E029 |  1600/2280 batches | lr 0.0391 | loss  3.296 | ppl     27.01
[2022-04-11 03:25:30.584] E029 |  1800/2280 batches | lr 0.0391 | loss  3.304 | ppl     27.22
[2022-04-11 03:25:34.153] E029 |  2000/2280 batches | lr 0.0391 | loss  3.325 | ppl     27.79
[2022-04-11 03:25:37.796] E029 |  2200/2280 batches | lr 0.0391 | loss  3.311 | ppl     27.40
[2022-04-11 03:25:39.212] E029 |  2280/2280 batches | lr 0.0391 | loss  3.332 | ppl     27.98
[2022-04-11 03:25:45.658] End E029 | valid loss  3.545; ppl     34.63 | accu 0.2951 = 106683/361540
[2022-04-11 03:26:05.275] End E029 |  test loss  4.665; ppl    106.18 | accu 0.1948 = 214943/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:26:08.809] End E029 |  test loss  3.589; ppl     36.21 | accu 0.2898 = 57118/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:26:11.744] End E029 |  test loss  3.515; ppl     33.62 | accu 0.2990 = 49151/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:26:11.745] Save: model.pt... 
[2022-04-11 03:26:11.757] Save: model.pt...Done. best_val_loss: 3.5448
[2022-04-11 03:26:11.757] Epoch 030/40 ==================================================
[2022-04-11 03:26:15.484] E030 |   200/2280 batches | lr 0.0391 | loss  3.361 | ppl     28.82
[2022-04-11 03:26:19.112] E030 |   400/2280 batches | lr 0.0391 | loss  3.406 | ppl     30.16
[2022-04-11 03:26:22.673] E030 |   600/2280 batches | lr 0.0391 | loss  3.360 | ppl     28.79
[2022-04-11 03:26:26.322] E030 |   800/2280 batches | lr 0.0391 | loss  3.366 | ppl     28.98
[2022-04-11 03:26:29.931] E030 |  1000/2280 batches | lr 0.0391 | loss  3.355 | ppl     28.64
[2022-04-11 03:26:33.606] E030 |  1200/2280 batches | lr 0.0391 | loss  3.302 | ppl     27.18
[2022-04-11 03:26:37.212] E030 |  1400/2280 batches | lr 0.0391 | loss  3.324 | ppl     27.76
[2022-04-11 03:26:40.870] E030 |  1600/2280 batches | lr 0.0391 | loss  3.297 | ppl     27.04
[2022-04-11 03:26:44.432] E030 |  1800/2280 batches | lr 0.0391 | loss  3.303 | ppl     27.20
[2022-04-11 03:26:48.024] E030 |  2000/2280 batches | lr 0.0391 | loss  3.325 | ppl     27.79
[2022-04-11 03:26:51.629] E030 |  2200/2280 batches | lr 0.0391 | loss  3.311 | ppl     27.42
[2022-04-11 03:26:53.051] E030 |  2280/2280 batches | lr 0.0391 | loss  3.330 | ppl     27.94
[2022-04-11 03:26:59.509] End E030 | valid loss  3.544; ppl     34.62 | accu 0.2951 = 106680/361540
[2022-04-11 03:27:19.421] End E030 |  test loss  4.665; ppl    106.17 | accu 0.1947 = 214880/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:27:23.007] End E030 |  test loss  3.588; ppl     36.16 | accu 0.2898 = 57122/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:27:25.974] End E030 |  test loss  3.515; ppl     33.62 | accu 0.2990 = 49148/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:27:25.974] Save: model.pt... 
[2022-04-11 03:27:25.992] Save: model.pt...Done. best_val_loss: 3.5444
[2022-04-11 03:27:25.992] Epoch 031/40 ==================================================
[2022-04-11 03:27:29.644] E031 |   200/2280 batches | lr 0.0391 | loss  3.362 | ppl     28.84
[2022-04-11 03:27:33.296] E031 |   400/2280 batches | lr 0.0391 | loss  3.404 | ppl     30.07
[2022-04-11 03:27:36.898] E031 |   600/2280 batches | lr 0.0391 | loss  3.358 | ppl     28.73
[2022-04-11 03:27:40.579] E031 |   800/2280 batches | lr 0.0391 | loss  3.366 | ppl     28.96
[2022-04-11 03:27:44.224] E031 |  1000/2280 batches | lr 0.0391 | loss  3.360 | ppl     28.78
[2022-04-11 03:27:47.824] E031 |  1200/2280 batches | lr 0.0391 | loss  3.304 | ppl     27.22
[2022-04-11 03:27:51.512] E031 |  1400/2280 batches | lr 0.0391 | loss  3.325 | ppl     27.79
[2022-04-11 03:27:55.070] E031 |  1600/2280 batches | lr 0.0391 | loss  3.299 | ppl     27.10
[2022-04-11 03:27:58.871] E031 |  1800/2280 batches | lr 0.0391 | loss  3.303 | ppl     27.18
[2022-04-11 03:28:02.600] E031 |  2000/2280 batches | lr 0.0391 | loss  3.324 | ppl     27.78
[2022-04-11 03:28:06.299] E031 |  2200/2280 batches | lr 0.0391 | loss  3.313 | ppl     27.46
[2022-04-11 03:28:07.768] E031 |  2280/2280 batches | lr 0.0391 | loss  3.331 | ppl     27.98
[2022-04-11 03:28:14.424] End E031 | valid loss  3.544; ppl     34.62 | accu 0.2951 = 106685/361540
[2022-04-11 03:28:34.466] End E031 |  test loss  4.664; ppl    106.01 | accu 0.1948 = 214935/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:28:38.078] End E031 |  test loss  3.588; ppl     36.17 | accu 0.2898 = 57122/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:28:41.058] End E031 |  test loss  3.515; ppl     33.62 | accu 0.2990 = 49142/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:28:41.059] Epoch 032/40 ==================================================
[2022-04-11 03:28:44.879] E032 |   200/2280 batches | lr 0.0195 | loss  3.360 | ppl     28.80
[2022-04-11 03:28:48.616] E032 |   400/2280 batches | lr 0.0195 | loss  3.404 | ppl     30.08
[2022-04-11 03:28:52.446] E032 |   600/2280 batches | lr 0.0195 | loss  3.360 | ppl     28.78
[2022-04-11 03:28:56.254] E032 |   800/2280 batches | lr 0.0195 | loss  3.368 | ppl     29.02
[2022-04-11 03:29:00.040] E032 |  1000/2280 batches | lr 0.0195 | loss  3.356 | ppl     28.68
[2022-04-11 03:29:03.870] E032 |  1200/2280 batches | lr 0.0195 | loss  3.304 | ppl     27.22
[2022-04-11 03:29:07.674] E032 |  1400/2280 batches | lr 0.0195 | loss  3.328 | ppl     27.88
[2022-04-11 03:29:11.458] E032 |  1600/2280 batches | lr 0.0195 | loss  3.297 | ppl     27.03
[2022-04-11 03:29:15.223] E032 |  1800/2280 batches | lr 0.0195 | loss  3.304 | ppl     27.22
[2022-04-11 03:29:18.938] E032 |  2000/2280 batches | lr 0.0195 | loss  3.323 | ppl     27.73
[2022-04-11 03:29:22.802] E032 |  2200/2280 batches | lr 0.0195 | loss  3.314 | ppl     27.49
[2022-04-11 03:29:24.412] E032 |  2280/2280 batches | lr 0.0195 | loss  3.327 | ppl     27.86
[2022-04-11 03:29:31.188] End E032 | valid loss  3.544; ppl     34.60 | accu 0.2951 = 106707/361540
[2022-04-11 03:29:51.861] End E032 |  test loss  4.662; ppl    105.81 | accu 0.1948 = 214961/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:29:55.475] End E032 |  test loss  3.587; ppl     36.13 | accu 0.2899 = 57153/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:29:58.480] End E032 |  test loss  3.515; ppl     33.61 | accu 0.2989 = 49138/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:29:58.481] Save: model.pt... 
[2022-04-11 03:29:58.493] Save: model.pt...Done. best_val_loss: 3.5438
[2022-04-11 03:29:58.494] Epoch 033/40 ==================================================
[2022-04-11 03:30:02.356] E033 |   200/2280 batches | lr 0.0195 | loss  3.364 | ppl     28.90
[2022-04-11 03:30:06.158] E033 |   400/2280 batches | lr 0.0195 | loss  3.401 | ppl     29.98
[2022-04-11 03:30:10.105] E033 |   600/2280 batches | lr 0.0195 | loss  3.359 | ppl     28.75
[2022-04-11 03:30:13.879] E033 |   800/2280 batches | lr 0.0195 | loss  3.369 | ppl     29.04
[2022-04-11 03:30:17.753] E033 |  1000/2280 batches | lr 0.0195 | loss  3.359 | ppl     28.76
[2022-04-11 03:30:21.486] E033 |  1200/2280 batches | lr 0.0195 | loss  3.299 | ppl     27.08
[2022-04-11 03:30:25.225] E033 |  1400/2280 batches | lr 0.0195 | loss  3.326 | ppl     27.82
[2022-04-11 03:30:28.953] E033 |  1600/2280 batches | lr 0.0195 | loss  3.298 | ppl     27.07
[2022-04-11 03:30:32.640] E033 |  1800/2280 batches | lr 0.0195 | loss  3.302 | ppl     27.18
[2022-04-11 03:30:36.417] E033 |  2000/2280 batches | lr 0.0195 | loss  3.324 | ppl     27.78
[2022-04-11 03:30:40.302] E033 |  2200/2280 batches | lr 0.0195 | loss  3.313 | ppl     27.47
[2022-04-11 03:30:41.837] E033 |  2280/2280 batches | lr 0.0195 | loss  3.326 | ppl     27.83
[2022-04-11 03:30:48.516] End E033 | valid loss  3.544; ppl     34.60 | accu 0.2952 = 106715/361540
[2022-04-11 03:31:08.778] End E033 |  test loss  4.664; ppl    106.02 | accu 0.1947 = 214874/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:31:12.373] End E033 |  test loss  3.586; ppl     36.11 | accu 0.2899 = 57149/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:31:15.375] End E033 |  test loss  3.515; ppl     33.61 | accu 0.2991 = 49165/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:31:15.375] Save: model.pt... 
[2022-04-11 03:31:15.388] Save: model.pt...Done. best_val_loss: 3.5437
[2022-04-11 03:31:15.388] Epoch 034/40 ==================================================
[2022-04-11 03:31:19.086] E034 |   200/2280 batches | lr 0.0195 | loss  3.361 | ppl     28.83
[2022-04-11 03:31:23.081] E034 |   400/2280 batches | lr 0.0195 | loss  3.402 | ppl     30.04
[2022-04-11 03:31:26.931] E034 |   600/2280 batches | lr 0.0195 | loss  3.360 | ppl     28.80
[2022-04-11 03:31:30.444] E034 |   800/2280 batches | lr 0.0195 | loss  3.366 | ppl     28.96
[2022-04-11 03:31:33.970] E034 |  1000/2280 batches | lr 0.0195 | loss  3.359 | ppl     28.75
[2022-04-11 03:31:37.481] E034 |  1200/2280 batches | lr 0.0195 | loss  3.302 | ppl     27.18
[2022-04-11 03:31:41.206] E034 |  1400/2280 batches | lr 0.0195 | loss  3.325 | ppl     27.79
[2022-04-11 03:31:44.879] E034 |  1600/2280 batches | lr 0.0195 | loss  3.296 | ppl     27.02
[2022-04-11 03:31:48.543] E034 |  1800/2280 batches | lr 0.0195 | loss  3.303 | ppl     27.19
[2022-04-11 03:31:52.192] E034 |  2000/2280 batches | lr 0.0195 | loss  3.322 | ppl     27.71
[2022-04-11 03:31:55.832] E034 |  2200/2280 batches | lr 0.0195 | loss  3.311 | ppl     27.41
[2022-04-11 03:31:57.293] E034 |  2280/2280 batches | lr 0.0195 | loss  3.327 | ppl     27.85
[2022-04-11 03:32:03.950] End E034 | valid loss  3.544; ppl     34.60 | accu 0.2951 = 106681/361540
[2022-04-11 03:32:24.145] End E034 |  test loss  4.662; ppl    105.82 | accu 0.1948 = 214954/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:32:27.729] End E034 |  test loss  3.587; ppl     36.12 | accu 0.2898 = 57127/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:32:30.699] End E034 |  test loss  3.515; ppl     33.60 | accu 0.2990 = 49143/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:32:30.699] Epoch 035/40 ==================================================
[2022-04-11 03:32:34.363] E035 |   200/2280 batches | lr 0.0098 | loss  3.362 | ppl     28.83
[2022-04-11 03:32:38.066] E035 |   400/2280 batches | lr 0.0098 | loss  3.403 | ppl     30.06
[2022-04-11 03:32:41.882] E035 |   600/2280 batches | lr 0.0098 | loss  3.358 | ppl     28.72
[2022-04-11 03:32:45.644] E035 |   800/2280 batches | lr 0.0098 | loss  3.366 | ppl     28.97
[2022-04-11 03:32:49.302] E035 |  1000/2280 batches | lr 0.0098 | loss  3.356 | ppl     28.67
[2022-04-11 03:32:52.994] E035 |  1200/2280 batches | lr 0.0098 | loss  3.302 | ppl     27.16
[2022-04-11 03:32:56.697] E035 |  1400/2280 batches | lr 0.0098 | loss  3.325 | ppl     27.80
[2022-04-11 03:33:00.354] E035 |  1600/2280 batches | lr 0.0098 | loss  3.294 | ppl     26.94
[2022-04-11 03:33:04.049] E035 |  1800/2280 batches | lr 0.0098 | loss  3.302 | ppl     27.17
[2022-04-11 03:33:07.756] E035 |  2000/2280 batches | lr 0.0098 | loss  3.321 | ppl     27.70
[2022-04-11 03:33:11.391] E035 |  2200/2280 batches | lr 0.0098 | loss  3.309 | ppl     27.37
[2022-04-11 03:33:12.865] E035 |  2280/2280 batches | lr 0.0098 | loss  3.326 | ppl     27.82
[2022-04-11 03:33:19.474] End E035 | valid loss  3.544; ppl     34.59 | accu 0.2951 = 106707/361540
[2022-04-11 03:33:40.450] End E035 |  test loss  4.661; ppl    105.74 | accu 0.1948 = 214996/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:33:44.076] End E035 |  test loss  3.586; ppl     36.10 | accu 0.2899 = 57147/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:33:47.082] End E035 |  test loss  3.514; ppl     33.60 | accu 0.2990 = 49154/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:33:47.082] Save: model.pt... 
[2022-04-11 03:33:47.096] Save: model.pt...Done. best_val_loss: 3.5435
[2022-04-11 03:33:47.096] Epoch 036/40 ==================================================
[2022-04-11 03:33:50.722] E036 |   200/2280 batches | lr 0.0098 | loss  3.363 | ppl     28.89
[2022-04-11 03:33:54.356] E036 |   400/2280 batches | lr 0.0098 | loss  3.403 | ppl     30.05
[2022-04-11 03:33:57.975] E036 |   600/2280 batches | lr 0.0098 | loss  3.356 | ppl     28.68
[2022-04-11 03:34:01.657] E036 |   800/2280 batches | lr 0.0098 | loss  3.367 | ppl     29.00
[2022-04-11 03:34:05.350] E036 |  1000/2280 batches | lr 0.0098 | loss  3.360 | ppl     28.78
[2022-04-11 03:34:08.879] E036 |  1200/2280 batches | lr 0.0098 | loss  3.300 | ppl     27.12
[2022-04-11 03:34:12.592] E036 |  1400/2280 batches | lr 0.0098 | loss  3.323 | ppl     27.75
[2022-04-11 03:34:16.282] E036 |  1600/2280 batches | lr 0.0098 | loss  3.295 | ppl     26.97
[2022-04-11 03:34:19.986] E036 |  1800/2280 batches | lr 0.0098 | loss  3.301 | ppl     27.14
[2022-04-11 03:34:23.633] E036 |  2000/2280 batches | lr 0.0098 | loss  3.325 | ppl     27.81
[2022-04-11 03:34:27.420] E036 |  2200/2280 batches | lr 0.0098 | loss  3.309 | ppl     27.37
[2022-04-11 03:34:28.837] E036 |  2280/2280 batches | lr 0.0098 | loss  3.331 | ppl     27.98
[2022-04-11 03:34:35.262] End E036 | valid loss  3.544; ppl     34.59 | accu 0.2951 = 106706/361540
[2022-04-11 03:34:56.380] End E036 |  test loss  4.662; ppl    105.80 | accu 0.1948 = 214931/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:34:59.898] End E036 |  test loss  3.586; ppl     36.09 | accu 0.2899 = 57147/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:35:02.945] End E036 |  test loss  3.515; ppl     33.60 | accu 0.2990 = 49157/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:35:02.946] Epoch 037/40 ==================================================
[2022-04-11 03:35:06.635] E037 |   200/2280 batches | lr 0.0049 | loss  3.362 | ppl     28.85
[2022-04-11 03:35:10.241] E037 |   400/2280 batches | lr 0.0049 | loss  3.402 | ppl     30.04
[2022-04-11 03:35:13.878] E037 |   600/2280 batches | lr 0.0049 | loss  3.359 | ppl     28.76
[2022-04-11 03:35:17.541] E037 |   800/2280 batches | lr 0.0049 | loss  3.366 | ppl     28.96
[2022-04-11 03:35:21.132] E037 |  1000/2280 batches | lr 0.0049 | loss  3.358 | ppl     28.73
[2022-04-11 03:35:24.706] E037 |  1200/2280 batches | lr 0.0049 | loss  3.300 | ppl     27.13
[2022-04-11 03:35:28.371] E037 |  1400/2280 batches | lr 0.0049 | loss  3.324 | ppl     27.77
[2022-04-11 03:35:32.078] E037 |  1600/2280 batches | lr 0.0049 | loss  3.292 | ppl     26.90
[2022-04-11 03:35:35.884] E037 |  1800/2280 batches | lr 0.0049 | loss  3.302 | ppl     27.18
[2022-04-11 03:35:39.705] E037 |  2000/2280 batches | lr 0.0049 | loss  3.323 | ppl     27.74
[2022-04-11 03:35:43.540] E037 |  2200/2280 batches | lr 0.0049 | loss  3.311 | ppl     27.41
[2022-04-11 03:35:44.982] E037 |  2280/2280 batches | lr 0.0049 | loss  3.328 | ppl     27.89
[2022-04-11 03:35:51.612] End E037 | valid loss  3.543; ppl     34.59 | accu 0.2951 = 106708/361540
[2022-04-11 03:36:11.723] End E037 |  test loss  4.662; ppl    105.80 | accu 0.1948 = 214957/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:36:15.358] End E037 |  test loss  3.586; ppl     36.09 | accu 0.2899 = 57143/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:36:18.382] End E037 |  test loss  3.514; ppl     33.60 | accu 0.2990 = 49155/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:36:18.383] Save: model.pt... 
[2022-04-11 03:36:18.395] Save: model.pt...Done. best_val_loss: 3.5435
[2022-04-11 03:36:18.395] Epoch 038/40 ==================================================
[2022-04-11 03:36:22.324] E038 |   200/2280 batches | lr 0.0049 | loss  3.361 | ppl     28.81
[2022-04-11 03:36:26.157] E038 |   400/2280 batches | lr 0.0049 | loss  3.403 | ppl     30.05
[2022-04-11 03:36:29.911] E038 |   600/2280 batches | lr 0.0049 | loss  3.357 | ppl     28.70
[2022-04-11 03:36:33.590] E038 |   800/2280 batches | lr 0.0049 | loss  3.368 | ppl     29.01
[2022-04-11 03:36:37.249] E038 |  1000/2280 batches | lr 0.0049 | loss  3.355 | ppl     28.64
[2022-04-11 03:36:40.934] E038 |  1200/2280 batches | lr 0.0049 | loss  3.301 | ppl     27.13
[2022-04-11 03:36:44.636] E038 |  1400/2280 batches | lr 0.0049 | loss  3.322 | ppl     27.71
[2022-04-11 03:36:48.442] E038 |  1600/2280 batches | lr 0.0049 | loss  3.294 | ppl     26.96
[2022-04-11 03:36:52.075] E038 |  1800/2280 batches | lr 0.0049 | loss  3.307 | ppl     27.30
[2022-04-11 03:36:55.709] E038 |  2000/2280 batches | lr 0.0049 | loss  3.323 | ppl     27.74
[2022-04-11 03:36:59.254] E038 |  2200/2280 batches | lr 0.0049 | loss  3.308 | ppl     27.32
[2022-04-11 03:37:00.686] E038 |  2280/2280 batches | lr 0.0049 | loss  3.327 | ppl     27.84
[2022-04-11 03:37:07.538] End E038 | valid loss  3.543; ppl     34.59 | accu 0.2951 = 106692/361540
[2022-04-11 03:37:28.243] End E038 |  test loss  4.661; ppl    105.72 | accu 0.1948 = 214984/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:37:31.852] End E038 |  test loss  3.586; ppl     36.08 | accu 0.2898 = 57133/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:37:34.811] End E038 |  test loss  3.514; ppl     33.60 | accu 0.2990 = 49150/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:37:34.812] Save: model.pt... 
[2022-04-11 03:37:34.824] Save: model.pt...Done. best_val_loss: 3.5434
[2022-04-11 03:37:34.824] Epoch 039/40 ==================================================
[2022-04-11 03:37:38.457] E039 |   200/2280 batches | lr 0.0049 | loss  3.361 | ppl     28.81
[2022-04-11 03:37:42.318] E039 |   400/2280 batches | lr 0.0049 | loss  3.402 | ppl     30.02
[2022-04-11 03:37:46.045] E039 |   600/2280 batches | lr 0.0049 | loss  3.359 | ppl     28.77
[2022-04-11 03:37:49.857] E039 |   800/2280 batches | lr 0.0049 | loss  3.369 | ppl     29.04
[2022-04-11 03:37:53.422] E039 |  1000/2280 batches | lr 0.0049 | loss  3.357 | ppl     28.71
[2022-04-11 03:37:57.115] E039 |  1200/2280 batches | lr 0.0049 | loss  3.302 | ppl     27.18
[2022-04-11 03:38:00.761] E039 |  1400/2280 batches | lr 0.0049 | loss  3.327 | ppl     27.84
[2022-04-11 03:38:04.281] E039 |  1600/2280 batches | lr 0.0049 | loss  3.298 | ppl     27.05
[2022-04-11 03:38:07.934] E039 |  1800/2280 batches | lr 0.0049 | loss  3.301 | ppl     27.14
[2022-04-11 03:38:11.540] E039 |  2000/2280 batches | lr 0.0049 | loss  3.325 | ppl     27.81
[2022-04-11 03:38:15.169] E039 |  2200/2280 batches | lr 0.0049 | loss  3.313 | ppl     27.46
[2022-04-11 03:38:16.625] E039 |  2280/2280 batches | lr 0.0049 | loss  3.330 | ppl     27.94
[2022-04-11 03:38:23.187] End E039 | valid loss  3.543; ppl     34.58 | accu 0.2951 = 106702/361540
[2022-04-11 03:38:44.418] End E039 |  test loss  4.661; ppl    105.71 | accu 0.1948 = 214953/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:38:48.031] End E039 |  test loss  3.586; ppl     36.07 | accu 0.2899 = 57140/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:38:50.992] End E039 |  test loss  3.514; ppl     33.60 | accu 0.2990 = 49150/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:38:50.993] Save: model.pt... 
[2022-04-11 03:38:51.005] Save: model.pt...Done. best_val_loss: 3.5434
[2022-04-11 03:38:51.005] Epoch 040/40 ==================================================
[2022-04-11 03:38:54.577] E040 |   200/2280 batches | lr 0.0049 | loss  3.360 | ppl     28.78
[2022-04-11 03:38:58.241] E040 |   400/2280 batches | lr 0.0049 | loss  3.401 | ppl     30.01
[2022-04-11 03:39:01.966] E040 |   600/2280 batches | lr 0.0049 | loss  3.360 | ppl     28.78
[2022-04-11 03:39:05.522] E040 |   800/2280 batches | lr 0.0049 | loss  3.370 | ppl     29.08
[2022-04-11 03:39:09.115] E040 |  1000/2280 batches | lr 0.0049 | loss  3.360 | ppl     28.77
[2022-04-11 03:39:13.109] E040 |  1200/2280 batches | lr 0.0049 | loss  3.304 | ppl     27.21
[2022-04-11 03:39:17.164] E040 |  1400/2280 batches | lr 0.0049 | loss  3.323 | ppl     27.75
[2022-04-11 03:39:20.949] E040 |  1600/2280 batches | lr 0.0049 | loss  3.293 | ppl     26.93
[2022-04-11 03:39:24.607] E040 |  1800/2280 batches | lr 0.0049 | loss  3.301 | ppl     27.15
[2022-04-11 03:39:28.396] E040 |  2000/2280 batches | lr 0.0049 | loss  3.323 | ppl     27.74
[2022-04-11 03:39:32.113] E040 |  2200/2280 batches | lr 0.0049 | loss  3.309 | ppl     27.36
[2022-04-11 03:39:33.620] E040 |  2280/2280 batches | lr 0.0049 | loss  3.325 | ppl     27.80
[2022-04-11 03:39:40.127] End E040 | valid loss  3.543; ppl     34.58 | accu 0.2951 = 106707/361540
[2022-04-11 03:39:59.849] End E040 |  test loss  4.661; ppl    105.74 | accu 0.1948 = 214951/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:40:03.422] End E040 |  test loss  3.585; ppl     36.07 | accu 0.2899 = 57148/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:40:06.436] End E040 |  test loss  3.514; ppl     33.60 | accu 0.2990 = 49148/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:40:06.437] Save: model.pt... 
[2022-04-11 03:40:06.450] Save: model.pt...Done. best_val_loss: 3.5433
[2022-04-11 03:40:26.390] End. test loss  4.66; ppl   105.74 | accu 0.1948 = 214951/1103580 ../data/sample_500k/adult_test.txt
[2022-04-11 03:40:30.459] End. test loss  3.59; ppl    36.07 | accu 0.2899 = 57148/197120 ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:40:33.642] End. test loss  3.51; ppl    33.60 | accu 0.2990 = 49148/164380 ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:40:33.643] =========================================================================================
[2022-04-11 03:40:33.643] valid_loss
[2022-04-11 03:40:33.643]  4.42, 4.20, 3.93, 3.95, 3.87, 3.81, 3.70, 3.69, 3.77, 3.66, 3.71, 3.69, 3.66, 3.62, 3.58, 3.65, 3.57, 3.60, 3.57, 3.56, 3.56, 3.56, 3.56, 3.55, 3.55, 3.56, 3.55, 3.55, 3.54, 3.54, 3.54, 3.54, 3.54, 3.54, 3.54, 3.54, 3.54, 3.54, 3.54, 3.54
[2022-04-11 03:40:33.643] valid_loss ppl
[2022-04-11 03:40:33.643]    83.22,   66.75,   50.84,   51.77,   47.72,   45.30,   40.32,   39.98,   43.30,   39.00,   40.66,   39.94,   38.91,   37.15,   35.78,   38.33,   35.60,   36.77,   35.37,   35.34,   35.32,   35.28,   35.29,   34.87,   34.69,   35.20,   34.65,   34.65,   34.63,   34.62,   34.62,   34.60,   34.60,   34.60,   34.59,   34.59,   34.59,   34.59,   34.58,   34.58
[2022-04-11 03:40:33.644] test_loss of ../data/sample_500k/adult_test.txt
[2022-04-11 03:40:33.644]  7.05, 5.96, 4.89, 5.61, 5.58, 4.79, 4.74, 4.70, 4.73, 4.68, 4.68, 4.67, 4.67, 4.68, 4.67, 4.66, 4.67, 4.67, 4.67, 4.67, 4.67, 4.67, 4.67, 4.66, 4.67, 4.67, 4.67, 4.67, 4.67, 4.67, 4.66, 4.66, 4.66, 4.66, 4.66, 4.66, 4.66, 4.66, 4.66, 4.66
[2022-04-11 03:40:33.644] test_loss of ../data/sample_500k/adult_test.txt ppl
[2022-04-11 03:40:33.644]  1153.44,  389.10,  133.58,  272.43,  265.40,  119.72,  114.17,  109.47,  112.85,  107.74,  107.71,  106.40,  107.19,  107.71,  107.13,  105.87,  106.76,  106.63,  106.73,  106.45,  106.40,  106.55,  106.48,  106.10,  106.61,  106.52,  106.21,  106.33,  106.18,  106.17,  106.01,  105.81,  106.02,  105.82,  105.74,  105.80,  105.80,  105.72,  105.71,  105.74
[2022-04-11 03:40:33.644] test_loss of ../data/sample_500k/adolescent_valid.txt
[2022-04-11 03:40:33.644]  4.34, 3.97, 3.97, 4.06, 4.01, 3.96, 3.75, 3.74, 3.99, 3.81, 3.95, 3.94, 3.83, 3.82, 3.77, 3.81, 3.76, 3.80, 3.64, 3.64, 3.64, 3.60, 3.61, 3.60, 3.59, 3.60, 3.59, 3.59, 3.59, 3.59, 3.59, 3.59, 3.59, 3.59, 3.59, 3.59, 3.59, 3.59, 3.59, 3.59
[2022-04-11 03:40:33.644] test_loss of ../data/sample_500k/adolescent_valid.txt ppl
[2022-04-11 03:40:33.644]    76.63,   53.17,   53.10,   58.08,   55.05,   52.69,   42.71,   41.89,   54.12,   44.96,   51.87,   51.64,   46.19,   45.65,   43.47,   45.24,   43.16,   44.84,   38.09,   38.01,   38.01,   36.72,   36.80,   36.46,   36.39,   36.62,   36.30,   36.35,   36.21,   36.16,   36.17,   36.13,   36.11,   36.12,   36.10,   36.09,   36.09,   36.08,   36.07,   36.07
[2022-04-11 03:40:33.644] test_loss of ../data/sample_500k/cbt_valid.txt
[2022-04-11 03:40:33.644]  4.61, 4.58, 3.94, 3.81, 3.72, 3.67, 3.66, 3.64, 3.64, 3.58, 3.57, 3.55, 3.54, 3.54, 3.53, 3.53, 3.53, 3.52, 3.52, 3.52, 3.52, 3.52, 3.52, 3.52, 3.52, 3.52, 3.52, 3.52, 3.52, 3.52, 3.52, 3.51, 3.51, 3.51, 3.51, 3.51, 3.51, 3.51, 3.51, 3.51
[2022-04-11 03:40:33.644] test_loss of ../data/sample_500k/cbt_valid.txt ppl
[2022-04-11 03:40:33.645]   100.81,   97.87,   51.19,   45.26,   41.35,   39.32,   38.95,   38.09,   37.93,   36.04,   35.62,   34.78,   34.44,   34.30,   34.19,   34.14,   33.99,   33.94,   33.84,   33.82,   33.80,   33.78,   33.76,   33.70,   33.69,   33.68,   33.65,   33.64,   33.62,   33.62,   33.62,   33.61,   33.61,   33.60,   33.60,   33.60,   33.60,   33.60,   33.60,   33.60
