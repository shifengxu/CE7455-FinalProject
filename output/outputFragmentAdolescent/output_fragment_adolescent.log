[2022-04-13 12:12:22.920] args: Namespace(batch_size=20, bptt=35, clip=0.25, data_dir='../data/sample_500k', dropout=0.2, emsize=200, epochs=20, fragment_aggregate_mode_list=['CNN', 'LSTM'], gpu_ids=[2], log_interval=200, lr=20.0, model='LSTM', nhead=2, nhid=200, nlayers=2, save='model.pt', seed=1111, subword_vocab_size=0, test_file_list=['cbt_valid.txt', 'adult_test.txt'], tied=False, train_file_list=['adolescent_train.txt'], valid_file_list=['adolescent_valid.txt'], word_split_mode_list=['Subword.200', 'Subword.500', 'Subword.1000', 'Subword.2000', 'Subword.5000', 'Subword.10000'])
[2022-04-13 12:12:22.920] device: cuda:2
Log file: ./output_wsm_Subword.200_fam_CNN.log open...
[2022-04-13 12:12:22.921] corpus.train_file_list: 1
[2022-04-13 12:12:22.921]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 12:12:22.921] corpus.valid_file_list: 1
[2022-04-13 12:12:22.921]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 12:12:22.921] corpus.test_file_list: 2
[2022-04-13 12:12:22.921]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:12:22.921]         ../data/sample_500k/adult_test.txt
[2022-04-13 12:12:22.921] corpus.subword_vocab_size: 0
[2022-04-13 12:12:22.921] corpus.subword_model = None. Corpus will not use subword.
[2022-04-13 12:12:22.921] corpus tokenize...
[2022-04-13 12:12:23.951]         train tokens: 467267  ../data/sample_500k/adolescent_train.txt
[2022-04-13 12:12:24.174]         valid tokens: 112256  ../data/sample_500k/adolescent_valid.txt
[2022-04-13 12:12:24.319]         test  tokens: 115417  ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:12:24.985]         test  tokens: 506878  ../data/sample_500k/adult_test.txt
[2022-04-13 12:12:24.986] corpus.ntokens      : 95521
[2022-04-13 12:12:24.986] corpus.char_count   : 166
[2022-04-13 12:12:24.986] corpus.char_cnt_dict: 166
[2022-04-13 12:12:24.986] corpus.char_id_dict : 166
[2022-04-13 12:12:24.996] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 12:12:24.997]         tokens_all: 467267
[2022-04-13 12:12:24.997]         batched   :  23363
[2022-04-13 12:12:24.997]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 12:12:26.708] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 12:12:26.709]         tokens_all: 112256
[2022-04-13 12:12:26.709]         batched   :   5612
[2022-04-13 12:12:26.709]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 12:12:26.711] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 12:12:26.711]         tokens_all: 115417
[2022-04-13 12:12:26.711]         batched   :   5770
[2022-04-13 12:12:26.711]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:12:26.717] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 12:12:26.717]         tokens_all: 506878
[2022-04-13 12:12:26.717]         batched   :  25343
[2022-04-13 12:12:26.717]         ../data/sample_500k/adult_test.txt
[2022-04-13 12:12:26.718] subword_adapter will be generated due to word_split_mode='Subword.200'
[2022-04-13 12:12:26.718] SubwordAdapter.file_list: 2
[2022-04-13 12:12:26.718]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 12:12:26.718]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 12:12:26.718] SubwordAdapter.subword_vocab_size: 200
[2022-04-13 12:12:26.718] SubwordAdapter.subword_model.train(2 files)...
[2022-04-13 12:12:27.074] SubwordAdapter.subword_model.train(2 files)...Done
[2022-04-13 12:12:27.790] RNNModel.rnn_type: LSTM
[2022-04-13 12:12:27.791] RNNModel.ntoken  : 95521
[2022-04-13 12:12:27.791] RNNModel.ninp    : 200
[2022-04-13 12:12:27.791] RNNModel.nhid    : 200
[2022-04-13 12:12:27.791] RNNModel.nlayers : 2
[2022-04-13 12:12:27.791] RNNModel.dropout : 0.2
[2022-04-13 12:12:27.791] RNNModel.tie_weights: False
[2022-04-13 12:12:27.791] RNNModel.fragment_aggregate_mode: CNN
[2022-04-13 12:12:27.791] RNNModel.fragment_cnt           : 202
[2022-04-13 12:12:27.791] RNNModel.fragment_emsize        : 25
[2022-04-13 12:12:27.791] RNNModel.fragment_nhid          : 200
[2022-04-13 12:12:27.792] RNNModel.fragment_embeds     : created
[2022-04-13 12:12:27.792] RNNModel.fragment_cnn3       : created
[2022-04-13 12:12:27.978] Epoch 001/20 ==================================================
[2022-04-13 12:12:45.951] E001 |   200/667 batches | lr 20.0000 | loss  8.554 | ppl   5187.17 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:13:03.738] E001 |   400/667 batches | lr 20.0000 | loss  7.682 | ppl   2167.89 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:13:21.594] E001 |   600/667 batches | lr 20.0000 | loss  7.075 | ppl   1182.59 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:13:27.606] E001 |   667/667 batches | lr 20.0000 | loss  6.751 | ppl    855.06 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:13:33.561] End E001 | valid loss  6.747; ppl    851.75 | accu 0.1434 = 16088/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:13:39.345] End E001 |  test loss  7.282; ppl   1454.35 | accu 0.1027 = 11851/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:14:05.525] End E001 |  test loss  8.304; ppl   4039.95 | accu 0.0614 = 31139/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:14:05.525] Save: model.pt... 
[2022-04-13 12:14:06.116] Save: model.pt...Done. best_val_loss: 6.7473
[2022-04-13 12:14:06.116] Epoch 002/20 ==================================================
[2022-04-13 12:14:23.754] E002 |   200/667 batches | lr 20.0000 | loss  6.580 | ppl    720.39 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:14:41.599] E002 |   400/667 batches | lr 20.0000 | loss  6.424 | ppl    616.68 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:14:59.596] E002 |   600/667 batches | lr 20.0000 | loss  6.213 | ppl    499.22 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:15:05.565] E002 |   667/667 batches | lr 20.0000 | loss  6.092 | ppl    442.15 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:15:11.462] End E002 | valid loss  6.213; ppl    499.30 | accu 0.1989 = 22325/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:15:17.243] End E002 |  test loss  8.068; ppl   3189.37 | accu 0.0672 = 7757/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:15:43.431] End E002 |  test loss 10.047; ppl  23095.95 | accu 0.0054 = 2728/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:15:43.431] Save: model.pt... 
[2022-04-13 12:15:44.008] Save: model.pt...Done. best_val_loss: 6.2132
[2022-04-13 12:15:44.008] Epoch 003/20 ==================================================
[2022-04-13 12:16:01.863] E003 |   200/667 batches | lr 20.0000 | loss  6.048 | ppl    423.30 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:16:19.866] E003 |   400/667 batches | lr 20.0000 | loss  6.001 | ppl    403.71 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:16:38.064] E003 |   600/667 batches | lr 20.0000 | loss  5.876 | ppl    356.43 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:16:44.126] E003 |   667/667 batches | lr 20.0000 | loss  5.776 | ppl    322.56 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:16:50.033] End E003 | valid loss  6.063; ppl    429.85 | accu 0.1975 = 22159/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:16:55.855] End E003 |  test loss  7.541; ppl   1882.98 | accu 0.0704 = 8117/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:17:22.140] End E003 |  test loss  9.268; ppl  10593.75 | accu 0.0075 = 3809/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:17:22.140] Save: model.pt... 
[2022-04-13 12:17:22.716] Save: model.pt...Done. best_val_loss: 6.0634
[2022-04-13 12:17:22.716] Epoch 004/20 ==================================================
[2022-04-13 12:17:40.465] E004 |   200/667 batches | lr 20.0000 | loss  5.769 | ppl    320.26 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:17:58.508] E004 |   400/667 batches | lr 20.0000 | loss  5.748 | ppl    313.62 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:18:16.478] E004 |   600/667 batches | lr 20.0000 | loss  5.649 | ppl    283.92 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:18:22.496] E004 |   667/667 batches | lr 20.0000 | loss  5.563 | ppl    260.54 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:18:28.399] End E004 | valid loss  6.020; ppl    411.58 | accu 0.2081 = 23351/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:18:34.181] End E004 |  test loss  8.217; ppl   3702.25 | accu 0.0664 = 7664/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:19:00.545] End E004 |  test loss  9.625; ppl  15140.77 | accu 0.0064 = 3250/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:19:00.545] Save: model.pt... 
[2022-04-13 12:19:01.127] Save: model.pt...Done. best_val_loss: 6.0200
[2022-04-13 12:19:01.127] Epoch 005/20 ==================================================
[2022-04-13 12:19:19.117] E005 |   200/667 batches | lr 20.0000 | loss  5.552 | ppl    257.86 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:19:37.222] E005 |   400/667 batches | lr 20.0000 | loss  5.559 | ppl    259.65 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:19:55.191] E005 |   600/667 batches | lr 20.0000 | loss  5.468 | ppl    237.07 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:20:01.100] E005 |   667/667 batches | lr 20.0000 | loss  5.388 | ppl    218.67 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:20:07.039] End E005 | valid loss  6.026; ppl    413.90 | accu 0.2061 = 23130/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:20:12.844] End E005 |  test loss  8.643; ppl   5668.63 | accu 0.0675 = 7792/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:20:39.273] End E005 |  test loss 10.903; ppl  54344.33 | accu 0.0050 = 2535/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:20:39.273] Epoch 006/20 ==================================================
[2022-04-13 12:20:57.148] E006 |   200/667 batches | lr 10.0000 | loss  5.291 | ppl    198.50 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:21:15.142] E006 |   400/667 batches | lr 10.0000 | loss  5.252 | ppl    191.00 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:21:33.091] E006 |   600/667 batches | lr 10.0000 | loss  5.145 | ppl    171.63 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:21:39.114] E006 |   667/667 batches | lr 10.0000 | loss  5.062 | ppl    157.88 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:21:45.031] End E006 | valid loss  5.888; ppl    360.79 | accu 0.2187 = 24548/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:21:50.872] End E006 |  test loss  8.176; ppl   3553.98 | accu 0.0709 = 8184/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:22:17.296] End E006 |  test loss  9.023; ppl   8292.62 | accu 0.0074 = 3749/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:22:17.297] Save: model.pt... 
[2022-04-13 12:22:17.899] Save: model.pt...Done. best_val_loss: 5.8883
[2022-04-13 12:22:17.899] Epoch 007/20 ==================================================
[2022-04-13 12:22:35.767] E007 |   200/667 batches | lr 10.0000 | loss  5.143 | ppl    171.22 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:22:53.857] E007 |   400/667 batches | lr 10.0000 | loss  5.129 | ppl    168.87 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:23:11.924] E007 |   600/667 batches | lr 10.0000 | loss  5.043 | ppl    154.91 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:23:17.958] E007 |   667/667 batches | lr 10.0000 | loss  4.969 | ppl    143.86 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:23:23.878] End E007 | valid loss  5.891; ppl    361.61 | accu 0.2181 = 24476/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:23:29.675] End E007 |  test loss  8.542; ppl   5127.31 | accu 0.0711 = 8198/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:23:56.023] End E007 |  test loss  9.145; ppl   9371.50 | accu 0.0072 = 3624/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:23:56.023] Epoch 008/20 ==================================================
[2022-04-13 12:24:13.715] E008 |   200/667 batches | lr 5.0000 | loss  5.002 | ppl    148.68 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:24:31.685] E008 |   400/667 batches | lr 5.0000 | loss  4.970 | ppl    143.97 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:24:49.649] E008 |   600/667 batches | lr 5.0000 | loss  4.867 | ppl    129.87 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:24:55.682] E008 |   667/667 batches | lr 5.0000 | loss  4.776 | ppl    118.64 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:25:01.620] End E008 | valid loss  5.859; ppl    350.25 | accu 0.2244 = 25185/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:25:07.455] End E008 |  test loss  7.946; ppl   2822.95 | accu 0.0766 = 8836/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:25:33.917] End E008 |  test loss  8.592; ppl   5386.68 | accu 0.0121 = 6110/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:25:33.917] Save: model.pt... 
[2022-04-13 12:25:34.506] Save: model.pt...Done. best_val_loss: 5.8587
[2022-04-13 12:25:34.506] Epoch 009/20 ==================================================
[2022-04-13 12:25:52.466] E009 |   200/667 batches | lr 5.0000 | loss  4.912 | ppl    135.96 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:26:10.554] E009 |   400/667 batches | lr 5.0000 | loss  4.900 | ppl    134.24 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:26:28.499] E009 |   600/667 batches | lr 5.0000 | loss  4.809 | ppl    122.61 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:26:34.526] E009 |   667/667 batches | lr 5.0000 | loss  4.732 | ppl    113.50 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:26:40.386] End E009 | valid loss  5.863; ppl    351.83 | accu 0.2245 = 25189/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:26:46.135] End E009 |  test loss  8.064; ppl   3178.50 | accu 0.0758 = 8751/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:27:12.278] End E009 |  test loss  8.681; ppl   5889.52 | accu 0.0106 = 5368/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:27:12.278] Epoch 010/20 ==================================================
[2022-04-13 12:27:30.115] E010 |   200/667 batches | lr 2.5000 | loss  4.842 | ppl    126.78 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:27:48.052] E010 |   400/667 batches | lr 2.5000 | loss  4.814 | ppl    123.18 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:28:06.002] E010 |   600/667 batches | lr 2.5000 | loss  4.711 | ppl    111.14 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:28:12.007] E010 |   667/667 batches | lr 2.5000 | loss  4.628 | ppl    102.28 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:28:17.926] End E010 | valid loss  5.855; ppl    349.00 | accu 0.2272 = 25498/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:28:23.699] End E010 |  test loss  7.828; ppl   2508.92 | accu 0.0771 = 8899/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:28:49.923] End E010 |  test loss  8.575; ppl   5298.26 | accu 0.0137 = 6922/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:28:49.923] Save: model.pt... 
[2022-04-13 12:28:50.511] Save: model.pt...Done. best_val_loss: 5.8551
[2022-04-13 12:28:50.512] Epoch 011/20 ==================================================
[2022-04-13 12:29:08.491] E011 |   200/667 batches | lr 2.5000 | loss  4.796 | ppl    121.04 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:29:26.460] E011 |   400/667 batches | lr 2.5000 | loss  4.777 | ppl    118.78 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:29:44.481] E011 |   600/667 batches | lr 2.5000 | loss  4.686 | ppl    108.44 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:29:50.493] E011 |   667/667 batches | lr 2.5000 | loss  4.601 | ppl     99.58 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:29:56.378] End E011 | valid loss  5.853; ppl    348.35 | accu 0.2273 = 25503/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:30:02.150] End E011 |  test loss  7.683; ppl   2171.77 | accu 0.0779 = 8988/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:30:28.330] End E011 |  test loss  8.577; ppl   5307.48 | accu 0.0132 = 6700/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:30:28.330] Save: model.pt... 
[2022-04-13 12:30:28.909] Save: model.pt...Done. best_val_loss: 5.8532
[2022-04-13 12:30:28.909] Epoch 012/20 ==================================================
[2022-04-13 12:30:46.813] E012 |   200/667 batches | lr 2.5000 | loss  4.761 | ppl    116.81 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:31:04.746] E012 |   400/667 batches | lr 2.5000 | loss  4.747 | ppl    115.19 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:31:22.750] E012 |   600/667 batches | lr 2.5000 | loss  4.659 | ppl    105.56 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:31:28.795] E012 |   667/667 batches | lr 2.5000 | loss  4.587 | ppl     98.17 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:31:34.676] End E012 | valid loss  5.857; ppl    349.52 | accu 0.2273 = 25502/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:31:40.478] End E012 |  test loss  7.654; ppl   2108.31 | accu 0.0780 = 8999/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:32:06.702] End E012 |  test loss  8.550; ppl   5167.44 | accu 0.0143 = 7267/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:32:06.702] Epoch 013/20 ==================================================
[2022-04-13 12:32:24.572] E013 |   200/667 batches | lr 1.2500 | loss  4.729 | ppl    113.14 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:32:42.539] E013 |   400/667 batches | lr 1.2500 | loss  4.706 | ppl    110.59 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:33:00.525] E013 |   600/667 batches | lr 1.2500 | loss  4.607 | ppl    100.23 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:33:06.541] E013 |   667/667 batches | lr 1.2500 | loss  4.527 | ppl     92.49 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:33:12.430] End E013 | valid loss  5.856; ppl    349.27 | accu 0.2290 = 25699/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:33:18.236] End E013 |  test loss  7.458; ppl   1732.92 | accu 0.0793 = 9153/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:33:44.596] End E013 |  test loss  8.450; ppl   4675.67 | accu 0.0157 = 7949/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:33:44.596] Epoch 014/20 ==================================================
[2022-04-13 12:34:02.550] E014 |   200/667 batches | lr 0.6250 | loss  4.701 | ppl    110.09 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:34:20.491] E014 |   400/667 batches | lr 0.6250 | loss  4.679 | ppl    107.71 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:34:38.490] E014 |   600/667 batches | lr 0.6250 | loss  4.581 | ppl     97.65 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:34:44.543] E014 |   667/667 batches | lr 0.6250 | loss  4.499 | ppl     89.97 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:34:50.442] End E014 | valid loss  5.853; ppl    348.15 | accu 0.2299 = 25804/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:34:56.247] End E014 |  test loss  7.446; ppl   1713.06 | accu 0.0792 = 9139/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:35:22.427] End E014 |  test loss  8.452; ppl   4684.09 | accu 0.0169 = 8556/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:35:22.427] Save: model.pt... 
[2022-04-13 12:35:23.015] Save: model.pt...Done. best_val_loss: 5.8526
[2022-04-13 12:35:23.015] Epoch 015/20 ==================================================
[2022-04-13 12:35:40.873] E015 |   200/667 batches | lr 0.6250 | loss  4.691 | ppl    108.96 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:35:58.850] E015 |   400/667 batches | lr 0.6250 | loss  4.669 | ppl    106.57 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:36:16.810] E015 |   600/667 batches | lr 0.6250 | loss  4.575 | ppl     96.98 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:36:22.862] E015 |   667/667 batches | lr 0.6250 | loss  4.497 | ppl     89.76 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:36:28.751] End E015 | valid loss  5.855; ppl    348.91 | accu 0.2302 = 25832/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:36:34.521] End E015 |  test loss  7.470; ppl   1754.98 | accu 0.0791 = 9123/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:37:00.765] End E015 |  test loss  8.483; ppl   4831.34 | accu 0.0161 = 8170/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:37:00.765] Epoch 016/20 ==================================================
[2022-04-13 12:37:18.591] E016 |   200/667 batches | lr 0.3125 | loss  4.682 | ppl    107.94 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:37:36.608] E016 |   400/667 batches | lr 0.3125 | loss  4.660 | ppl    105.63 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:37:54.747] E016 |   600/667 batches | lr 0.3125 | loss  4.561 | ppl     95.68 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:38:00.839] E016 |   667/667 batches | lr 0.3125 | loss  4.482 | ppl     88.44 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:38:06.743] End E016 | valid loss  5.854; ppl    348.66 | accu 0.2303 = 25841/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:38:12.516] End E016 |  test loss  7.441; ppl   1704.64 | accu 0.0792 = 9143/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:38:38.717] End E016 |  test loss  8.456; ppl   4702.39 | accu 0.0174 = 8809/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:38:38.717] Epoch 017/20 ==================================================
[2022-04-13 12:38:56.546] E017 |   200/667 batches | lr 0.1562 | loss  4.674 | ppl    107.18 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:39:14.597] E017 |   400/667 batches | lr 0.1562 | loss  4.654 | ppl    105.02 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:39:32.634] E017 |   600/667 batches | lr 0.1562 | loss  4.554 | ppl     95.04 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:39:38.710] E017 |   667/667 batches | lr 0.1562 | loss  4.472 | ppl     87.49 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:39:44.584] End E017 | valid loss  5.855; ppl    348.97 | accu 0.2302 = 25835/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:39:50.359] End E017 |  test loss  7.428; ppl   1683.04 | accu 0.0792 = 9137/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:40:16.527] End E017 |  test loss  8.449; ppl   4671.97 | accu 0.0176 = 8935/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:40:16.528] Epoch 018/20 ==================================================
[2022-04-13 12:40:34.230] E018 |   200/667 batches | lr 0.0781 | loss  4.669 | ppl    106.57 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:40:52.356] E018 |   400/667 batches | lr 0.0781 | loss  4.650 | ppl    104.54 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:41:10.500] E018 |   600/667 batches | lr 0.0781 | loss  4.548 | ppl     94.42 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:41:16.599] E018 |   667/667 batches | lr 0.0781 | loss  4.474 | ppl     87.74 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:41:22.481] End E018 | valid loss  5.856; ppl    349.35 | accu 0.2303 = 25840/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:41:28.273] End E018 |  test loss  7.431; ppl   1687.58 | accu 0.0791 = 9132/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:41:54.424] End E018 |  test loss  8.452; ppl   4684.94 | accu 0.0177 = 8965/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:41:54.424] Epoch 019/20 ==================================================
[2022-04-13 12:42:12.340] E019 |   200/667 batches | lr 0.0391 | loss  4.670 | ppl    106.65 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:42:30.283] E019 |   400/667 batches | lr 0.0391 | loss  4.645 | ppl    104.04 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:42:48.218] E019 |   600/667 batches | lr 0.0391 | loss  4.546 | ppl     94.26 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:42:54.252] E019 |   667/667 batches | lr 0.0391 | loss  4.463 | ppl     86.79 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:43:00.124] End E019 | valid loss  5.857; ppl    349.81 | accu 0.2302 = 25838/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:43:05.894] End E019 |  test loss  7.425; ppl   1678.15 | accu 0.0791 = 9130/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:43:32.072] End E019 |  test loss  8.448; ppl   4663.40 | accu 0.0178 = 9039/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:43:32.073] Epoch 020/20 ==================================================
[2022-04-13 12:43:49.965] E020 |   200/667 batches | lr 0.0195 | loss  4.668 | ppl    106.44 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:44:07.990] E020 |   400/667 batches | lr 0.0195 | loss  4.650 | ppl    104.58 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:44:25.999] E020 |   600/667 batches | lr 0.0195 | loss  4.549 | ppl     94.52 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:44:31.866] E020 |   667/667 batches | lr 0.0195 | loss  4.470 | ppl     87.37 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:44:37.753] End E020 | valid loss  5.858; ppl    350.03 | accu 0.2305 = 25863/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:44:43.513] End E020 |  test loss  7.425; ppl   1678.18 | accu 0.0791 = 9122/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:45:09.701] End E020 |  test loss  8.445; ppl   4649.89 | accu 0.0180 = 9098/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:45:15.659] End. test loss  7.45; ppl  1713.06 | accu 0.0792 = 9139/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:45:41.871] End. test loss  8.45; ppl  4684.09 | accu 0.0169 = 8556/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:45:41.872] =========================================================================================
[2022-04-13 12:45:41.872] valid_loss
[2022-04-13 12:45:41.872]  6.75, 6.21, 6.06, 6.02, 6.03, 5.89, 5.89, 5.86, 5.86, 5.86, 5.85, 5.86, 5.86, 5.85, 5.85, 5.85, 5.85, 5.86, 5.86, 5.86
[2022-04-13 12:45:41.872] valid_loss ppl
[2022-04-13 12:45:41.872]   851.75,  499.30,  429.85,  411.58,  413.90,  360.79,  361.61,  350.25,  351.83,  349.00,  348.35,  349.52,  349.27,  348.15,  348.91,  348.66,  348.97,  349.35,  349.81,  350.03
[2022-04-13 12:45:41.872] test_loss of ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:45:41.872]  7.28, 8.07, 7.54, 8.22, 8.64, 8.18, 8.54, 7.95, 8.06, 7.83, 7.68, 7.65, 7.46, 7.45, 7.47, 7.44, 7.43, 7.43, 7.43, 7.43
[2022-04-13 12:45:41.872] test_loss of ../data/sample_500k/cbt_valid.txt ppl
[2022-04-13 12:45:41.872]  1454.35, 3189.37, 1882.98, 3702.25, 5668.63, 3553.98, 5127.31, 2822.95, 3178.50, 2508.92, 2171.77, 2108.31, 1732.92, 1713.06, 1754.98, 1704.64, 1683.04, 1687.58, 1678.15, 1678.18
[2022-04-13 12:45:41.872] test_loss of ../data/sample_500k/adult_test.txt
[2022-04-13 12:45:41.872]  8.30,10.05, 9.27, 9.63,10.90, 9.02, 9.15, 8.59, 8.68, 8.58, 8.58, 8.55, 8.45, 8.45, 8.48, 8.46, 8.45, 8.45, 8.45, 8.44
[2022-04-13 12:45:41.872] test_loss of ../data/sample_500k/adult_test.txt ppl
[2022-04-13 12:45:41.872]  4039.95,23095.95,10593.75,15140.77,54344.33, 8292.62, 9371.50, 5386.68, 5889.52, 5298.26, 5307.48, 5167.44, 4675.67, 4684.09, 4831.34, 4702.39, 4671.97, 4684.94, 4663.40, 4649.89
[2022-04-13 12:45:41.873] 
[2022-04-13 12:45:41.873] 
[2022-04-13 12:45:41.873] 
Log file: ./output_wsm_Subword.200_fam_CNN.log closed.
Log file: ./output_wsm_Subword.200_fam_LSTM.log open...
[2022-04-13 12:45:41.885] corpus.train_file_list: 1
[2022-04-13 12:45:41.885]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 12:45:41.885] corpus.valid_file_list: 1
[2022-04-13 12:45:41.885]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 12:45:41.885] corpus.test_file_list: 2
[2022-04-13 12:45:41.885]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:45:41.886]         ../data/sample_500k/adult_test.txt
[2022-04-13 12:45:41.886] corpus.subword_vocab_size: 0
[2022-04-13 12:45:41.886] corpus.subword_model = None. Corpus will not use subword.
[2022-04-13 12:45:41.886] corpus tokenize...
[2022-04-13 12:45:42.942]         train tokens: 467267  ../data/sample_500k/adolescent_train.txt
[2022-04-13 12:45:43.160]         valid tokens: 112256  ../data/sample_500k/adolescent_valid.txt
[2022-04-13 12:45:43.297]         test  tokens: 115417  ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:45:43.896]         test  tokens: 506878  ../data/sample_500k/adult_test.txt
[2022-04-13 12:45:43.896] corpus.ntokens      : 95521
[2022-04-13 12:45:43.896] corpus.char_count   : 166
[2022-04-13 12:45:43.896] corpus.char_cnt_dict: 166
[2022-04-13 12:45:43.896] corpus.char_id_dict : 166
[2022-04-13 12:45:43.900] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 12:45:43.900]         tokens_all: 467267
[2022-04-13 12:45:43.900]         batched   :  23363
[2022-04-13 12:45:43.900]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 12:45:43.901] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 12:45:43.901]         tokens_all: 112256
[2022-04-13 12:45:43.902]         batched   :   5612
[2022-04-13 12:45:43.902]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 12:45:43.903] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 12:45:43.903]         tokens_all: 115417
[2022-04-13 12:45:43.903]         batched   :   5770
[2022-04-13 12:45:43.903]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:45:43.906] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 12:45:43.906]         tokens_all: 506878
[2022-04-13 12:45:43.906]         batched   :  25343
[2022-04-13 12:45:43.906]         ../data/sample_500k/adult_test.txt
[2022-04-13 12:45:43.907] subword_adapter will be generated due to word_split_mode='Subword.200'
[2022-04-13 12:45:43.907] SubwordAdapter.file_list: 2
[2022-04-13 12:45:43.907]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 12:45:43.907]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 12:45:43.907] SubwordAdapter.subword_vocab_size: 200
[2022-04-13 12:45:43.907] SubwordAdapter.subword_model.train(2 files)...
[2022-04-13 12:45:44.291] SubwordAdapter.subword_model.train(2 files)...Done
[2022-04-13 12:45:44.947] RNNModel.rnn_type: LSTM
[2022-04-13 12:45:44.947] RNNModel.ntoken  : 95521
[2022-04-13 12:45:44.947] RNNModel.ninp    : 200
[2022-04-13 12:45:44.947] RNNModel.nhid    : 200
[2022-04-13 12:45:44.947] RNNModel.nlayers : 2
[2022-04-13 12:45:44.947] RNNModel.dropout : 0.2
[2022-04-13 12:45:44.947] RNNModel.tie_weights: False
[2022-04-13 12:45:44.947] RNNModel.fragment_aggregate_mode: LSTM
[2022-04-13 12:45:44.947] RNNModel.fragment_cnt           : 202
[2022-04-13 12:45:44.947] RNNModel.fragment_emsize        : 25
[2022-04-13 12:45:44.948] RNNModel.fragment_nhid          : 200
[2022-04-13 12:45:44.948] RNNModel.fragment_embeds     : created
[2022-04-13 12:45:44.951] RNNModel.fragment_lstm       : created
[2022-04-13 12:45:44.951] RNNModel.fragment_lstm_linear: created
[2022-04-13 12:45:44.992] Epoch 001/20 ==================================================
[2022-04-13 12:46:55.121] E001 |   200/667 batches | lr 20.0000 | loss  8.556 | ppl   5199.00 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:48:07.025] E001 |   400/667 batches | lr 20.0000 | loss  7.763 | ppl   2352.75 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:49:18.170] E001 |   600/667 batches | lr 20.0000 | loss  7.242 | ppl   1397.02 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:49:41.797] E001 |   667/667 batches | lr 20.0000 | loss  6.924 | ppl   1016.82 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:49:56.060] End E001 | valid loss  6.858; ppl    951.68 | accu 0.1689 = 18950/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:50:10.309] End E001 |  test loss  8.057; ppl   3155.22 | accu 0.0556 = 6419/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:51:13.632] End E001 |  test loss  9.449; ppl  12699.91 | accu 0.0071 = 3608/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:51:13.632] Save: model.pt... 
[2022-04-13 12:51:14.217] Save: model.pt...Done. best_val_loss: 6.8582
[2022-04-13 12:51:14.217] Epoch 002/20 ==================================================
[2022-04-13 12:52:24.295] E002 |   200/667 batches | lr 20.0000 | loss  6.716 | ppl    825.17 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:53:36.520] E002 |   400/667 batches | lr 20.0000 | loss  6.515 | ppl    675.04 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 12:54:47.615] E002 |   600/667 batches | lr 20.0000 | loss  6.287 | ppl    537.61 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 12:55:11.448] E002 |   667/667 batches | lr 20.0000 | loss  6.151 | ppl    469.13 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 12:55:25.463] End E002 | valid loss  6.312; ppl    550.88 | accu 0.1770 = 19862/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 12:55:39.479] End E002 |  test loss  8.079; ppl   3225.98 | accu 0.0613 = 7076/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 12:56:42.567] End E002 |  test loss 10.323; ppl  30423.03 | accu 0.0046 = 2315/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 12:56:42.567] Save: model.pt... 
[2022-04-13 12:56:43.155] Save: model.pt...Done. best_val_loss: 6.3115
[2022-04-13 12:56:43.155] Epoch 003/20 ==================================================
[2022-04-13 12:57:53.784] E003 |   200/667 batches | lr 20.0000 | loss  6.096 | ppl    444.12 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 12:59:06.331] E003 |   400/667 batches | lr 20.0000 | loss  6.034 | ppl    417.56 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 13:00:17.903] E003 |   600/667 batches | lr 20.0000 | loss  5.893 | ppl    362.58 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 13:00:41.802] E003 |   667/667 batches | lr 20.0000 | loss  5.797 | ppl    329.37 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 13:00:55.718] End E003 | valid loss  6.061; ppl    428.86 | accu 0.2045 = 22952/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 13:01:09.734] End E003 |  test loss  7.411; ppl   1654.34 | accu 0.0763 = 8798/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 13:02:13.079] End E003 |  test loss  9.110; ppl   9044.83 | accu 0.0075 = 3820/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 13:02:13.079] Save: model.pt... 
[2022-04-13 13:02:13.673] Save: model.pt...Done. best_val_loss: 6.0611
[2022-04-13 13:02:13.673] Epoch 004/20 ==================================================
[2022-04-13 13:03:23.935] E004 |   200/667 batches | lr 20.0000 | loss  5.781 | ppl    324.00 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 13:04:36.610] E004 |   400/667 batches | lr 20.0000 | loss  5.756 | ppl    315.97 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 13:05:48.822] E004 |   600/667 batches | lr 20.0000 | loss  5.637 | ppl    280.55 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 13:06:12.716] E004 |   667/667 batches | lr 20.0000 | loss  5.558 | ppl    259.36 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 13:06:26.786] End E004 | valid loss  6.019; ppl    411.17 | accu 0.2112 = 23702/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 13:06:40.966] End E004 |  test loss  8.083; ppl   3239.78 | accu 0.0731 = 8435/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 13:07:44.106] End E004 |  test loss 10.307; ppl  29943.27 | accu 0.0044 = 2254/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 13:07:44.106] Save: model.pt... 
[2022-04-13 13:07:44.684] Save: model.pt...Done. best_val_loss: 6.0190
[2022-04-13 13:07:44.684] Epoch 005/20 ==================================================
[2022-04-13 13:08:55.053] E005 |   200/667 batches | lr 20.0000 | loss  5.551 | ppl    257.45 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 13:10:08.027] E005 |   400/667 batches | lr 20.0000 | loss  5.541 | ppl    255.06 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 13:11:21.235] E005 |   600/667 batches | lr 20.0000 | loss  5.443 | ppl    231.22 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 13:11:45.060] E005 |   667/667 batches | lr 20.0000 | loss  5.372 | ppl    215.26 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 13:11:59.230] End E005 | valid loss  5.992; ppl    400.19 | accu 0.2120 = 23788/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 13:12:13.438] End E005 |  test loss  7.866; ppl   2606.43 | accu 0.0758 = 8749/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 13:13:17.104] End E005 |  test loss  9.168; ppl   9584.24 | accu 0.0111 = 5651/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 13:13:17.104] Save: model.pt... 
[2022-04-13 13:13:17.680] Save: model.pt...Done. best_val_loss: 5.9919
[2022-04-13 13:13:17.680] Epoch 006/20 ==================================================
[2022-04-13 13:14:28.446] E006 |   200/667 batches | lr 20.0000 | loss  5.364 | ppl    213.65 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 13:15:41.938] E006 |   400/667 batches | lr 20.0000 | loss  5.364 | ppl    213.60 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 13:16:53.137] E006 |   600/667 batches | lr 20.0000 | loss  5.270 | ppl    194.51 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 13:17:16.807] E006 |   667/667 batches | lr 20.0000 | loss  5.205 | ppl    182.10 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 13:17:30.820] End E006 | valid loss  5.993; ppl    400.53 | accu 0.2088 = 23433/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 13:17:44.967] End E006 |  test loss  7.786; ppl   2407.76 | accu 0.0789 = 9108/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 13:18:48.526] End E006 |  test loss  8.949; ppl   7703.14 | accu 0.0237 = 11993/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 13:18:48.526] Epoch 007/20 ==================================================
[2022-04-13 13:19:59.718] E007 |   200/667 batches | lr 10.0000 | loss  5.108 | ppl    165.34 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 13:21:12.970] E007 |   400/667 batches | lr 10.0000 | loss  5.069 | ppl    159.09 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 13:22:25.272] E007 |   600/667 batches | lr 10.0000 | loss  4.957 | ppl    142.18 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 13:22:49.439] E007 |   667/667 batches | lr 10.0000 | loss  4.875 | ppl    130.93 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 13:23:03.502] End E007 | valid loss  5.935; ppl    378.19 | accu 0.2175 = 24407/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 13:23:17.748] End E007 |  test loss  7.913; ppl   2732.54 | accu 0.0830 = 9572/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 13:24:21.018] End E007 |  test loss  8.794; ppl   6596.77 | accu 0.0197 = 9969/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 13:24:21.019] Save: model.pt... 
[2022-04-13 13:24:21.592] Save: model.pt...Done. best_val_loss: 5.9354
[2022-04-13 13:24:21.592] Epoch 008/20 ==================================================
[2022-04-13 13:25:32.228] E008 |   200/667 batches | lr 10.0000 | loss  4.964 | ppl    143.23 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 13:26:44.904] E008 |   400/667 batches | lr 10.0000 | loss  4.948 | ppl    140.84 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 13:27:57.731] E008 |   600/667 batches | lr 10.0000 | loss  4.857 | ppl    128.65 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 13:28:21.917] E008 |   667/667 batches | lr 10.0000 | loss  4.789 | ppl    120.12 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 13:28:36.227] End E008 | valid loss  5.935; ppl    377.87 | accu 0.2190 = 24573/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 13:28:50.549] End E008 |  test loss  7.868; ppl   2611.05 | accu 0.0846 = 9765/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 13:29:56.402] End E008 |  test loss  8.807; ppl   6680.22 | accu 0.0209 = 10610/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 13:29:56.402] Save: model.pt... 
[2022-04-13 13:29:56.994] Save: model.pt...Done. best_val_loss: 5.9345
[2022-04-13 13:29:56.994] Epoch 009/20 ==================================================
[2022-04-13 13:31:07.986] E009 |   200/667 batches | lr 10.0000 | loss  4.861 | ppl    129.20 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 13:32:21.993] E009 |   400/667 batches | lr 10.0000 | loss  4.854 | ppl    128.20 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 13:33:35.800] E009 |   600/667 batches | lr 10.0000 | loss  4.773 | ppl    118.27 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 13:34:00.171] E009 |   667/667 batches | lr 10.0000 | loss  4.705 | ppl    110.48 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 13:34:14.418] End E009 | valid loss  5.933; ppl    377.38 | accu 0.2186 = 24529/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 13:34:28.963] End E009 |  test loss  7.719; ppl   2251.70 | accu 0.0871 = 10052/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 13:35:34.921] End E009 |  test loss  8.705; ppl   6032.56 | accu 0.0270 = 13681/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 13:35:34.921] Save: model.pt... 
[2022-04-13 13:35:35.529] Save: model.pt...Done. best_val_loss: 5.9332
[2022-04-13 13:35:35.529] Epoch 010/20 ==================================================
[2022-04-13 13:36:47.206] E010 |   200/667 batches | lr 10.0000 | loss  4.771 | ppl    118.02 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 13:38:00.364] E010 |   400/667 batches | lr 10.0000 | loss  4.764 | ppl    117.16 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 13:39:14.054] E010 |   600/667 batches | lr 10.0000 | loss  4.691 | ppl    108.96 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 13:39:38.407] E010 |   667/667 batches | lr 10.0000 | loss  4.630 | ppl    102.55 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 13:39:52.921] End E010 | valid loss  5.964; ppl    389.10 | accu 0.2190 = 24580/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 13:40:07.546] End E010 |  test loss  8.053; ppl   3143.00 | accu 0.0828 = 9549/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 13:41:12.083] End E010 |  test loss  9.063; ppl   8631.20 | accu 0.0219 = 11102/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 13:41:12.084] Epoch 011/20 ==================================================
[2022-04-13 13:42:22.418] E011 |   200/667 batches | lr 5.0000 | loss  4.658 | ppl    105.37 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 13:43:35.818] E011 |   400/667 batches | lr 5.0000 | loss  4.617 | ppl    101.23 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 13:44:47.787] E011 |   600/667 batches | lr 5.0000 | loss  4.524 | ppl     92.18 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 13:45:11.831] E011 |   667/667 batches | lr 5.0000 | loss  4.441 | ppl     84.82 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 13:45:25.961] End E011 | valid loss  5.945; ppl    381.98 | accu 0.2231 = 25038/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 13:45:40.100] End E011 |  test loss  8.087; ppl   3253.31 | accu 0.0880 = 10156/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 13:46:43.370] End E011 |  test loss  8.715; ppl   6091.62 | accu 0.0316 = 15993/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 13:46:43.370] Epoch 012/20 ==================================================
[2022-04-13 13:47:53.314] E012 |   200/667 batches | lr 2.5000 | loss  4.574 | ppl     96.93 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 13:49:06.709] E012 |   400/667 batches | lr 2.5000 | loss  4.535 | ppl     93.20 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 13:50:19.066] E012 |   600/667 batches | lr 2.5000 | loss  4.432 | ppl     84.06 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 13:50:43.379] E012 |   667/667 batches | lr 2.5000 | loss  4.348 | ppl     77.34 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 13:50:57.824] End E012 | valid loss  5.935; ppl    378.03 | accu 0.2261 = 25374/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 13:51:12.197] End E012 |  test loss  8.085; ppl   3243.91 | accu 0.0909 = 10492/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 13:52:16.544] End E012 |  test loss  8.695; ppl   5975.15 | accu 0.0328 = 16614/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 13:52:16.544] Epoch 013/20 ==================================================
[2022-04-13 13:53:27.638] E013 |   200/667 batches | lr 1.2500 | loss  4.530 | ppl     92.79 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 13:54:40.501] E013 |   400/667 batches | lr 1.2500 | loss  4.493 | ppl     89.36 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 13:55:52.649] E013 |   600/667 batches | lr 1.2500 | loss  4.384 | ppl     80.13 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 13:56:16.698] E013 |   667/667 batches | lr 1.2500 | loss  4.298 | ppl     73.55 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 13:56:30.770] End E013 | valid loss  5.938; ppl    379.18 | accu 0.2269 = 25460/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 13:56:44.890] End E013 |  test loss  8.077; ppl   3220.54 | accu 0.0909 = 10484/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 13:57:48.265] End E013 |  test loss  8.743; ppl   6267.55 | accu 0.0299 = 15149/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 13:57:48.266] Epoch 014/20 ==================================================
[2022-04-13 13:58:58.375] E014 |   200/667 batches | lr 0.6250 | loss  4.504 | ppl     90.39 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 14:00:11.079] E014 |   400/667 batches | lr 0.6250 | loss  4.472 | ppl     87.52 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 14:01:23.241] E014 |   600/667 batches | lr 0.6250 | loss  4.359 | ppl     78.21 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 14:01:47.608] E014 |   667/667 batches | lr 0.6250 | loss  4.275 | ppl     71.91 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 14:02:01.735] End E014 | valid loss  5.932; ppl    376.97 | accu 0.2274 = 25520/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 14:02:15.856] End E014 |  test loss  8.092; ppl   3268.69 | accu 0.0908 = 10473/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:03:19.547] End E014 |  test loss  8.773; ppl   6459.36 | accu 0.0295 = 14932/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:03:19.547] Save: model.pt... 
[2022-04-13 14:03:20.137] Save: model.pt...Done. best_val_loss: 5.9322
[2022-04-13 14:03:20.137] Epoch 015/20 ==================================================
[2022-04-13 14:04:30.887] E015 |   200/667 batches | lr 0.6250 | loss  4.491 | ppl     89.22 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 14:05:43.634] E015 |   400/667 batches | lr 0.6250 | loss  4.457 | ppl     86.24 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 14:06:57.136] E015 |   600/667 batches | lr 0.6250 | loss  4.355 | ppl     77.83 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 14:07:21.005] E015 |   667/667 batches | lr 0.6250 | loss  4.276 | ppl     71.94 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 14:07:34.946] End E015 | valid loss  5.935; ppl    377.88 | accu 0.2277 = 25547/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 14:07:49.066] End E015 |  test loss  8.053; ppl   3143.22 | accu 0.0915 = 10559/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:08:52.505] End E015 |  test loss  8.748; ppl   6297.44 | accu 0.0301 = 15246/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:08:52.505] Epoch 016/20 ==================================================
[2022-04-13 14:10:03.928] E016 |   200/667 batches | lr 0.3125 | loss  4.478 | ppl     88.03 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 14:11:16.729] E016 |   400/667 batches | lr 0.3125 | loss  4.448 | ppl     85.50 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 14:12:30.328] E016 |   600/667 batches | lr 0.3125 | loss  4.337 | ppl     76.48 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 14:12:54.682] E016 |   667/667 batches | lr 0.3125 | loss  4.260 | ppl     70.82 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 14:13:08.722] End E016 | valid loss  5.932; ppl    377.04 | accu 0.2278 = 25563/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 14:13:22.825] End E016 |  test loss  8.095; ppl   3278.09 | accu 0.0904 = 10425/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:14:26.483] End E016 |  test loss  8.799; ppl   6626.47 | accu 0.0276 = 13965/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:14:26.483] Epoch 017/20 ==================================================
[2022-04-13 14:15:36.934] E017 |   200/667 batches | lr 0.1562 | loss  4.476 | ppl     87.90 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 14:16:50.441] E017 |   400/667 batches | lr 0.1562 | loss  4.441 | ppl     84.84 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 14:18:02.380] E017 |   600/667 batches | lr 0.1562 | loss  4.333 | ppl     76.18 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 14:18:26.519] E017 |   667/667 batches | lr 0.1562 | loss  4.249 | ppl     70.00 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 14:18:40.550] End E017 | valid loss  5.935; ppl    378.05 | accu 0.2279 = 25580/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 14:18:54.534] End E017 |  test loss  8.086; ppl   3248.68 | accu 0.0902 = 10412/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:19:57.507] End E017 |  test loss  8.781; ppl   6509.00 | accu 0.0283 = 14329/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:19:57.508] Epoch 018/20 ==================================================
[2022-04-13 14:21:08.500] E018 |   200/667 batches | lr 0.0781 | loss  4.474 | ppl     87.67 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 14:22:21.001] E018 |   400/667 batches | lr 0.0781 | loss  4.438 | ppl     84.64 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 14:23:33.987] E018 |   600/667 batches | lr 0.0781 | loss  4.328 | ppl     75.82 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 14:23:58.246] E018 |   667/667 batches | lr 0.0781 | loss  4.244 | ppl     69.70 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 14:24:12.332] End E018 | valid loss  5.935; ppl    378.15 | accu 0.2281 = 25602/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 14:24:26.574] End E018 |  test loss  8.093; ppl   3271.64 | accu 0.0897 = 10346/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:25:30.039] End E018 |  test loss  8.786; ppl   6545.11 | accu 0.0282 = 14291/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:25:30.039] Epoch 019/20 ==================================================
[2022-04-13 14:26:39.844] E019 |   200/667 batches | lr 0.0391 | loss  4.467 | ppl     87.05 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 14:27:52.999] E019 |   400/667 batches | lr 0.0391 | loss  4.437 | ppl     84.51 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 14:29:05.678] E019 |   600/667 batches | lr 0.0391 | loss  4.328 | ppl     75.81 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 14:29:30.161] E019 |   667/667 batches | lr 0.0391 | loss  4.240 | ppl     69.40 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 14:29:44.238] End E019 | valid loss  5.935; ppl    378.22 | accu 0.2280 = 25588/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 14:29:58.328] End E019 |  test loss  8.093; ppl   3270.83 | accu 0.0895 = 10322/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:31:02.007] End E019 |  test loss  8.786; ppl   6541.51 | accu 0.0282 = 14303/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:31:02.008] Epoch 020/20 ==================================================
[2022-04-13 14:32:11.789] E020 |   200/667 batches | lr 0.0195 | loss  4.468 | ppl     87.15 frag_cnt/word_cnt=3.254=455613/140000
[2022-04-13 14:33:24.670] E020 |   400/667 batches | lr 0.0195 | loss  4.434 | ppl     84.29 frag_cnt/word_cnt=3.282=459419/140000
[2022-04-13 14:34:36.977] E020 |   600/667 batches | lr 0.0195 | loss  4.327 | ppl     75.71 frag_cnt/word_cnt=3.266=457255/140000
[2022-04-13 14:35:00.795] E020 |   667/667 batches | lr 0.0195 | loss  4.250 | ppl     70.08 frag_cnt/word_cnt=3.246=152257/46900
[2022-04-13 14:35:15.180] End E020 | valid loss  5.937; ppl    378.68 | accu 0.2281 = 25602/112220 | w_len 3.1469 = 353149/112220
[2022-04-13 14:35:29.352] End E020 |  test loss  8.094; ppl   3275.04 | accu 0.0896 = 10336/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:36:32.843] End E020 |  test loss  8.785; ppl   6533.70 | accu 0.0284 = 14377/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:36:47.115] End. test loss  8.09; ppl  3268.69 | accu 0.0908 = 10473/115380 | w_len 2.3715 = 273618/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:37:50.470] End. test loss  8.77; ppl  6459.36 | accu 0.0295 = 14932/506840 | w_len 3.1954 = 1619577/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:37:50.470] =========================================================================================
[2022-04-13 14:37:50.470] valid_loss
[2022-04-13 14:37:50.470]  6.86, 6.31, 6.06, 6.02, 5.99, 5.99, 5.94, 5.93, 5.93, 5.96, 5.95, 5.93, 5.94, 5.93, 5.93, 5.93, 5.94, 5.94, 5.94, 5.94
[2022-04-13 14:37:50.470] valid_loss ppl
[2022-04-13 14:37:50.470]   951.68,  550.88,  428.86,  411.17,  400.19,  400.53,  378.19,  377.87,  377.38,  389.10,  381.98,  378.03,  379.18,  376.97,  377.88,  377.04,  378.05,  378.15,  378.22,  378.68
[2022-04-13 14:37:50.471] test_loss of ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:37:50.471]  8.06, 8.08, 7.41, 8.08, 7.87, 7.79, 7.91, 7.87, 7.72, 8.05, 8.09, 8.08, 8.08, 8.09, 8.05, 8.10, 8.09, 8.09, 8.09, 8.09
[2022-04-13 14:37:50.471] test_loss of ../data/sample_500k/cbt_valid.txt ppl
[2022-04-13 14:37:50.471]  3155.22, 3225.98, 1654.34, 3239.78, 2606.43, 2407.76, 2732.54, 2611.05, 2251.70, 3143.00, 3253.31, 3243.91, 3220.54, 3268.69, 3143.22, 3278.09, 3248.68, 3271.64, 3270.83, 3275.04
[2022-04-13 14:37:50.471] test_loss of ../data/sample_500k/adult_test.txt
[2022-04-13 14:37:50.471]  9.45,10.32, 9.11,10.31, 9.17, 8.95, 8.79, 8.81, 8.70, 9.06, 8.71, 8.70, 8.74, 8.77, 8.75, 8.80, 8.78, 8.79, 8.79, 8.78
[2022-04-13 14:37:50.471] test_loss of ../data/sample_500k/adult_test.txt ppl
[2022-04-13 14:37:50.471] 12699.91,30423.03, 9044.83,29943.27, 9584.24, 7703.14, 6596.77, 6680.22, 6032.56, 8631.20, 6091.62, 5975.15, 6267.55, 6459.36, 6297.44, 6626.47, 6509.00, 6545.11, 6541.51, 6533.70
[2022-04-13 14:37:50.471] 
[2022-04-13 14:37:50.471] 
[2022-04-13 14:37:50.471] 
Log file: ./output_wsm_Subword.200_fam_LSTM.log closed.
Log file: ./output_wsm_Subword.500_fam_CNN.log open...
[2022-04-13 14:37:50.482] corpus.train_file_list: 1
[2022-04-13 14:37:50.483]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 14:37:50.483] corpus.valid_file_list: 1
[2022-04-13 14:37:50.483]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 14:37:50.483] corpus.test_file_list: 2
[2022-04-13 14:37:50.483]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:37:50.483]         ../data/sample_500k/adult_test.txt
[2022-04-13 14:37:50.483] corpus.subword_vocab_size: 0
[2022-04-13 14:37:50.483] corpus.subword_model = None. Corpus will not use subword.
[2022-04-13 14:37:50.483] corpus tokenize...
[2022-04-13 14:37:51.532]         train tokens: 467267  ../data/sample_500k/adolescent_train.txt
[2022-04-13 14:37:51.751]         valid tokens: 112256  ../data/sample_500k/adolescent_valid.txt
[2022-04-13 14:37:51.886]         test  tokens: 115417  ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:37:52.499]         test  tokens: 506878  ../data/sample_500k/adult_test.txt
[2022-04-13 14:37:52.499] corpus.ntokens      : 95521
[2022-04-13 14:37:52.500] corpus.char_count   : 166
[2022-04-13 14:37:52.500] corpus.char_cnt_dict: 166
[2022-04-13 14:37:52.500] corpus.char_id_dict : 166
[2022-04-13 14:37:52.503] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 14:37:52.503]         tokens_all: 467267
[2022-04-13 14:37:52.503]         batched   :  23363
[2022-04-13 14:37:52.503]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 14:37:52.505] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 14:37:52.506]         tokens_all: 112256
[2022-04-13 14:37:52.506]         batched   :   5612
[2022-04-13 14:37:52.506]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 14:37:52.507] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 14:37:52.507]         tokens_all: 115417
[2022-04-13 14:37:52.507]         batched   :   5770
[2022-04-13 14:37:52.507]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:37:52.511] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 14:37:52.511]         tokens_all: 506878
[2022-04-13 14:37:52.511]         batched   :  25343
[2022-04-13 14:37:52.511]         ../data/sample_500k/adult_test.txt
[2022-04-13 14:37:52.512] subword_adapter will be generated due to word_split_mode='Subword.500'
[2022-04-13 14:37:52.513] SubwordAdapter.file_list: 2
[2022-04-13 14:37:52.513]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 14:37:52.513]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 14:37:52.513] SubwordAdapter.subword_vocab_size: 500
[2022-04-13 14:37:52.513] SubwordAdapter.subword_model.train(2 files)...
[2022-04-13 14:37:52.956] SubwordAdapter.subword_model.train(2 files)...Done
[2022-04-13 14:37:53.599] RNNModel.rnn_type: LSTM
[2022-04-13 14:37:53.599] RNNModel.ntoken  : 95521
[2022-04-13 14:37:53.599] RNNModel.ninp    : 200
[2022-04-13 14:37:53.599] RNNModel.nhid    : 200
[2022-04-13 14:37:53.599] RNNModel.nlayers : 2
[2022-04-13 14:37:53.599] RNNModel.dropout : 0.2
[2022-04-13 14:37:53.599] RNNModel.tie_weights: False
[2022-04-13 14:37:53.599] RNNModel.fragment_aggregate_mode: CNN
[2022-04-13 14:37:53.600] RNNModel.fragment_cnt           : 502
[2022-04-13 14:37:53.600] RNNModel.fragment_emsize        : 25
[2022-04-13 14:37:53.600] RNNModel.fragment_nhid          : 200
[2022-04-13 14:37:53.600] RNNModel.fragment_embeds     : created
[2022-04-13 14:37:53.601] RNNModel.fragment_cnn3       : created
[2022-04-13 14:37:53.640] Epoch 001/20 ==================================================
[2022-04-13 14:38:11.388] E001 |   200/667 batches | lr 20.0000 | loss  8.560 | ppl   5219.29 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 14:38:29.288] E001 |   400/667 batches | lr 20.0000 | loss  7.661 | ppl   2123.75 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 14:38:47.088] E001 |   600/667 batches | lr 20.0000 | loss  7.074 | ppl   1181.06 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 14:38:53.072] E001 |   667/667 batches | lr 20.0000 | loss  6.746 | ppl    851.05 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 14:38:58.916] End E001 | valid loss  6.593; ppl    729.70 | accu 0.1743 = 19556/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 14:39:04.676] End E001 |  test loss  7.833; ppl   2522.94 | accu 0.0732 = 8442/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:39:30.821] End E001 |  test loss  9.499; ppl  13344.09 | accu 0.0044 = 2205/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:39:30.821] Save: model.pt... 
[2022-04-13 14:39:31.408] Save: model.pt...Done. best_val_loss: 6.5926
[2022-04-13 14:39:31.409] Epoch 002/20 ==================================================
[2022-04-13 14:39:49.121] E002 |   200/667 batches | lr 20.0000 | loss  6.581 | ppl    720.94 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 14:40:06.944] E002 |   400/667 batches | lr 20.0000 | loss  6.409 | ppl    607.13 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 14:40:24.750] E002 |   600/667 batches | lr 20.0000 | loss  6.197 | ppl    491.14 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 14:40:30.743] E002 |   667/667 batches | lr 20.0000 | loss  6.077 | ppl    435.85 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 14:40:36.567] End E002 | valid loss  6.249; ppl    517.47 | accu 0.1986 = 22289/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 14:40:42.357] End E002 |  test loss  8.549; ppl   5163.77 | accu 0.0648 = 7481/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:41:08.479] End E002 |  test loss 10.737; ppl  46020.98 | accu 0.0051 = 2602/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:41:08.480] Save: model.pt... 
[2022-04-13 14:41:09.055] Save: model.pt...Done. best_val_loss: 6.2490
[2022-04-13 14:41:09.055] Epoch 003/20 ==================================================
[2022-04-13 14:41:26.885] E003 |   200/667 batches | lr 20.0000 | loss  6.035 | ppl    417.66 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 14:41:44.847] E003 |   400/667 batches | lr 20.0000 | loss  5.999 | ppl    402.92 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 14:42:02.763] E003 |   600/667 batches | lr 20.0000 | loss  5.860 | ppl    350.78 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 14:42:08.772] E003 |   667/667 batches | lr 20.0000 | loss  5.772 | ppl    321.08 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 14:42:14.659] End E003 | valid loss  6.058; ppl    427.71 | accu 0.2069 = 23214/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 14:42:20.414] End E003 |  test loss  7.932; ppl   2786.37 | accu 0.0721 = 8318/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:42:46.571] End E003 |  test loss  9.473; ppl  13008.42 | accu 0.0065 = 3272/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:42:46.572] Save: model.pt... 
[2022-04-13 14:42:47.150] Save: model.pt...Done. best_val_loss: 6.0585
[2022-04-13 14:42:47.150] Epoch 004/20 ==================================================
[2022-04-13 14:43:05.021] E004 |   200/667 batches | lr 20.0000 | loss  5.761 | ppl    317.72 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 14:43:23.018] E004 |   400/667 batches | lr 20.0000 | loss  5.738 | ppl    310.54 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 14:43:41.014] E004 |   600/667 batches | lr 20.0000 | loss  5.638 | ppl    280.93 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 14:43:47.057] E004 |   667/667 batches | lr 20.0000 | loss  5.552 | ppl    257.69 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 14:43:52.910] End E004 | valid loss  6.007; ppl    406.27 | accu 0.2089 = 23446/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 14:43:58.668] End E004 |  test loss  8.092; ppl   3266.93 | accu 0.0700 = 8079/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:44:24.994] End E004 |  test loss  9.211; ppl  10006.18 | accu 0.0092 = 4686/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:44:24.994] Save: model.pt... 
[2022-04-13 14:44:25.593] Save: model.pt...Done. best_val_loss: 6.0070
[2022-04-13 14:44:25.593] Epoch 005/20 ==================================================
[2022-04-13 14:44:43.442] E005 |   200/667 batches | lr 20.0000 | loss  5.554 | ppl    258.21 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 14:45:01.353] E005 |   400/667 batches | lr 20.0000 | loss  5.560 | ppl    259.75 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 14:45:19.330] E005 |   600/667 batches | lr 20.0000 | loss  5.470 | ppl    237.48 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 14:45:25.418] E005 |   667/667 batches | lr 20.0000 | loss  5.410 | ppl    223.56 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 14:45:31.316] End E005 | valid loss  6.015; ppl    409.47 | accu 0.2063 = 23153/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 14:45:37.132] End E005 |  test loss  7.866; ppl   2608.35 | accu 0.0744 = 8583/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:46:03.281] End E005 |  test loss  8.561; ppl   5224.07 | accu 0.0278 = 14081/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:46:03.281] Epoch 006/20 ==================================================
[2022-04-13 14:46:21.171] E006 |   200/667 batches | lr 10.0000 | loss  5.289 | ppl    198.10 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 14:46:39.146] E006 |   400/667 batches | lr 10.0000 | loss  5.255 | ppl    191.56 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 14:46:57.180] E006 |   600/667 batches | lr 10.0000 | loss  5.146 | ppl    171.76 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 14:47:03.188] E006 |   667/667 batches | lr 10.0000 | loss  5.065 | ppl    158.33 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 14:47:09.143] End E006 | valid loss  5.895; ppl    363.15 | accu 0.2192 = 24594/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 14:47:15.388] End E006 |  test loss  7.841; ppl   2543.75 | accu 0.0727 = 8389/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:47:42.033] End E006 |  test loss  8.693; ppl   5963.61 | accu 0.0114 = 5775/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:47:42.033] Save: model.pt... 
[2022-04-13 14:47:42.652] Save: model.pt...Done. best_val_loss: 5.8948
[2022-04-13 14:47:42.653] Epoch 007/20 ==================================================
[2022-04-13 14:48:00.565] E007 |   200/667 batches | lr 10.0000 | loss  5.140 | ppl    170.80 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 14:48:18.584] E007 |   400/667 batches | lr 10.0000 | loss  5.131 | ppl    169.18 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 14:48:36.641] E007 |   600/667 batches | lr 10.0000 | loss  5.044 | ppl    155.09 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 14:48:42.677] E007 |   667/667 batches | lr 10.0000 | loss  4.974 | ppl    144.54 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 14:48:48.660] End E007 | valid loss  5.895; ppl    363.09 | accu 0.2198 = 24665/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 14:48:54.511] End E007 |  test loss  7.750; ppl   2322.47 | accu 0.0750 = 8657/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:49:21.038] End E007 |  test loss  8.759; ppl   6370.77 | accu 0.0136 = 6873/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:49:21.038] Save: model.pt... 
[2022-04-13 14:49:21.631] Save: model.pt...Done. best_val_loss: 5.8946
[2022-04-13 14:49:21.631] Epoch 008/20 ==================================================
[2022-04-13 14:49:39.527] E008 |   200/667 batches | lr 10.0000 | loss  5.034 | ppl    153.60 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 14:49:57.533] E008 |   400/667 batches | lr 10.0000 | loss  5.033 | ppl    153.45 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 14:50:15.396] E008 |   600/667 batches | lr 10.0000 | loss  4.954 | ppl    141.68 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 14:50:21.469] E008 |   667/667 batches | lr 10.0000 | loss  4.886 | ppl    132.42 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 14:50:27.440] End E008 | valid loss  5.902; ppl    365.66 | accu 0.2202 = 24715/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 14:50:33.341] End E008 |  test loss  7.615; ppl   2028.34 | accu 0.0748 = 8630/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:50:59.889] End E008 |  test loss  8.573; ppl   5287.30 | accu 0.0127 = 6424/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:50:59.889] Epoch 009/20 ==================================================
[2022-04-13 14:51:17.846] E009 |   200/667 batches | lr 5.0000 | loss  4.909 | ppl    135.46 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 14:51:35.917] E009 |   400/667 batches | lr 5.0000 | loss  4.881 | ppl    131.83 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 14:51:53.992] E009 |   600/667 batches | lr 5.0000 | loss  4.779 | ppl    118.97 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 14:52:00.019] E009 |   667/667 batches | lr 5.0000 | loss  4.706 | ppl    110.63 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 14:52:05.962] End E009 | valid loss  5.886; ppl    359.82 | accu 0.2246 = 25208/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 14:52:11.892] End E009 |  test loss  7.683; ppl   2171.38 | accu 0.0781 = 9012/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:52:38.354] End E009 |  test loss  8.541; ppl   5122.82 | accu 0.0162 = 8234/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:52:38.354] Save: model.pt... 
[2022-04-13 14:52:38.942] Save: model.pt...Done. best_val_loss: 5.8856
[2022-04-13 14:52:38.942] Epoch 010/20 ==================================================
[2022-04-13 14:52:56.767] E010 |   200/667 batches | lr 5.0000 | loss  4.828 | ppl    125.01 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 14:53:14.793] E010 |   400/667 batches | lr 5.0000 | loss  4.816 | ppl    123.49 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 14:53:32.914] E010 |   600/667 batches | lr 5.0000 | loss  4.729 | ppl    113.18 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 14:53:38.955] E010 |   667/667 batches | lr 5.0000 | loss  4.655 | ppl    105.07 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 14:53:44.959] End E010 | valid loss  5.891; ppl    361.86 | accu 0.2249 = 25234/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 14:53:50.817] End E010 |  test loss  7.677; ppl   2157.83 | accu 0.0783 = 9035/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:54:17.623] End E010 |  test loss  8.465; ppl   4743.50 | accu 0.0178 = 9003/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:54:17.623] Epoch 011/20 ==================================================
[2022-04-13 14:54:35.530] E011 |   200/667 batches | lr 2.5000 | loss  4.763 | ppl    117.15 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 14:54:53.538] E011 |   400/667 batches | lr 2.5000 | loss  4.735 | ppl    113.90 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 14:55:11.568] E011 |   600/667 batches | lr 2.5000 | loss  4.631 | ppl    102.62 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 14:55:17.588] E011 |   667/667 batches | lr 2.5000 | loss  4.558 | ppl     95.39 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 14:55:23.495] End E011 | valid loss  5.883; ppl    358.99 | accu 0.2269 = 25459/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 14:55:29.293] End E011 |  test loss  7.653; ppl   2107.41 | accu 0.0792 = 9141/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:55:55.642] End E011 |  test loss  8.442; ppl   4637.17 | accu 0.0193 = 9782/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:55:55.642] Save: model.pt... 
[2022-04-13 14:55:56.222] Save: model.pt...Done. best_val_loss: 5.8833
[2022-04-13 14:55:56.222] Epoch 012/20 ==================================================
[2022-04-13 14:56:13.966] E012 |   200/667 batches | lr 2.5000 | loss  4.716 | ppl    111.70 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 14:56:32.059] E012 |   400/667 batches | lr 2.5000 | loss  4.697 | ppl    109.63 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 14:56:50.115] E012 |   600/667 batches | lr 2.5000 | loss  4.609 | ppl    100.38 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 14:56:56.185] E012 |   667/667 batches | lr 2.5000 | loss  4.536 | ppl     93.33 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 14:57:02.137] End E012 | valid loss  5.883; ppl    358.85 | accu 0.2268 = 25447/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 14:57:07.992] End E012 |  test loss  7.643; ppl   2086.81 | accu 0.0795 = 9176/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:57:34.430] End E012 |  test loss  8.439; ppl   4625.72 | accu 0.0175 = 8884/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:57:34.431] Save: model.pt... 
[2022-04-13 14:57:35.030] Save: model.pt...Done. best_val_loss: 5.8829
[2022-04-13 14:57:35.031] Epoch 013/20 ==================================================
[2022-04-13 14:57:53.407] E013 |   200/667 batches | lr 2.5000 | loss  4.682 | ppl    107.95 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 14:58:11.486] E013 |   400/667 batches | lr 2.5000 | loss  4.670 | ppl    106.67 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 14:58:29.501] E013 |   600/667 batches | lr 2.5000 | loss  4.582 | ppl     97.69 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 14:58:35.542] E013 |   667/667 batches | lr 2.5000 | loss  4.516 | ppl     91.48 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 14:58:41.477] End E013 | valid loss  5.889; ppl    361.10 | accu 0.2267 = 25445/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 14:58:47.325] End E013 |  test loss  7.767; ppl   2360.66 | accu 0.0796 = 9188/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 14:59:13.951] End E013 |  test loss  8.440; ppl   4630.29 | accu 0.0206 = 10436/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 14:59:13.951] Epoch 014/20 ==================================================
[2022-04-13 14:59:31.859] E014 |   200/667 batches | lr 1.2500 | loss  4.655 | ppl    105.07 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 14:59:49.939] E014 |   400/667 batches | lr 1.2500 | loss  4.631 | ppl    102.59 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 15:00:07.858] E014 |   600/667 batches | lr 1.2500 | loss  4.534 | ppl     93.13 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 15:00:13.886] E014 |   667/667 batches | lr 1.2500 | loss  4.462 | ppl     86.64 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 15:00:19.841] End E014 | valid loss  5.881; ppl    358.14 | accu 0.2282 = 25603/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 15:00:25.693] End E014 |  test loss  7.643; ppl   2085.89 | accu 0.0797 = 9198/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:00:52.310] End E014 |  test loss  8.362; ppl   4280.45 | accu 0.0214 = 10825/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 15:00:52.310] Save: model.pt... 
[2022-04-13 15:00:52.909] Save: model.pt...Done. best_val_loss: 5.8809
[2022-04-13 15:00:52.909] Epoch 015/20 ==================================================
[2022-04-13 15:01:10.840] E015 |   200/667 batches | lr 1.2500 | loss  4.629 | ppl    102.43 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 15:01:28.858] E015 |   400/667 batches | lr 1.2500 | loss  4.610 | ppl    100.45 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 15:01:46.874] E015 |   600/667 batches | lr 1.2500 | loss  4.522 | ppl     91.99 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 15:01:52.882] E015 |   667/667 batches | lr 1.2500 | loss  4.453 | ppl     85.87 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 15:01:58.856] End E015 | valid loss  5.883; ppl    359.04 | accu 0.2281 = 25597/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 15:02:04.782] End E015 |  test loss  7.636; ppl   2072.46 | accu 0.0807 = 9310/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:02:31.341] End E015 |  test loss  8.328; ppl   4137.75 | accu 0.0248 = 12564/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 15:02:31.342] Epoch 016/20 ==================================================
[2022-04-13 15:02:49.200] E016 |   200/667 batches | lr 0.6250 | loss  4.610 | ppl    100.50 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 15:03:07.221] E016 |   400/667 batches | lr 0.6250 | loss  4.590 | ppl     98.50 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 15:03:25.272] E016 |   600/667 batches | lr 0.6250 | loss  4.494 | ppl     89.52 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 15:03:31.299] E016 |   667/667 batches | lr 0.6250 | loss  4.423 | ppl     83.33 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 15:03:37.334] End E016 | valid loss  5.887; ppl    360.49 | accu 0.2289 = 25686/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 15:03:43.237] End E016 |  test loss  7.647; ppl   2093.97 | accu 0.0801 = 9242/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:04:09.845] End E016 |  test loss  8.371; ppl   4318.61 | accu 0.0209 = 10606/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 15:04:09.845] Epoch 017/20 ==================================================
[2022-04-13 15:04:27.770] E017 |   200/667 batches | lr 0.3125 | loss  4.601 | ppl     99.61 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 15:04:45.806] E017 |   400/667 batches | lr 0.3125 | loss  4.579 | ppl     97.43 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 15:05:03.901] E017 |   600/667 batches | lr 0.3125 | loss  4.482 | ppl     88.40 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 15:05:09.955] E017 |   667/667 batches | lr 0.3125 | loss  4.407 | ppl     82.03 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 15:05:15.920] End E017 | valid loss  5.886; ppl    359.95 | accu 0.2294 = 25745/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 15:05:21.815] End E017 |  test loss  7.622; ppl   2042.10 | accu 0.0796 = 9179/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:05:48.429] End E017 |  test loss  8.369; ppl   4309.97 | accu 0.0207 = 10485/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 15:05:48.429] Epoch 018/20 ==================================================
[2022-04-13 15:06:06.298] E018 |   200/667 batches | lr 0.1562 | loss  4.596 | ppl     99.07 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 15:06:24.375] E018 |   400/667 batches | lr 0.1562 | loss  4.573 | ppl     96.87 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 15:06:42.507] E018 |   600/667 batches | lr 0.1562 | loss  4.473 | ppl     87.63 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 15:06:48.556] E018 |   667/667 batches | lr 0.1562 | loss  4.399 | ppl     81.34 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 15:06:54.548] End E018 | valid loss  5.884; ppl    359.38 | accu 0.2296 = 25764/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 15:07:00.413] End E018 |  test loss  7.616; ppl   2031.34 | accu 0.0794 = 9163/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:07:27.026] End E018 |  test loss  8.377; ppl   4344.94 | accu 0.0205 = 10408/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 15:07:27.026] Epoch 019/20 ==================================================
[2022-04-13 15:07:44.877] E019 |   200/667 batches | lr 0.0781 | loss  4.593 | ppl     98.80 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 15:08:02.918] E019 |   400/667 batches | lr 0.0781 | loss  4.570 | ppl     96.51 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 15:08:20.955] E019 |   600/667 batches | lr 0.0781 | loss  4.472 | ppl     87.50 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 15:08:26.990] E019 |   667/667 batches | lr 0.0781 | loss  4.391 | ppl     80.71 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 15:08:32.979] End E019 | valid loss  5.884; ppl    359.08 | accu 0.2296 = 25765/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 15:08:38.884] End E019 |  test loss  7.611; ppl   2020.45 | accu 0.0793 = 9153/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:09:05.649] End E019 |  test loss  8.377; ppl   4344.79 | accu 0.0209 = 10614/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 15:09:05.649] Epoch 020/20 ==================================================
[2022-04-13 15:09:23.497] E020 |   200/667 batches | lr 0.0391 | loss  4.589 | ppl     98.43 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 15:09:41.616] E020 |   400/667 batches | lr 0.0391 | loss  4.571 | ppl     96.69 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 15:09:59.627] E020 |   600/667 batches | lr 0.0391 | loss  4.472 | ppl     87.55 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 15:10:05.691] E020 |   667/667 batches | lr 0.0391 | loss  4.390 | ppl     80.66 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 15:10:11.633] End E020 | valid loss  5.884; ppl    359.28 | accu 0.2298 = 25787/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 15:10:17.492] End E020 |  test loss  7.606; ppl   2010.40 | accu 0.0793 = 9151/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:10:44.012] End E020 |  test loss  8.373; ppl   4329.00 | accu 0.0212 = 10766/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 15:10:50.057] End. test loss  7.64; ppl  2085.89 | accu 0.0797 = 9198/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:11:16.712] End. test loss  8.36; ppl  4280.45 | accu 0.0214 = 10825/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 15:11:16.712] =========================================================================================
[2022-04-13 15:11:16.713] valid_loss
[2022-04-13 15:11:16.713]  6.59, 6.25, 6.06, 6.01, 6.01, 5.89, 5.89, 5.90, 5.89, 5.89, 5.88, 5.88, 5.89, 5.88, 5.88, 5.89, 5.89, 5.88, 5.88, 5.88
[2022-04-13 15:11:16.713] valid_loss ppl
[2022-04-13 15:11:16.713]   729.70,  517.47,  427.71,  406.27,  409.47,  363.15,  363.09,  365.66,  359.82,  361.86,  358.99,  358.85,  361.10,  358.14,  359.04,  360.49,  359.95,  359.38,  359.08,  359.28
[2022-04-13 15:11:16.713] test_loss of ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:11:16.713]  7.83, 8.55, 7.93, 8.09, 7.87, 7.84, 7.75, 7.61, 7.68, 7.68, 7.65, 7.64, 7.77, 7.64, 7.64, 7.65, 7.62, 7.62, 7.61, 7.61
[2022-04-13 15:11:16.713] test_loss of ../data/sample_500k/cbt_valid.txt ppl
[2022-04-13 15:11:16.713]  2522.94, 5163.77, 2786.37, 3266.93, 2608.35, 2543.75, 2322.47, 2028.34, 2171.38, 2157.83, 2107.41, 2086.81, 2360.66, 2085.89, 2072.46, 2093.97, 2042.10, 2031.34, 2020.45, 2010.40
[2022-04-13 15:11:16.713] test_loss of ../data/sample_500k/adult_test.txt
[2022-04-13 15:11:16.713]  9.50,10.74, 9.47, 9.21, 8.56, 8.69, 8.76, 8.57, 8.54, 8.46, 8.44, 8.44, 8.44, 8.36, 8.33, 8.37, 8.37, 8.38, 8.38, 8.37
[2022-04-13 15:11:16.713] test_loss of ../data/sample_500k/adult_test.txt ppl
[2022-04-13 15:11:16.713] 13344.09,46020.98,13008.42,10006.18, 5224.07, 5963.61, 6370.77, 5287.30, 5122.82, 4743.50, 4637.17, 4625.72, 4630.29, 4280.45, 4137.75, 4318.61, 4309.97, 4344.94, 4344.79, 4329.00
[2022-04-13 15:11:16.713] 
[2022-04-13 15:11:16.713] 
[2022-04-13 15:11:16.713] 
Log file: ./output_wsm_Subword.500_fam_CNN.log closed.
Log file: ./output_wsm_Subword.500_fam_LSTM.log open...
[2022-04-13 15:11:16.724] corpus.train_file_list: 1
[2022-04-13 15:11:16.724]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 15:11:16.724] corpus.valid_file_list: 1
[2022-04-13 15:11:16.724]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 15:11:16.724] corpus.test_file_list: 2
[2022-04-13 15:11:16.724]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:11:16.724]         ../data/sample_500k/adult_test.txt
[2022-04-13 15:11:16.724] corpus.subword_vocab_size: 0
[2022-04-13 15:11:16.724] corpus.subword_model = None. Corpus will not use subword.
[2022-04-13 15:11:16.724] corpus tokenize...
[2022-04-13 15:11:17.785]         train tokens: 467267  ../data/sample_500k/adolescent_train.txt
[2022-04-13 15:11:18.017]         valid tokens: 112256  ../data/sample_500k/adolescent_valid.txt
[2022-04-13 15:11:18.157]         test  tokens: 115417  ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:11:18.803]         test  tokens: 506878  ../data/sample_500k/adult_test.txt
[2022-04-13 15:11:18.804] corpus.ntokens      : 95521
[2022-04-13 15:11:18.804] corpus.char_count   : 166
[2022-04-13 15:11:18.804] corpus.char_cnt_dict: 166
[2022-04-13 15:11:18.804] corpus.char_id_dict : 166
[2022-04-13 15:11:18.812] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 15:11:18.812]         tokens_all: 467267
[2022-04-13 15:11:18.812]         batched   :  23363
[2022-04-13 15:11:18.812]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 15:11:18.814] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 15:11:18.814]         tokens_all: 112256
[2022-04-13 15:11:18.814]         batched   :   5612
[2022-04-13 15:11:18.814]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 15:11:18.815] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 15:11:18.816]         tokens_all: 115417
[2022-04-13 15:11:18.816]         batched   :   5770
[2022-04-13 15:11:18.816]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:11:18.819] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 15:11:18.819]         tokens_all: 506878
[2022-04-13 15:11:18.820]         batched   :  25343
[2022-04-13 15:11:18.820]         ../data/sample_500k/adult_test.txt
[2022-04-13 15:11:18.821] subword_adapter will be generated due to word_split_mode='Subword.500'
[2022-04-13 15:11:18.821] SubwordAdapter.file_list: 2
[2022-04-13 15:11:18.821]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 15:11:18.821]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 15:11:18.821] SubwordAdapter.subword_vocab_size: 500
[2022-04-13 15:11:18.821] SubwordAdapter.subword_model.train(2 files)...
[2022-04-13 15:11:19.295] SubwordAdapter.subword_model.train(2 files)...Done
[2022-04-13 15:11:20.067] RNNModel.rnn_type: LSTM
[2022-04-13 15:11:20.067] RNNModel.ntoken  : 95521
[2022-04-13 15:11:20.067] RNNModel.ninp    : 200
[2022-04-13 15:11:20.067] RNNModel.nhid    : 200
[2022-04-13 15:11:20.067] RNNModel.nlayers : 2
[2022-04-13 15:11:20.067] RNNModel.dropout : 0.2
[2022-04-13 15:11:20.067] RNNModel.tie_weights: False
[2022-04-13 15:11:20.067] RNNModel.fragment_aggregate_mode: LSTM
[2022-04-13 15:11:20.067] RNNModel.fragment_cnt           : 502
[2022-04-13 15:11:20.068] RNNModel.fragment_emsize        : 25
[2022-04-13 15:11:20.068] RNNModel.fragment_nhid          : 200
[2022-04-13 15:11:20.068] RNNModel.fragment_embeds     : created
[2022-04-13 15:11:20.072] RNNModel.fragment_lstm       : created
[2022-04-13 15:11:20.072] RNNModel.fragment_lstm_linear: created
[2022-04-13 15:11:20.113] Epoch 001/20 ==================================================
[2022-04-13 15:12:25.657] E001 |   200/667 batches | lr 20.0000 | loss  8.588 | ppl   5366.09 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 15:13:33.358] E001 |   400/667 batches | lr 20.0000 | loss  7.749 | ppl   2320.39 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 15:14:38.408] E001 |   600/667 batches | lr 20.0000 | loss  7.218 | ppl   1363.28 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 15:15:01.434] E001 |   667/667 batches | lr 20.0000 | loss  6.889 | ppl    981.07 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 15:15:15.947] End E001 | valid loss  6.904; ppl    996.22 | accu 0.1368 = 15354/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 15:15:30.681] End E001 |  test loss  7.332; ppl   1529.15 | accu 0.1164 = 13429/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:16:36.070] End E001 |  test loss  8.347; ppl   4215.49 | accu 0.0746 = 37831/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 15:16:36.071] Save: model.pt... 
[2022-04-13 15:16:36.673] Save: model.pt...Done. best_val_loss: 6.9040
[2022-04-13 15:16:36.673] Epoch 002/20 ==================================================
[2022-04-13 15:17:41.309] E002 |   200/667 batches | lr 20.0000 | loss  6.666 | ppl    785.24 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 15:18:49.548] E002 |   400/667 batches | lr 20.0000 | loss  6.501 | ppl    665.87 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 15:19:56.588] E002 |   600/667 batches | lr 20.0000 | loss  6.279 | ppl    533.31 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 15:20:18.701] E002 |   667/667 batches | lr 20.0000 | loss  6.154 | ppl    470.43 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 15:20:33.188] End E002 | valid loss  6.266; ppl    526.44 | accu 0.1927 = 21629/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 15:20:47.798] End E002 |  test loss  8.227; ppl   3742.23 | accu 0.0700 = 8082/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:21:53.359] End E002 |  test loss 10.842; ppl  51124.97 | accu 0.0053 = 2680/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 15:21:53.359] Save: model.pt... 
[2022-04-13 15:21:53.946] Save: model.pt...Done. best_val_loss: 6.2661
[2022-04-13 15:21:53.946] Epoch 003/20 ==================================================
[2022-04-13 15:22:58.663] E003 |   200/667 batches | lr 20.0000 | loss  6.098 | ppl    445.00 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 15:24:06.320] E003 |   400/667 batches | lr 20.0000 | loss  6.027 | ppl    414.37 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 15:25:13.159] E003 |   600/667 batches | lr 20.0000 | loss  5.880 | ppl    357.92 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 15:25:35.906] E003 |   667/667 batches | lr 20.0000 | loss  5.796 | ppl    329.07 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 15:25:50.403] End E003 | valid loss  6.112; ppl    451.33 | accu 0.2000 = 22444/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 15:26:05.390] End E003 |  test loss  7.676; ppl   2156.09 | accu 0.0790 = 9116/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:27:10.538] End E003 |  test loss  9.547; ppl  13997.25 | accu 0.0071 = 3587/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 15:27:10.538] Save: model.pt... 
[2022-04-13 15:27:11.135] Save: model.pt...Done. best_val_loss: 6.1122
[2022-04-13 15:27:11.135] Epoch 004/20 ==================================================
[2022-04-13 15:28:14.960] E004 |   200/667 batches | lr 20.0000 | loss  5.755 | ppl    315.88 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 15:29:22.491] E004 |   400/667 batches | lr 20.0000 | loss  5.734 | ppl    309.14 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 15:30:28.735] E004 |   600/667 batches | lr 20.0000 | loss  5.630 | ppl    278.62 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 15:30:51.056] E004 |   667/667 batches | lr 20.0000 | loss  5.548 | ppl    256.72 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 15:31:05.579] End E004 | valid loss  6.030; ppl    415.72 | accu 0.2073 = 23260/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 15:31:19.974] End E004 |  test loss  8.174; ppl   3547.45 | accu 0.0734 = 8470/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:32:24.177] End E004 |  test loss  9.554; ppl  14096.19 | accu 0.0059 = 2978/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 15:32:24.177] Save: model.pt... 
[2022-04-13 15:32:24.777] Save: model.pt...Done. best_val_loss: 6.0300
[2022-04-13 15:32:24.778] Epoch 005/20 ==================================================
[2022-04-13 15:33:28.772] E005 |   200/667 batches | lr 20.0000 | loss  5.530 | ppl    252.13 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 15:34:35.244] E005 |   400/667 batches | lr 20.0000 | loss  5.520 | ppl    249.60 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 15:35:42.802] E005 |   600/667 batches | lr 20.0000 | loss  5.432 | ppl    228.52 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 15:36:05.395] E005 |   667/667 batches | lr 20.0000 | loss  5.354 | ppl    211.45 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 15:36:19.837] End E005 | valid loss  6.003; ppl    404.82 | accu 0.2082 = 23359/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 15:36:34.594] End E005 |  test loss  7.921; ppl   2755.71 | accu 0.0744 = 8581/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:37:39.094] End E005 |  test loss  9.939; ppl  20721.15 | accu 0.0059 = 3001/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 15:37:39.094] Save: model.pt... 
[2022-04-13 15:37:39.697] Save: model.pt...Done. best_val_loss: 6.0035
[2022-04-13 15:37:39.697] Epoch 006/20 ==================================================
[2022-04-13 15:38:45.165] E006 |   200/667 batches | lr 20.0000 | loss  5.349 | ppl    210.44 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 15:39:52.194] E006 |   400/667 batches | lr 20.0000 | loss  5.351 | ppl    210.73 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 15:40:58.365] E006 |   600/667 batches | lr 20.0000 | loss  5.260 | ppl    192.39 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 15:41:20.312] E006 |   667/667 batches | lr 20.0000 | loss  5.199 | ppl    181.05 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 15:41:34.621] End E006 | valid loss  6.006; ppl    405.94 | accu 0.2087 = 23421/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 15:41:49.182] End E006 |  test loss  8.020; ppl   3039.95 | accu 0.0727 = 8388/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:42:54.905] End E006 |  test loss  9.592; ppl  14641.73 | accu 0.0103 = 5217/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 15:42:54.905] Epoch 007/20 ==================================================
[2022-04-13 15:43:59.090] E007 |   200/667 batches | lr 10.0000 | loss  5.096 | ppl    163.42 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 15:45:07.257] E007 |   400/667 batches | lr 10.0000 | loss  5.052 | ppl    156.37 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 15:46:13.922] E007 |   600/667 batches | lr 10.0000 | loss  4.948 | ppl    140.96 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 15:46:36.134] E007 |   667/667 batches | lr 10.0000 | loss  4.865 | ppl    129.66 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 15:46:50.528] End E007 | valid loss  5.934; ppl    377.63 | accu 0.2158 = 24220/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 15:47:04.867] End E007 |  test loss  7.720; ppl   2252.41 | accu 0.0741 = 8548/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:48:10.262] End E007 |  test loss  9.600; ppl  14767.20 | accu 0.0064 = 3242/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 15:48:10.262] Save: model.pt... 
[2022-04-13 15:48:10.848] Save: model.pt...Done. best_val_loss: 5.9339
[2022-04-13 15:48:10.848] Epoch 008/20 ==================================================
[2022-04-13 15:49:16.436] E008 |   200/667 batches | lr 10.0000 | loss  4.951 | ppl    141.32 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 15:50:24.000] E008 |   400/667 batches | lr 10.0000 | loss  4.935 | ppl    139.10 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 15:51:32.224] E008 |   600/667 batches | lr 10.0000 | loss  4.849 | ppl    127.62 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 15:51:54.886] E008 |   667/667 batches | lr 10.0000 | loss  4.773 | ppl    118.29 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 15:52:09.566] End E008 | valid loss  5.958; ppl    386.74 | accu 0.2181 = 24471/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 15:52:24.138] End E008 |  test loss  7.748; ppl   2316.54 | accu 0.0759 = 8757/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:53:28.616] End E008 |  test loss  9.449; ppl  12696.47 | accu 0.0102 = 5189/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 15:53:28.617] Epoch 009/20 ==================================================
[2022-04-13 15:54:33.053] E009 |   200/667 batches | lr 5.0000 | loss  4.820 | ppl    123.96 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 15:55:41.667] E009 |   400/667 batches | lr 5.0000 | loss  4.782 | ppl    119.34 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 15:56:49.877] E009 |   600/667 batches | lr 5.0000 | loss  4.676 | ppl    107.39 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 15:57:11.983] E009 |   667/667 batches | lr 5.0000 | loss  4.590 | ppl     98.46 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 15:57:26.900] End E009 | valid loss  5.940; ppl    380.00 | accu 0.2227 = 24991/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 15:57:41.438] End E009 |  test loss  7.607; ppl   2012.94 | accu 0.0789 = 9107/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 15:58:46.795] End E009 |  test loss  9.532; ppl  13793.15 | accu 0.0088 = 4482/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 15:58:46.795] Epoch 010/20 ==================================================
[2022-04-13 15:59:51.561] E010 |   200/667 batches | lr 2.5000 | loss  4.739 | ppl    114.36 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 16:00:57.867] E010 |   400/667 batches | lr 2.5000 | loss  4.694 | ppl    109.33 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 16:02:05.775] E010 |   600/667 batches | lr 2.5000 | loss  4.586 | ppl     98.09 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 16:02:28.395] E010 |   667/667 batches | lr 2.5000 | loss  4.502 | ppl     90.24 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 16:02:42.885] End E010 | valid loss  5.913; ppl    369.80 | accu 0.2254 = 25296/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 16:02:57.166] End E010 |  test loss  7.470; ppl   1754.97 | accu 0.0819 = 9454/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 16:04:01.813] End E010 |  test loss  9.206; ppl   9960.89 | accu 0.0105 = 5335/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 16:04:01.813] Save: model.pt... 
[2022-04-13 16:04:02.405] Save: model.pt...Done. best_val_loss: 5.9130
[2022-04-13 16:04:02.405] Epoch 011/20 ==================================================
[2022-04-13 16:05:08.553] E011 |   200/667 batches | lr 2.5000 | loss  4.687 | ppl    108.58 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 16:06:17.162] E011 |   400/667 batches | lr 2.5000 | loss  4.656 | ppl    105.20 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 16:07:24.001] E011 |   600/667 batches | lr 2.5000 | loss  4.557 | ppl     95.34 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 16:07:46.457] E011 |   667/667 batches | lr 2.5000 | loss  4.478 | ppl     88.06 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 16:08:01.111] End E011 | valid loss  5.923; ppl    373.67 | accu 0.2257 = 25329/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 16:08:15.934] End E011 |  test loss  7.463; ppl   1743.15 | accu 0.0823 = 9499/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 16:09:21.054] End E011 |  test loss  9.025; ppl   8308.41 | accu 0.0138 = 6973/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 16:09:21.054] Epoch 012/20 ==================================================
[2022-04-13 16:10:25.416] E012 |   200/667 batches | lr 1.2500 | loss  4.652 | ppl    104.81 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 16:11:32.467] E012 |   400/667 batches | lr 1.2500 | loss  4.616 | ppl    101.10 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 16:12:39.210] E012 |   600/667 batches | lr 1.2500 | loss  4.510 | ppl     90.95 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 16:13:02.458] E012 |   667/667 batches | lr 1.2500 | loss  4.421 | ppl     83.20 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 16:13:17.184] End E012 | valid loss  5.918; ppl    371.54 | accu 0.2262 = 25388/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 16:13:32.126] End E012 |  test loss  7.441; ppl   1705.27 | accu 0.0841 = 9704/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 16:14:38.234] End E012 |  test loss  8.916; ppl   7453.53 | accu 0.0154 = 7782/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 16:14:38.235] Epoch 013/20 ==================================================
[2022-04-13 16:15:43.241] E013 |   200/667 batches | lr 0.6250 | loss  4.631 | ppl    102.65 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 16:16:51.255] E013 |   400/667 batches | lr 0.6250 | loss  4.596 | ppl     99.04 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 16:17:58.287] E013 |   600/667 batches | lr 0.6250 | loss  4.487 | ppl     88.86 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 16:18:20.572] E013 |   667/667 batches | lr 0.6250 | loss  4.395 | ppl     81.06 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 16:18:35.376] End E013 | valid loss  5.914; ppl    370.27 | accu 0.2275 = 25525/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 16:18:50.128] End E013 |  test loss  7.431; ppl   1688.23 | accu 0.0841 = 9703/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 16:19:56.284] End E013 |  test loss  8.918; ppl   7467.91 | accu 0.0147 = 7438/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 16:19:56.284] Epoch 014/20 ==================================================
[2022-04-13 16:21:01.623] E014 |   200/667 batches | lr 0.3125 | loss  4.617 | ppl    101.17 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 16:22:10.116] E014 |   400/667 batches | lr 0.3125 | loss  4.581 | ppl     97.61 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 16:23:18.476] E014 |   600/667 batches | lr 0.3125 | loss  4.472 | ppl     87.55 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 16:23:41.278] E014 |   667/667 batches | lr 0.3125 | loss  4.384 | ppl     80.17 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 16:23:56.030] End E014 | valid loss  5.910; ppl    368.84 | accu 0.2282 = 25611/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 16:24:10.585] End E014 |  test loss  7.418; ppl   1666.45 | accu 0.0851 = 9818/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 16:25:15.201] End E014 |  test loss  8.890; ppl   7261.05 | accu 0.0156 = 7917/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 16:25:15.201] Save: model.pt... 
[2022-04-13 16:25:15.797] Save: model.pt...Done. best_val_loss: 5.9104
[2022-04-13 16:25:15.797] Epoch 015/20 ==================================================
[2022-04-13 16:26:20.431] E015 |   200/667 batches | lr 0.3125 | loss  4.611 | ppl    100.60 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 16:27:27.875] E015 |   400/667 batches | lr 0.3125 | loss  4.576 | ppl     97.15 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 16:28:35.381] E015 |   600/667 batches | lr 0.3125 | loss  4.469 | ppl     87.24 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 16:28:57.958] E015 |   667/667 batches | lr 0.3125 | loss  4.385 | ppl     80.25 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 16:29:12.543] End E015 | valid loss  5.910; ppl    368.65 | accu 0.2283 = 25618/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 16:29:27.197] End E015 |  test loss  7.411; ppl   1654.79 | accu 0.0855 = 9861/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 16:30:33.343] End E015 |  test loss  8.870; ppl   7115.24 | accu 0.0163 = 8244/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 16:30:33.343] Save: model.pt... 
[2022-04-13 16:30:33.938] Save: model.pt...Done. best_val_loss: 5.9099
[2022-04-13 16:30:33.938] Epoch 016/20 ==================================================
[2022-04-13 16:31:39.176] E016 |   200/667 batches | lr 0.3125 | loss  4.602 | ppl     99.71 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 16:32:47.790] E016 |   400/667 batches | lr 0.3125 | loss  4.570 | ppl     96.52 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 16:33:55.522] E016 |   600/667 batches | lr 0.3125 | loss  4.465 | ppl     86.96 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 16:34:18.343] E016 |   667/667 batches | lr 0.3125 | loss  4.382 | ppl     79.96 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 16:34:33.004] End E016 | valid loss  5.910; ppl    368.53 | accu 0.2285 = 25639/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 16:34:47.717] End E016 |  test loss  7.414; ppl   1659.79 | accu 0.0854 = 9855/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 16:35:53.129] End E016 |  test loss  8.873; ppl   7133.53 | accu 0.0160 = 8116/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 16:35:53.129] Save: model.pt... 
[2022-04-13 16:35:53.739] Save: model.pt...Done. best_val_loss: 5.9095
[2022-04-13 16:35:53.739] Epoch 017/20 ==================================================
[2022-04-13 16:36:58.736] E017 |   200/667 batches | lr 0.3125 | loss  4.596 | ppl     99.13 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 16:38:06.774] E017 |   400/667 batches | lr 0.3125 | loss  4.565 | ppl     96.09 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 16:39:13.556] E017 |   600/667 batches | lr 0.3125 | loss  4.463 | ppl     86.75 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 16:39:36.492] E017 |   667/667 batches | lr 0.3125 | loss  4.378 | ppl     79.66 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 16:39:51.144] End E017 | valid loss  5.911; ppl    369.24 | accu 0.2288 = 25678/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 16:40:05.783] End E017 |  test loss  7.401; ppl   1638.24 | accu 0.0856 = 9881/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 16:41:11.686] End E017 |  test loss  8.865; ppl   7079.41 | accu 0.0163 = 8250/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 16:41:11.686] Epoch 018/20 ==================================================
[2022-04-13 16:42:18.247] E018 |   200/667 batches | lr 0.1562 | loss  4.593 | ppl     98.79 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 16:43:26.114] E018 |   400/667 batches | lr 0.1562 | loss  4.558 | ppl     95.38 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 16:44:32.516] E018 |   600/667 batches | lr 0.1562 | loss  4.455 | ppl     86.05 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 16:44:54.641] E018 |   667/667 batches | lr 0.1562 | loss  4.364 | ppl     78.60 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 16:45:08.938] End E018 | valid loss  5.911; ppl    369.25 | accu 0.2287 = 25660/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 16:45:23.320] End E018 |  test loss  7.406; ppl   1646.23 | accu 0.0855 = 9861/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 16:46:27.294] End E018 |  test loss  8.850; ppl   6971.74 | accu 0.0168 = 8516/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 16:46:27.295] Epoch 019/20 ==================================================
[2022-04-13 16:47:31.973] E019 |   200/667 batches | lr 0.0781 | loss  4.591 | ppl     98.57 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 16:48:39.353] E019 |   400/667 batches | lr 0.0781 | loss  4.558 | ppl     95.35 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 16:49:46.172] E019 |   600/667 batches | lr 0.0781 | loss  4.451 | ppl     85.72 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 16:50:08.244] E019 |   667/667 batches | lr 0.0781 | loss  4.365 | ppl     78.62 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 16:50:22.698] End E019 | valid loss  5.913; ppl    369.81 | accu 0.2288 = 25671/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 16:50:37.160] End E019 |  test loss  7.399; ppl   1634.76 | accu 0.0858 = 9899/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 16:51:41.164] End E019 |  test loss  8.835; ppl   6871.35 | accu 0.0173 = 8763/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 16:51:41.164] Epoch 020/20 ==================================================
[2022-04-13 16:52:46.000] E020 |   200/667 batches | lr 0.0391 | loss  4.591 | ppl     98.56 frag_cnt/word_cnt=2.609=365242/140000
[2022-04-13 16:53:53.804] E020 |   400/667 batches | lr 0.0391 | loss  4.555 | ppl     95.08 frag_cnt/word_cnt=2.646=370388/140000
[2022-04-13 16:54:59.352] E020 |   600/667 batches | lr 0.0391 | loss  4.449 | ppl     85.52 frag_cnt/word_cnt=2.630=368153/140000
[2022-04-13 16:55:21.889] E020 |   667/667 batches | lr 0.0391 | loss  4.360 | ppl     78.22 frag_cnt/word_cnt=2.618=122782/46900
[2022-04-13 16:55:36.026] End E020 | valid loss  5.914; ppl    370.05 | accu 0.2288 = 25674/112220 | w_len 2.5007 = 280626/112220
[2022-04-13 16:55:50.321] End E020 |  test loss  7.397; ppl   1631.56 | accu 0.0859 = 9908/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 16:56:54.711] End E020 |  test loss  8.828; ppl   6823.73 | accu 0.0174 = 8821/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 16:57:09.237] End. test loss  7.41; ppl  1659.79 | accu 0.0854 = 9855/115380 | w_len 1.8144 = 209350/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 16:58:13.671] End. test loss  8.87; ppl  7133.53 | accu 0.0160 = 8116/506840 | w_len 2.4840 = 1258997/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 16:58:13.671] =========================================================================================
[2022-04-13 16:58:13.671] valid_loss
[2022-04-13 16:58:13.671]  6.90, 6.27, 6.11, 6.03, 6.00, 6.01, 5.93, 5.96, 5.94, 5.91, 5.92, 5.92, 5.91, 5.91, 5.91, 5.91, 5.91, 5.91, 5.91, 5.91
[2022-04-13 16:58:13.671] valid_loss ppl
[2022-04-13 16:58:13.671]   996.22,  526.44,  451.33,  415.72,  404.82,  405.94,  377.63,  386.74,  380.00,  369.80,  373.67,  371.54,  370.27,  368.84,  368.65,  368.53,  369.24,  369.25,  369.81,  370.05
[2022-04-13 16:58:13.671] test_loss of ../data/sample_500k/cbt_valid.txt
[2022-04-13 16:58:13.671]  7.33, 8.23, 7.68, 8.17, 7.92, 8.02, 7.72, 7.75, 7.61, 7.47, 7.46, 7.44, 7.43, 7.42, 7.41, 7.41, 7.40, 7.41, 7.40, 7.40
[2022-04-13 16:58:13.672] test_loss of ../data/sample_500k/cbt_valid.txt ppl
[2022-04-13 16:58:13.672]  1529.15, 3742.23, 2156.09, 3547.45, 2755.71, 3039.95, 2252.41, 2316.54, 2012.94, 1754.97, 1743.15, 1705.27, 1688.23, 1666.45, 1654.79, 1659.79, 1638.24, 1646.23, 1634.76, 1631.56
[2022-04-13 16:58:13.672] test_loss of ../data/sample_500k/adult_test.txt
[2022-04-13 16:58:13.672]  8.35,10.84, 9.55, 9.55, 9.94, 9.59, 9.60, 9.45, 9.53, 9.21, 9.03, 8.92, 8.92, 8.89, 8.87, 8.87, 8.86, 8.85, 8.84, 8.83
[2022-04-13 16:58:13.672] test_loss of ../data/sample_500k/adult_test.txt ppl
[2022-04-13 16:58:13.672]  4215.49,51124.97,13997.25,14096.19,20721.15,14641.73,14767.20,12696.47,13793.15, 9960.89, 8308.41, 7453.53, 7467.91, 7261.05, 7115.24, 7133.53, 7079.41, 6971.74, 6871.35, 6823.73
[2022-04-13 16:58:13.672] 
[2022-04-13 16:58:13.672] 
[2022-04-13 16:58:13.672] 
Log file: ./output_wsm_Subword.500_fam_LSTM.log closed.
Log file: ./output_wsm_Subword.1000_fam_CNN.log open...
[2022-04-13 16:58:13.685] corpus.train_file_list: 1
[2022-04-13 16:58:13.685]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 16:58:13.685] corpus.valid_file_list: 1
[2022-04-13 16:58:13.685]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 16:58:13.685] corpus.test_file_list: 2
[2022-04-13 16:58:13.685]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 16:58:13.685]         ../data/sample_500k/adult_test.txt
[2022-04-13 16:58:13.685] corpus.subword_vocab_size: 0
[2022-04-13 16:58:13.685] corpus.subword_model = None. Corpus will not use subword.
[2022-04-13 16:58:13.685] corpus tokenize...
[2022-04-13 16:58:14.736]         train tokens: 467267  ../data/sample_500k/adolescent_train.txt
[2022-04-13 16:58:14.980]         valid tokens: 112256  ../data/sample_500k/adolescent_valid.txt
[2022-04-13 16:58:15.139]         test  tokens: 115417  ../data/sample_500k/cbt_valid.txt
[2022-04-13 16:58:15.787]         test  tokens: 506878  ../data/sample_500k/adult_test.txt
[2022-04-13 16:58:15.787] corpus.ntokens      : 95521
[2022-04-13 16:58:15.787] corpus.char_count   : 166
[2022-04-13 16:58:15.787] corpus.char_cnt_dict: 166
[2022-04-13 16:58:15.787] corpus.char_id_dict : 166
[2022-04-13 16:58:15.796] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 16:58:15.797]         tokens_all: 467267
[2022-04-13 16:58:15.797]         batched   :  23363
[2022-04-13 16:58:15.797]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 16:58:15.800] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 16:58:15.800]         tokens_all: 112256
[2022-04-13 16:58:15.801]         batched   :   5612
[2022-04-13 16:58:15.801]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 16:58:15.802] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 16:58:15.802]         tokens_all: 115417
[2022-04-13 16:58:15.802]         batched   :   5770
[2022-04-13 16:58:15.802]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 16:58:15.808] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 16:58:15.808]         tokens_all: 506878
[2022-04-13 16:58:15.808]         batched   :  25343
[2022-04-13 16:58:15.809]         ../data/sample_500k/adult_test.txt
[2022-04-13 16:58:15.809] subword_adapter will be generated due to word_split_mode='Subword.1000'
[2022-04-13 16:58:15.810] SubwordAdapter.file_list: 2
[2022-04-13 16:58:15.810]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 16:58:15.810]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 16:58:15.810] SubwordAdapter.subword_vocab_size: 1000
[2022-04-13 16:58:15.810] SubwordAdapter.subword_model.train(2 files)...
[2022-04-13 16:58:16.364] SubwordAdapter.subword_model.train(2 files)...Done
[2022-04-13 16:58:17.015] RNNModel.rnn_type: LSTM
[2022-04-13 16:58:17.015] RNNModel.ntoken  : 95521
[2022-04-13 16:58:17.015] RNNModel.ninp    : 200
[2022-04-13 16:58:17.015] RNNModel.nhid    : 200
[2022-04-13 16:58:17.015] RNNModel.nlayers : 2
[2022-04-13 16:58:17.015] RNNModel.dropout : 0.2
[2022-04-13 16:58:17.015] RNNModel.tie_weights: False
[2022-04-13 16:58:17.015] RNNModel.fragment_aggregate_mode: CNN
[2022-04-13 16:58:17.016] RNNModel.fragment_cnt           : 1002
[2022-04-13 16:58:17.016] RNNModel.fragment_emsize        : 25
[2022-04-13 16:58:17.016] RNNModel.fragment_nhid          : 200
[2022-04-13 16:58:17.017] RNNModel.fragment_embeds     : created
[2022-04-13 16:58:17.017] RNNModel.fragment_cnn3       : created
[2022-04-13 16:58:17.058] Epoch 001/20 ==================================================
[2022-04-13 16:58:34.755] E001 |   200/667 batches | lr 20.0000 | loss  8.550 | ppl   5168.85 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 16:58:52.599] E001 |   400/667 batches | lr 20.0000 | loss  7.643 | ppl   2085.53 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 16:59:10.401] E001 |   600/667 batches | lr 20.0000 | loss  7.043 | ppl   1145.24 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 16:59:16.362] E001 |   667/667 batches | lr 20.0000 | loss  6.715 | ppl    824.98 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 16:59:22.351] End E001 | valid loss  6.664; ppl    783.39 | accu 0.1679 = 18844/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 16:59:28.241] End E001 |  test loss  7.751; ppl   2323.45 | accu 0.0691 = 7975/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 16:59:54.728] End E001 |  test loss  8.693; ppl   5960.04 | accu 0.0333 = 16856/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 16:59:54.728] Save: model.pt... 
[2022-04-13 16:59:55.343] Save: model.pt...Done. best_val_loss: 6.6636
[2022-04-13 16:59:55.343] Epoch 002/20 ==================================================
[2022-04-13 17:00:13.215] E002 |   200/667 batches | lr 20.0000 | loss  6.556 | ppl    703.43 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:00:31.075] E002 |   400/667 batches | lr 20.0000 | loss  6.404 | ppl    604.36 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:00:49.087] E002 |   600/667 batches | lr 20.0000 | loss  6.193 | ppl    489.29 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:00:55.086] E002 |   667/667 batches | lr 20.0000 | loss  6.062 | ppl    429.27 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:01:01.062] End E002 | valid loss  6.240; ppl    512.67 | accu 0.1860 = 20877/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:01:06.888] End E002 |  test loss  8.447; ppl   4662.75 | accu 0.0590 = 6804/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:01:33.197] End E002 |  test loss 10.173; ppl  26177.03 | accu 0.0115 = 5811/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:01:33.197] Save: model.pt... 
[2022-04-13 17:01:33.787] Save: model.pt...Done. best_val_loss: 6.2396
[2022-04-13 17:01:33.787] Epoch 003/20 ==================================================
[2022-04-13 17:01:51.635] E003 |   200/667 batches | lr 20.0000 | loss  6.047 | ppl    422.73 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:02:09.599] E003 |   400/667 batches | lr 20.0000 | loss  6.004 | ppl    405.16 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:02:27.242] E003 |   600/667 batches | lr 20.0000 | loss  5.862 | ppl    351.44 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:02:33.283] E003 |   667/667 batches | lr 20.0000 | loss  5.779 | ppl    323.49 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:02:39.247] End E003 | valid loss  6.337; ppl    564.98 | accu 0.1729 = 19401/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:02:45.107] End E003 |  test loss  7.577; ppl   1952.12 | accu 0.0746 = 8603/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:03:11.472] End E003 |  test loss  9.210; ppl  10001.23 | accu 0.0114 = 5790/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:03:11.472] Epoch 004/20 ==================================================
[2022-04-13 17:03:29.168] E004 |   200/667 batches | lr 10.0000 | loss  5.659 | ppl    286.87 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:03:46.998] E004 |   400/667 batches | lr 10.0000 | loss  5.615 | ppl    274.60 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:04:04.982] E004 |   600/667 batches | lr 10.0000 | loss  5.480 | ppl    239.90 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:04:10.963] E004 |   667/667 batches | lr 10.0000 | loss  5.399 | ppl    221.14 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:04:16.923] End E004 | valid loss  5.939; ppl    379.67 | accu 0.2139 = 24006/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:04:22.805] End E004 |  test loss  8.336; ppl   4171.16 | accu 0.0695 = 8022/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:04:49.178] End E004 |  test loss 10.343; ppl  31024.16 | accu 0.0061 = 3095/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:04:49.178] Save: model.pt... 
[2022-04-13 17:04:49.787] Save: model.pt...Done. best_val_loss: 5.9393
[2022-04-13 17:04:49.787] Epoch 005/20 ==================================================
[2022-04-13 17:05:07.779] E005 |   200/667 batches | lr 10.0000 | loss  5.470 | ppl    237.37 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:05:25.730] E005 |   400/667 batches | lr 10.0000 | loss  5.456 | ppl    234.06 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:05:43.703] E005 |   600/667 batches | lr 10.0000 | loss  5.343 | ppl    209.19 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:05:49.731] E005 |   667/667 batches | lr 10.0000 | loss  5.269 | ppl    194.22 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:05:55.638] End E005 | valid loss  5.920; ppl    372.50 | accu 0.2164 = 24286/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:06:01.494] End E005 |  test loss  8.450; ppl   4674.96 | accu 0.0718 = 8283/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:06:27.840] End E005 |  test loss 10.270; ppl  28844.76 | accu 0.0083 = 4216/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:06:27.840] Save: model.pt... 
[2022-04-13 17:06:28.438] Save: model.pt...Done. best_val_loss: 5.9202
[2022-04-13 17:06:28.438] Epoch 006/20 ==================================================
[2022-04-13 17:06:46.339] E006 |   200/667 batches | lr 10.0000 | loss  5.332 | ppl    206.95 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:07:04.391] E006 |   400/667 batches | lr 10.0000 | loss  5.330 | ppl    206.41 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:07:22.402] E006 |   600/667 batches | lr 10.0000 | loss  5.230 | ppl    186.83 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:07:28.410] E006 |   667/667 batches | lr 10.0000 | loss  5.160 | ppl    174.18 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:07:34.315] End E006 | valid loss  5.891; ppl    361.65 | accu 0.2184 = 24514/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:07:40.145] End E006 |  test loss  8.003; ppl   2989.70 | accu 0.0741 = 8550/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:08:06.646] End E006 |  test loss  9.604; ppl  14821.27 | accu 0.0130 = 6593/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:08:06.647] Save: model.pt... 
[2022-04-13 17:08:07.250] Save: model.pt...Done. best_val_loss: 5.8907
[2022-04-13 17:08:07.250] Epoch 007/20 ==================================================
[2022-04-13 17:08:24.907] E007 |   200/667 batches | lr 10.0000 | loss  5.219 | ppl    184.72 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:08:42.926] E007 |   400/667 batches | lr 10.0000 | loss  5.219 | ppl    184.78 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:09:00.768] E007 |   600/667 batches | lr 10.0000 | loss  5.128 | ppl    168.71 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:09:06.654] E007 |   667/667 batches | lr 10.0000 | loss  5.059 | ppl    157.45 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:09:12.571] End E007 | valid loss  5.895; ppl    363.26 | accu 0.2194 = 24624/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:09:18.404] End E007 |  test loss  8.114; ppl   3340.35 | accu 0.0755 = 8713/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:09:44.762] End E007 |  test loss  9.780; ppl  17672.43 | accu 0.0111 = 5619/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:09:44.762] Epoch 008/20 ==================================================
[2022-04-13 17:10:02.590] E008 |   200/667 batches | lr 5.0000 | loss  5.077 | ppl    160.29 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:10:20.653] E008 |   400/667 batches | lr 5.0000 | loss  5.052 | ppl    156.34 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:10:38.658] E008 |   600/667 batches | lr 5.0000 | loss  4.940 | ppl    139.79 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:10:44.741] E008 |   667/667 batches | lr 5.0000 | loss  4.863 | ppl    129.41 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:10:50.640] End E008 | valid loss  5.866; ppl    353.00 | accu 0.2238 = 25117/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:10:56.439] End E008 |  test loss  8.043; ppl   3110.84 | accu 0.0780 = 9003/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:11:22.672] End E008 |  test loss  9.394; ppl  12021.07 | accu 0.0136 = 6917/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:11:22.672] Save: model.pt... 
[2022-04-13 17:11:23.294] Save: model.pt...Done. best_val_loss: 5.8665
[2022-04-13 17:11:23.294] Epoch 009/20 ==================================================
[2022-04-13 17:11:41.192] E009 |   200/667 batches | lr 5.0000 | loss  4.988 | ppl    146.64 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:11:59.170] E009 |   400/667 batches | lr 5.0000 | loss  4.979 | ppl    145.28 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:12:17.128] E009 |   600/667 batches | lr 5.0000 | loss  4.881 | ppl    131.81 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:12:23.064] E009 |   667/667 batches | lr 5.0000 | loss  4.812 | ppl    122.99 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:12:28.975] End E009 | valid loss  5.863; ppl    351.72 | accu 0.2241 = 25152/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:12:34.791] End E009 |  test loss  8.012; ppl   3017.60 | accu 0.0796 = 9188/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:13:01.259] End E009 |  test loss  9.340; ppl  11383.32 | accu 0.0175 = 8855/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:13:01.259] Save: model.pt... 
[2022-04-13 17:13:01.889] Save: model.pt...Done. best_val_loss: 5.8628
[2022-04-13 17:13:01.889] Epoch 010/20 ==================================================
[2022-04-13 17:13:19.694] E010 |   200/667 batches | lr 5.0000 | loss  4.925 | ppl    137.74 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:13:37.638] E010 |   400/667 batches | lr 5.0000 | loss  4.920 | ppl    136.97 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:13:55.358] E010 |   600/667 batches | lr 5.0000 | loss  4.830 | ppl    125.26 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:14:01.394] E010 |   667/667 batches | lr 5.0000 | loss  4.765 | ppl    117.39 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:14:07.289] End E010 | valid loss  5.874; ppl    355.67 | accu 0.2247 = 25219/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:14:13.096] End E010 |  test loss  8.089; ppl   3259.54 | accu 0.0780 = 8999/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:14:39.414] End E010 |  test loss  9.379; ppl  11836.83 | accu 0.0165 = 8351/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:14:39.414] Epoch 011/20 ==================================================
[2022-04-13 17:14:57.345] E011 |   200/667 batches | lr 2.5000 | loss  4.856 | ppl    128.52 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:15:15.206] E011 |   400/667 batches | lr 2.5000 | loss  4.836 | ppl    125.91 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:15:33.220] E011 |   600/667 batches | lr 2.5000 | loss  4.732 | ppl    113.56 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:15:39.214] E011 |   667/667 batches | lr 2.5000 | loss  4.657 | ppl    105.29 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:15:45.131] End E011 | valid loss  5.857; ppl    349.80 | accu 0.2277 = 25548/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:15:50.928] End E011 |  test loss  8.077; ppl   3218.50 | accu 0.0828 = 9554/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:16:17.199] End E011 |  test loss  9.275; ppl  10664.46 | accu 0.0200 = 10142/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:16:17.200] Save: model.pt... 
[2022-04-13 17:16:17.814] Save: model.pt...Done. best_val_loss: 5.8574
[2022-04-13 17:16:17.814] Epoch 012/20 ==================================================
[2022-04-13 17:16:35.731] E012 |   200/667 batches | lr 2.5000 | loss  4.809 | ppl    122.64 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:16:53.697] E012 |   400/667 batches | lr 2.5000 | loss  4.798 | ppl    121.24 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:17:11.779] E012 |   600/667 batches | lr 2.5000 | loss  4.705 | ppl    110.53 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:17:17.824] E012 |   667/667 batches | lr 2.5000 | loss  4.634 | ppl    102.95 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:17:23.792] End E012 | valid loss  5.862; ppl    351.26 | accu 0.2271 = 25487/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:17:29.623] End E012 |  test loss  8.035; ppl   3086.32 | accu 0.0830 = 9576/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:17:56.050] End E012 |  test loss  9.144; ppl   9354.05 | accu 0.0240 = 12188/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:17:56.050] Epoch 013/20 ==================================================
[2022-04-13 17:18:14.209] E013 |   200/667 batches | lr 1.2500 | loss  4.774 | ppl    118.39 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:18:32.205] E013 |   400/667 batches | lr 1.2500 | loss  4.755 | ppl    116.18 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:18:50.207] E013 |   600/667 batches | lr 1.2500 | loss  4.652 | ppl    104.78 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:18:56.250] E013 |   667/667 batches | lr 1.2500 | loss  4.579 | ppl     97.42 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:19:02.123] End E013 | valid loss  5.857; ppl    349.54 | accu 0.2286 = 25653/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:19:07.902] End E013 |  test loss  8.084; ppl   3242.09 | accu 0.0843 = 9726/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:19:34.211] End E013 |  test loss  9.182; ppl   9721.37 | accu 0.0228 = 11570/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:19:34.211] Save: model.pt... 
[2022-04-13 17:19:34.826] Save: model.pt...Done. best_val_loss: 5.8566
[2022-04-13 17:19:34.826] Epoch 014/20 ==================================================
[2022-04-13 17:19:52.662] E014 |   200/667 batches | lr 1.2500 | loss  4.749 | ppl    115.48 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:20:10.690] E014 |   400/667 batches | lr 1.2500 | loss  4.736 | ppl    114.01 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:20:28.617] E014 |   600/667 batches | lr 1.2500 | loss  4.641 | ppl    103.65 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:20:34.638] E014 |   667/667 batches | lr 1.2500 | loss  4.569 | ppl     96.44 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:20:40.532] End E014 | valid loss  5.858; ppl    350.16 | accu 0.2289 = 25687/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:20:46.329] End E014 |  test loss  8.089; ppl   3259.57 | accu 0.0840 = 9693/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:21:12.581] End E014 |  test loss  9.181; ppl   9706.92 | accu 0.0224 = 11376/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:21:12.582] Epoch 015/20 ==================================================
[2022-04-13 17:21:30.505] E015 |   200/667 batches | lr 0.6250 | loss  4.731 | ppl    113.40 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:21:48.482] E015 |   400/667 batches | lr 0.6250 | loss  4.715 | ppl    111.57 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:22:06.501] E015 |   600/667 batches | lr 0.6250 | loss  4.614 | ppl    100.93 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:22:12.490] E015 |   667/667 batches | lr 0.6250 | loss  4.534 | ppl     93.12 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:22:18.326] End E015 | valid loss  5.857; ppl    349.61 | accu 0.2294 = 25741/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:22:24.158] End E015 |  test loss  8.044; ppl   3115.74 | accu 0.0861 = 9931/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:22:50.525] End E015 |  test loss  9.149; ppl   9405.86 | accu 0.0255 = 12904/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:22:50.525] Epoch 016/20 ==================================================
[2022-04-13 17:23:08.005] E016 |   200/667 batches | lr 0.3125 | loss  4.719 | ppl    112.09 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:23:25.601] E016 |   400/667 batches | lr 0.3125 | loss  4.698 | ppl    109.74 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:23:43.574] E016 |   600/667 batches | lr 0.3125 | loss  4.598 | ppl     99.26 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:23:49.617] E016 |   667/667 batches | lr 0.3125 | loss  4.520 | ppl     91.83 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:23:55.581] End E016 | valid loss  5.854; ppl    348.79 | accu 0.2301 = 25822/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:24:01.429] End E016 |  test loss  8.038; ppl   3096.35 | accu 0.0855 = 9867/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:24:27.927] End E016 |  test loss  9.152; ppl   9437.31 | accu 0.0250 = 12690/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:24:27.928] Save: model.pt... 
[2022-04-13 17:24:28.531] Save: model.pt...Done. best_val_loss: 5.8545
[2022-04-13 17:24:28.531] Epoch 017/20 ==================================================
[2022-04-13 17:24:46.366] E017 |   200/667 batches | lr 0.3125 | loss  4.710 | ppl    111.09 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:25:04.182] E017 |   400/667 batches | lr 0.3125 | loss  4.696 | ppl    109.54 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:25:21.882] E017 |   600/667 batches | lr 0.3125 | loss  4.593 | ppl     98.79 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:25:27.978] E017 |   667/667 batches | lr 0.3125 | loss  4.523 | ppl     92.07 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:25:33.952] End E017 | valid loss  5.855; ppl    349.11 | accu 0.2302 = 25830/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:25:39.819] End E017 |  test loss  8.060; ppl   3164.75 | accu 0.0854 = 9849/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:26:06.258] End E017 |  test loss  9.176; ppl   9662.11 | accu 0.0249 = 12637/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:26:06.258] Epoch 018/20 ==================================================
[2022-04-13 17:26:24.145] E018 |   200/667 batches | lr 0.1562 | loss  4.706 | ppl    110.64 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:26:42.141] E018 |   400/667 batches | lr 0.1562 | loss  4.690 | ppl    108.84 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:27:00.010] E018 |   600/667 batches | lr 0.1562 | loss  4.589 | ppl     98.36 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:27:06.052] E018 |   667/667 batches | lr 0.1562 | loss  4.512 | ppl     91.06 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:27:11.997] End E018 | valid loss  5.855; ppl    349.05 | accu 0.2307 = 25893/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:27:17.837] End E018 |  test loss  8.053; ppl   3143.19 | accu 0.0851 = 9816/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:27:44.378] End E018 |  test loss  9.166; ppl   9567.13 | accu 0.0248 = 12564/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:27:44.379] Epoch 019/20 ==================================================
[2022-04-13 17:28:02.122] E019 |   200/667 batches | lr 0.0781 | loss  4.704 | ppl    110.35 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:28:20.194] E019 |   400/667 batches | lr 0.0781 | loss  4.686 | ppl    108.43 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:28:38.261] E019 |   600/667 batches | lr 0.0781 | loss  4.583 | ppl     97.83 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:28:44.297] E019 |   667/667 batches | lr 0.0781 | loss  4.513 | ppl     91.24 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:28:50.248] End E019 | valid loss  5.854; ppl    348.71 | accu 0.2308 = 25895/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:28:56.131] End E019 |  test loss  8.027; ppl   3063.08 | accu 0.0856 = 9879/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:29:22.466] End E019 |  test loss  9.126; ppl   9188.52 | accu 0.0254 = 12880/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:29:22.466] Save: model.pt... 
[2022-04-13 17:29:23.078] Save: model.pt...Done. best_val_loss: 5.8543
[2022-04-13 17:29:23.078] Epoch 020/20 ==================================================
[2022-04-13 17:29:40.979] E020 |   200/667 batches | lr 0.0781 | loss  4.700 | ppl    109.92 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:29:58.891] E020 |   400/667 batches | lr 0.0781 | loss  4.685 | ppl    108.35 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:30:16.792] E020 |   600/667 batches | lr 0.0781 | loss  4.582 | ppl     97.74 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:30:22.826] E020 |   667/667 batches | lr 0.0781 | loss  4.510 | ppl     90.91 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:30:28.722] End E020 | valid loss  5.854; ppl    348.64 | accu 0.2308 = 25895/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:30:34.529] End E020 |  test loss  8.025; ppl   3055.15 | accu 0.0856 = 9876/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:31:00.859] End E020 |  test loss  9.123; ppl   9163.74 | accu 0.0254 = 12875/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:31:00.859] Save: model.pt... 
[2022-04-13 17:31:01.488] Save: model.pt...Done. best_val_loss: 5.8540
[2022-04-13 17:31:07.486] End. test loss  8.02; ppl  3055.15 | accu 0.0856 = 9876/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:31:33.766] End. test loss  9.12; ppl  9163.74 | accu 0.0254 = 12875/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:31:33.766] =========================================================================================
[2022-04-13 17:31:33.766] valid_loss
[2022-04-13 17:31:33.766]  6.66, 6.24, 6.34, 5.94, 5.92, 5.89, 5.90, 5.87, 5.86, 5.87, 5.86, 5.86, 5.86, 5.86, 5.86, 5.85, 5.86, 5.86, 5.85, 5.85
[2022-04-13 17:31:33.766] valid_loss ppl
[2022-04-13 17:31:33.766]   783.39,  512.67,  564.98,  379.67,  372.50,  361.65,  363.26,  353.00,  351.72,  355.67,  349.80,  351.26,  349.54,  350.16,  349.61,  348.79,  349.11,  349.05,  348.71,  348.64
[2022-04-13 17:31:33.766] test_loss of ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:31:33.767]  7.75, 8.45, 7.58, 8.34, 8.45, 8.00, 8.11, 8.04, 8.01, 8.09, 8.08, 8.03, 8.08, 8.09, 8.04, 8.04, 8.06, 8.05, 8.03, 8.02
[2022-04-13 17:31:33.767] test_loss of ../data/sample_500k/cbt_valid.txt ppl
[2022-04-13 17:31:33.767]  2323.45, 4662.75, 1952.12, 4171.16, 4674.96, 2989.70, 3340.35, 3110.84, 3017.60, 3259.54, 3218.50, 3086.32, 3242.09, 3259.57, 3115.74, 3096.35, 3164.75, 3143.19, 3063.08, 3055.15
[2022-04-13 17:31:33.767] test_loss of ../data/sample_500k/adult_test.txt
[2022-04-13 17:31:33.767]  8.69,10.17, 9.21,10.34,10.27, 9.60, 9.78, 9.39, 9.34, 9.38, 9.27, 9.14, 9.18, 9.18, 9.15, 9.15, 9.18, 9.17, 9.13, 9.12
[2022-04-13 17:31:33.767] test_loss of ../data/sample_500k/adult_test.txt ppl
[2022-04-13 17:31:33.767]  5960.04,26177.03,10001.23,31024.16,28844.76,14821.27,17672.43,12021.07,11383.32,11836.83,10664.46, 9354.05, 9721.37, 9706.92, 9405.86, 9437.31, 9662.11, 9567.13, 9188.52, 9163.74
[2022-04-13 17:31:33.767] 
[2022-04-13 17:31:33.767] 
[2022-04-13 17:31:33.767] 
Log file: ./output_wsm_Subword.1000_fam_CNN.log closed.
Log file: ./output_wsm_Subword.1000_fam_LSTM.log open...
[2022-04-13 17:31:33.777] corpus.train_file_list: 1
[2022-04-13 17:31:33.777]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 17:31:33.777] corpus.valid_file_list: 1
[2022-04-13 17:31:33.777]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 17:31:33.777] corpus.test_file_list: 2
[2022-04-13 17:31:33.777]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:31:33.777]         ../data/sample_500k/adult_test.txt
[2022-04-13 17:31:33.777] corpus.subword_vocab_size: 0
[2022-04-13 17:31:33.777] corpus.subword_model = None. Corpus will not use subword.
[2022-04-13 17:31:33.778] corpus tokenize...
[2022-04-13 17:31:34.836]         train tokens: 467267  ../data/sample_500k/adolescent_train.txt
[2022-04-13 17:31:35.078]         valid tokens: 112256  ../data/sample_500k/adolescent_valid.txt
[2022-04-13 17:31:35.214]         test  tokens: 115417  ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:31:35.822]         test  tokens: 506878  ../data/sample_500k/adult_test.txt
[2022-04-13 17:31:35.822] corpus.ntokens      : 95521
[2022-04-13 17:31:35.823] corpus.char_count   : 166
[2022-04-13 17:31:35.823] corpus.char_cnt_dict: 166
[2022-04-13 17:31:35.823] corpus.char_id_dict : 166
[2022-04-13 17:31:35.828] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 17:31:35.828]         tokens_all: 467267
[2022-04-13 17:31:35.829]         batched   :  23363
[2022-04-13 17:31:35.829]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 17:31:35.833] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 17:31:35.833]         tokens_all: 112256
[2022-04-13 17:31:35.833]         batched   :   5612
[2022-04-13 17:31:35.833]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 17:31:35.837] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 17:31:35.837]         tokens_all: 115417
[2022-04-13 17:31:35.838]         batched   :   5770
[2022-04-13 17:31:35.838]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:31:35.844] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 17:31:35.845]         tokens_all: 506878
[2022-04-13 17:31:35.845]         batched   :  25343
[2022-04-13 17:31:35.845]         ../data/sample_500k/adult_test.txt
[2022-04-13 17:31:35.846] subword_adapter will be generated due to word_split_mode='Subword.1000'
[2022-04-13 17:31:35.846] SubwordAdapter.file_list: 2
[2022-04-13 17:31:35.846]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 17:31:35.846]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 17:31:35.846] SubwordAdapter.subword_vocab_size: 1000
[2022-04-13 17:31:35.846] SubwordAdapter.subword_model.train(2 files)...
[2022-04-13 17:31:36.429] SubwordAdapter.subword_model.train(2 files)...Done
[2022-04-13 17:31:37.178] RNNModel.rnn_type: LSTM
[2022-04-13 17:31:37.178] RNNModel.ntoken  : 95521
[2022-04-13 17:31:37.178] RNNModel.ninp    : 200
[2022-04-13 17:31:37.178] RNNModel.nhid    : 200
[2022-04-13 17:31:37.178] RNNModel.nlayers : 2
[2022-04-13 17:31:37.178] RNNModel.dropout : 0.2
[2022-04-13 17:31:37.178] RNNModel.tie_weights: False
[2022-04-13 17:31:37.178] RNNModel.fragment_aggregate_mode: LSTM
[2022-04-13 17:31:37.178] RNNModel.fragment_cnt           : 1002
[2022-04-13 17:31:37.179] RNNModel.fragment_emsize        : 25
[2022-04-13 17:31:37.179] RNNModel.fragment_nhid          : 200
[2022-04-13 17:31:37.179] RNNModel.fragment_embeds     : created
[2022-04-13 17:31:37.183] RNNModel.fragment_lstm       : created
[2022-04-13 17:31:37.183] RNNModel.fragment_lstm_linear: created
[2022-04-13 17:31:37.224] Epoch 001/20 ==================================================
[2022-04-13 17:32:39.777] E001 |   200/667 batches | lr 20.0000 | loss  8.496 | ppl   4897.10 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:33:43.280] E001 |   400/667 batches | lr 20.0000 | loss  7.785 | ppl   2404.66 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:34:47.943] E001 |   600/667 batches | lr 20.0000 | loss  7.270 | ppl   1436.67 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:35:10.149] E001 |   667/667 batches | lr 20.0000 | loss  6.953 | ppl   1046.67 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:35:24.606] End E001 | valid loss  6.901; ppl    992.95 | accu 0.1278 = 14345/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:35:39.162] End E001 |  test loss  7.278; ppl   1448.16 | accu 0.1140 = 13159/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:36:43.681] End E001 |  test loss  8.358; ppl   4263.56 | accu 0.0749 = 37958/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:36:43.681] Save: model.pt... 
[2022-04-13 17:36:44.302] Save: model.pt...Done. best_val_loss: 6.9007
[2022-04-13 17:36:44.302] Epoch 002/20 ==================================================
[2022-04-13 17:37:46.251] E002 |   200/667 batches | lr 20.0000 | loss  6.713 | ppl    822.69 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:38:50.729] E002 |   400/667 batches | lr 20.0000 | loss  6.516 | ppl    676.15 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:39:53.889] E002 |   600/667 batches | lr 20.0000 | loss  6.294 | ppl    541.43 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:40:15.403] E002 |   667/667 batches | lr 20.0000 | loss  6.180 | ppl    483.05 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:40:29.515] End E002 | valid loss  6.248; ppl    516.84 | accu 0.1958 = 21972/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:40:43.913] End E002 |  test loss  8.021; ppl   3044.58 | accu 0.0677 = 7811/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:41:48.386] End E002 |  test loss  9.714; ppl  16551.98 | accu 0.0077 = 3914/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:41:48.386] Save: model.pt... 
[2022-04-13 17:41:48.970] Save: model.pt...Done. best_val_loss: 6.2477
[2022-04-13 17:41:48.971] Epoch 003/20 ==================================================
[2022-04-13 17:42:52.046] E003 |   200/667 batches | lr 20.0000 | loss  6.126 | ppl    457.56 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:43:56.529] E003 |   400/667 batches | lr 20.0000 | loss  6.048 | ppl    423.29 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:45:01.828] E003 |   600/667 batches | lr 20.0000 | loss  5.903 | ppl    366.12 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:45:24.250] E003 |   667/667 batches | lr 20.0000 | loss  5.811 | ppl    334.02 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:45:38.767] End E003 | valid loss  6.075; ppl    435.05 | accu 0.1945 = 21825/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:45:53.122] End E003 |  test loss  7.540; ppl   1882.57 | accu 0.0695 = 8024/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:46:57.601] End E003 |  test loss  8.842; ppl   6915.47 | accu 0.0161 = 8182/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:46:57.601] Save: model.pt... 
[2022-04-13 17:46:58.194] Save: model.pt...Done. best_val_loss: 6.0755
[2022-04-13 17:46:58.194] Epoch 004/20 ==================================================
[2022-04-13 17:48:02.173] E004 |   200/667 batches | lr 20.0000 | loss  5.787 | ppl    325.99 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:49:08.181] E004 |   400/667 batches | lr 20.0000 | loss  5.752 | ppl    314.97 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:50:13.037] E004 |   600/667 batches | lr 20.0000 | loss  5.636 | ppl    280.32 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:50:35.264] E004 |   667/667 batches | lr 20.0000 | loss  5.568 | ppl    261.97 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:50:49.687] End E004 | valid loss  6.016; ppl    409.97 | accu 0.2113 = 23714/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:51:04.001] End E004 |  test loss  7.257; ppl   1418.26 | accu 0.0884 = 10205/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:52:08.736] End E004 |  test loss  8.508; ppl   4952.27 | accu 0.0265 = 13413/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:52:08.736] Save: model.pt... 
[2022-04-13 17:52:09.326] Save: model.pt...Done. best_val_loss: 6.0161
[2022-04-13 17:52:09.326] Epoch 005/20 ==================================================
[2022-04-13 17:53:13.980] E005 |   200/667 batches | lr 20.0000 | loss  5.547 | ppl    256.36 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:54:20.996] E005 |   400/667 batches | lr 20.0000 | loss  5.536 | ppl    253.64 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 17:55:26.501] E005 |   600/667 batches | lr 20.0000 | loss  5.437 | ppl    229.67 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 17:55:48.279] E005 |   667/667 batches | lr 20.0000 | loss  5.365 | ppl    213.80 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 17:56:02.811] End E005 | valid loss  6.058; ppl    427.60 | accu 0.1983 = 22254/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 17:56:17.476] End E005 |  test loss  7.270; ppl   1435.87 | accu 0.0943 = 10880/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 17:57:22.285] End E005 |  test loss  8.360; ppl   4272.31 | accu 0.0491 = 24900/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 17:57:22.286] Epoch 006/20 ==================================================
[2022-04-13 17:58:24.025] E006 |   200/667 batches | lr 10.0000 | loss  5.256 | ppl    191.78 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 17:59:30.235] E006 |   400/667 batches | lr 10.0000 | loss  5.223 | ppl    185.42 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 18:00:34.554] E006 |   600/667 batches | lr 10.0000 | loss  5.095 | ppl    163.28 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 18:00:56.355] E006 |   667/667 batches | lr 10.0000 | loss  5.019 | ppl    151.33 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 18:01:10.745] End E006 | valid loss  5.923; ppl    373.55 | accu 0.2187 = 24540/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 18:01:25.641] End E006 |  test loss  7.172; ppl   1301.98 | accu 0.0889 = 10260/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 18:02:30.907] End E006 |  test loss  8.354; ppl   4245.91 | accu 0.0244 = 12378/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 18:02:30.907] Save: model.pt... 
[2022-04-13 18:02:31.507] Save: model.pt...Done. best_val_loss: 5.9231
[2022-04-13 18:02:31.508] Epoch 007/20 ==================================================
[2022-04-13 18:03:35.583] E007 |   200/667 batches | lr 10.0000 | loss  5.101 | ppl    164.20 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 18:04:41.116] E007 |   400/667 batches | lr 10.0000 | loss  5.090 | ppl    162.43 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 18:05:46.252] E007 |   600/667 batches | lr 10.0000 | loss  4.982 | ppl    145.79 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 18:06:08.034] E007 |   667/667 batches | lr 10.0000 | loss  4.915 | ppl    136.36 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 18:06:22.346] End E007 | valid loss  5.928; ppl    375.58 | accu 0.2180 = 24467/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 18:06:36.718] End E007 |  test loss  7.239; ppl   1392.65 | accu 0.0846 = 9759/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 18:07:41.144] End E007 |  test loss  8.518; ppl   5005.27 | accu 0.0208 = 10548/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 18:07:41.144] Epoch 008/20 ==================================================
[2022-04-13 18:08:44.025] E008 |   200/667 batches | lr 5.0000 | loss  4.959 | ppl    142.52 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 18:09:47.843] E008 |   400/667 batches | lr 5.0000 | loss  4.922 | ppl    137.27 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 18:10:52.284] E008 |   600/667 batches | lr 5.0000 | loss  4.805 | ppl    122.09 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 18:11:14.534] E008 |   667/667 batches | lr 5.0000 | loss  4.722 | ppl    112.35 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 18:11:29.142] End E008 | valid loss  5.910; ppl    368.81 | accu 0.2234 = 25075/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 18:11:43.887] End E008 |  test loss  7.165; ppl   1292.97 | accu 0.0911 = 10516/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 18:12:49.275] End E008 |  test loss  8.507; ppl   4947.47 | accu 0.0214 = 10838/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 18:12:49.275] Save: model.pt... 
[2022-04-13 18:12:49.905] Save: model.pt...Done. best_val_loss: 5.9103
[2022-04-13 18:12:49.905] Epoch 009/20 ==================================================
[2022-04-13 18:13:53.677] E009 |   200/667 batches | lr 5.0000 | loss  4.876 | ppl    131.09 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 18:14:58.872] E009 |   400/667 batches | lr 5.0000 | loss  4.853 | ppl    128.09 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 18:16:05.528] E009 |   600/667 batches | lr 5.0000 | loss  4.747 | ppl    115.29 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 18:16:26.933] E009 |   667/667 batches | lr 5.0000 | loss  4.675 | ppl    107.22 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 18:16:41.445] End E009 | valid loss  5.915; ppl    370.70 | accu 0.2227 = 24986/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 18:16:56.091] End E009 |  test loss  7.151; ppl   1275.58 | accu 0.0940 = 10843/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 18:18:00.821] End E009 |  test loss  8.465; ppl   4745.61 | accu 0.0259 = 13107/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 18:18:00.821] Epoch 010/20 ==================================================
[2022-04-13 18:19:03.640] E010 |   200/667 batches | lr 2.5000 | loss  4.803 | ppl    121.83 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 18:20:08.979] E010 |   400/667 batches | lr 2.5000 | loss  4.767 | ppl    117.53 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 18:21:16.056] E010 |   600/667 batches | lr 2.5000 | loss  4.650 | ppl    104.57 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 18:21:37.410] E010 |   667/667 batches | lr 2.5000 | loss  4.570 | ppl     96.50 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 18:21:52.139] End E010 | valid loss  5.913; ppl    369.87 | accu 0.2262 = 25386/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 18:22:07.376] End E010 |  test loss  7.151; ppl   1274.99 | accu 0.0952 = 10986/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 18:23:12.789] End E010 |  test loss  8.508; ppl   4953.99 | accu 0.0275 = 13922/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 18:23:12.790] Epoch 011/20 ==================================================
[2022-04-13 18:24:16.925] E011 |   200/667 batches | lr 1.2500 | loss  4.756 | ppl    116.30 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 18:25:22.532] E011 |   400/667 batches | lr 1.2500 | loss  4.720 | ppl    112.15 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 18:26:27.361] E011 |   600/667 batches | lr 1.2500 | loss  4.599 | ppl     99.34 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 18:26:48.835] E011 |   667/667 batches | lr 1.2500 | loss  4.524 | ppl     92.21 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 18:27:03.297] End E011 | valid loss  5.908; ppl    368.03 | accu 0.2274 = 25520/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 18:27:17.802] End E011 |  test loss  7.103; ppl   1215.44 | accu 0.0957 = 11044/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 18:28:23.144] End E011 |  test loss  8.486; ppl   4848.24 | accu 0.0251 = 12747/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 18:28:23.144] Save: model.pt... 
[2022-04-13 18:28:23.778] Save: model.pt...Done. best_val_loss: 5.9082
[2022-04-13 18:28:23.778] Epoch 012/20 ==================================================
[2022-04-13 18:29:26.403] E012 |   200/667 batches | lr 1.2500 | loss  4.727 | ppl    112.99 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 18:30:32.546] E012 |   400/667 batches | lr 1.2500 | loss  4.697 | ppl    109.61 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 18:31:39.837] E012 |   600/667 batches | lr 1.2500 | loss  4.589 | ppl     98.39 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 18:32:01.951] E012 |   667/667 batches | lr 1.2500 | loss  4.510 | ppl     90.88 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 18:32:16.482] End E012 | valid loss  5.914; ppl    370.05 | accu 0.2274 = 25522/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 18:32:31.539] End E012 |  test loss  7.121; ppl   1238.21 | accu 0.0949 = 10949/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 18:33:37.029] End E012 |  test loss  8.537; ppl   5102.14 | accu 0.0241 = 12193/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 18:33:37.029] Epoch 013/20 ==================================================
[2022-04-13 18:34:40.945] E013 |   200/667 batches | lr 0.6250 | loss  4.708 | ppl    110.82 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 18:35:45.749] E013 |   400/667 batches | lr 0.6250 | loss  4.676 | ppl    107.35 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 18:36:51.092] E013 |   600/667 batches | lr 0.6250 | loss  4.559 | ppl     95.45 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 18:37:12.979] E013 |   667/667 batches | lr 0.6250 | loss  4.482 | ppl     88.39 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 18:37:27.433] End E013 | valid loss  5.912; ppl    369.45 | accu 0.2281 = 25592/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 18:37:41.871] End E013 |  test loss  7.095; ppl   1205.71 | accu 0.0960 = 11076/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 18:38:47.484] End E013 |  test loss  8.514; ppl   4985.96 | accu 0.0253 = 12810/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 18:38:47.484] Epoch 014/20 ==================================================
[2022-04-13 18:39:51.414] E014 |   200/667 batches | lr 0.3125 | loss  4.696 | ppl    109.49 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 18:40:57.696] E014 |   400/667 batches | lr 0.3125 | loss  4.663 | ppl    105.94 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 18:42:02.231] E014 |   600/667 batches | lr 0.3125 | loss  4.545 | ppl     94.18 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 18:42:24.101] E014 |   667/667 batches | lr 0.3125 | loss  4.461 | ppl     86.59 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 18:42:38.630] End E014 | valid loss  5.908; ppl    367.95 | accu 0.2282 = 25612/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 18:42:53.229] End E014 |  test loss  7.081; ppl   1189.12 | accu 0.0964 = 11120/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 18:43:58.184] End E014 |  test loss  8.505; ppl   4941.23 | accu 0.0249 = 12638/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 18:43:58.185] Save: model.pt... 
[2022-04-13 18:43:58.816] Save: model.pt...Done. best_val_loss: 5.9079
[2022-04-13 18:43:58.816] Epoch 015/20 ==================================================
[2022-04-13 18:45:03.156] E015 |   200/667 batches | lr 0.3125 | loss  4.691 | ppl    108.93 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 18:46:08.786] E015 |   400/667 batches | lr 0.3125 | loss  4.656 | ppl    105.19 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 18:47:13.297] E015 |   600/667 batches | lr 0.3125 | loss  4.542 | ppl     93.85 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 18:47:35.656] E015 |   667/667 batches | lr 0.3125 | loss  4.465 | ppl     86.90 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 18:47:50.144] End E015 | valid loss  5.908; ppl    368.07 | accu 0.2284 = 25627/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 18:48:04.608] End E015 |  test loss  7.083; ppl   1191.81 | accu 0.0966 = 11149/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 18:49:10.083] End E015 |  test loss  8.503; ppl   4927.10 | accu 0.0254 = 12859/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 18:49:10.083] Epoch 016/20 ==================================================
[2022-04-13 18:50:14.815] E016 |   200/667 batches | lr 0.1562 | loss  4.682 | ppl    107.96 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 18:51:22.439] E016 |   400/667 batches | lr 0.1562 | loss  4.652 | ppl    104.76 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 18:52:27.903] E016 |   600/667 batches | lr 0.1562 | loss  4.533 | ppl     93.01 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 18:52:49.526] E016 |   667/667 batches | lr 0.1562 | loss  4.458 | ppl     86.34 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 18:53:04.107] End E016 | valid loss  5.906; ppl    367.41 | accu 0.2290 = 25698/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 18:53:19.124] End E016 |  test loss  7.071; ppl   1177.12 | accu 0.0973 = 11222/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 18:54:24.466] End E016 |  test loss  8.488; ppl   4857.59 | accu 0.0260 = 13183/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 18:54:24.466] Save: model.pt... 
[2022-04-13 18:54:25.143] Save: model.pt...Done. best_val_loss: 5.9065
[2022-04-13 18:54:25.143] Epoch 017/20 ==================================================
[2022-04-13 18:55:27.819] E017 |   200/667 batches | lr 0.1562 | loss  4.678 | ppl    107.51 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 18:56:33.413] E017 |   400/667 batches | lr 0.1562 | loss  4.646 | ppl    104.13 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 18:57:38.162] E017 |   600/667 batches | lr 0.1562 | loss  4.534 | ppl     93.18 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 18:57:59.439] E017 |   667/667 batches | lr 0.1562 | loss  4.463 | ppl     86.77 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 18:58:13.879] End E017 | valid loss  5.907; ppl    367.77 | accu 0.2290 = 25699/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 18:58:28.348] End E017 |  test loss  7.067; ppl   1173.12 | accu 0.0976 = 11262/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 18:59:34.585] End E017 |  test loss  8.487; ppl   4850.81 | accu 0.0262 = 13303/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 18:59:34.586] Epoch 018/20 ==================================================
[2022-04-13 19:00:37.711] E018 |   200/667 batches | lr 0.0781 | loss  4.679 | ppl    107.62 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 19:01:43.005] E018 |   400/667 batches | lr 0.0781 | loss  4.644 | ppl    104.00 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 19:02:48.414] E018 |   600/667 batches | lr 0.0781 | loss  4.529 | ppl     92.68 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 19:03:10.100] E018 |   667/667 batches | lr 0.0781 | loss  4.450 | ppl     85.65 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 19:03:24.487] End E018 | valid loss  5.907; ppl    367.64 | accu 0.2290 = 25700/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 19:03:39.037] End E018 |  test loss  7.064; ppl   1169.02 | accu 0.0977 = 11272/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:04:44.290] End E018 |  test loss  8.482; ppl   4827.31 | accu 0.0265 = 13407/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:04:44.290] Epoch 019/20 ==================================================
[2022-04-13 19:05:46.487] E019 |   200/667 batches | lr 0.0391 | loss  4.673 | ppl    107.02 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 19:06:52.043] E019 |   400/667 batches | lr 0.0391 | loss  4.642 | ppl    103.80 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 19:07:57.150] E019 |   600/667 batches | lr 0.0391 | loss  4.527 | ppl     92.45 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 19:08:19.460] E019 |   667/667 batches | lr 0.0391 | loss  4.454 | ppl     85.99 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 19:08:34.108] End E019 | valid loss  5.909; ppl    368.24 | accu 0.2292 = 25717/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 19:08:48.625] End E019 |  test loss  7.063; ppl   1167.46 | accu 0.0978 = 11289/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:09:52.922] End E019 |  test loss  8.480; ppl   4818.01 | accu 0.0268 = 13592/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:09:52.922] Epoch 020/20 ==================================================
[2022-04-13 19:10:56.688] E020 |   200/667 batches | lr 0.0195 | loss  4.674 | ppl    107.09 frag_cnt/word_cnt=2.337=327243/140000
[2022-04-13 19:12:02.349] E020 |   400/667 batches | lr 0.0195 | loss  4.643 | ppl    103.88 frag_cnt/word_cnt=2.372=332053/140000
[2022-04-13 19:13:06.613] E020 |   600/667 batches | lr 0.0195 | loss  4.526 | ppl     92.43 frag_cnt/word_cnt=2.361=330480/140000
[2022-04-13 19:13:28.601] E020 |   667/667 batches | lr 0.0195 | loss  4.452 | ppl     85.79 frag_cnt/word_cnt=2.351=110285/46900
[2022-04-13 19:13:43.106] End E020 | valid loss  5.909; ppl    368.25 | accu 0.2293 = 25734/112220 | w_len 2.2450 = 251937/112220
[2022-04-13 19:13:57.553] End E020 |  test loss  7.063; ppl   1167.37 | accu 0.0979 = 11290/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:15:02.734] End E020 |  test loss  8.480; ppl   4817.19 | accu 0.0268 = 13573/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:15:17.572] End. test loss  7.07; ppl  1177.12 | accu 0.0973 = 11222/115380 | w_len 1.6106 = 185828/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:16:22.459] End. test loss  8.49; ppl  4857.59 | accu 0.0260 = 13183/506840 | w_len 2.1848 = 1107354/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:16:22.459] =========================================================================================
[2022-04-13 19:16:22.459] valid_loss
[2022-04-13 19:16:22.460]  6.90, 6.25, 6.08, 6.02, 6.06, 5.92, 5.93, 5.91, 5.92, 5.91, 5.91, 5.91, 5.91, 5.91, 5.91, 5.91, 5.91, 5.91, 5.91, 5.91
[2022-04-13 19:16:22.460] valid_loss ppl
[2022-04-13 19:16:22.460]   992.95,  516.84,  435.05,  409.97,  427.60,  373.55,  375.58,  368.81,  370.70,  369.87,  368.03,  370.05,  369.45,  367.95,  368.07,  367.41,  367.77,  367.64,  368.24,  368.25
[2022-04-13 19:16:22.460] test_loss of ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:16:22.460]  7.28, 8.02, 7.54, 7.26, 7.27, 7.17, 7.24, 7.16, 7.15, 7.15, 7.10, 7.12, 7.09, 7.08, 7.08, 7.07, 7.07, 7.06, 7.06, 7.06
[2022-04-13 19:16:22.460] test_loss of ../data/sample_500k/cbt_valid.txt ppl
[2022-04-13 19:16:22.460]  1448.16, 3044.58, 1882.57, 1418.26, 1435.87, 1301.98, 1392.65, 1292.97, 1275.58, 1274.99, 1215.44, 1238.21, 1205.71, 1189.12, 1191.81, 1177.12, 1173.12, 1169.02, 1167.46, 1167.37
[2022-04-13 19:16:22.460] test_loss of ../data/sample_500k/adult_test.txt
[2022-04-13 19:16:22.460]  8.36, 9.71, 8.84, 8.51, 8.36, 8.35, 8.52, 8.51, 8.46, 8.51, 8.49, 8.54, 8.51, 8.51, 8.50, 8.49, 8.49, 8.48, 8.48, 8.48
[2022-04-13 19:16:22.460] test_loss of ../data/sample_500k/adult_test.txt ppl
[2022-04-13 19:16:22.460]  4263.56,16551.98, 6915.47, 4952.27, 4272.31, 4245.91, 5005.27, 4947.47, 4745.61, 4953.99, 4848.24, 5102.14, 4985.96, 4941.23, 4927.10, 4857.59, 4850.81, 4827.31, 4818.01, 4817.19
[2022-04-13 19:16:22.460] 
[2022-04-13 19:16:22.460] 
[2022-04-13 19:16:22.460] 
Log file: ./output_wsm_Subword.1000_fam_LSTM.log closed.
Log file: ./output_wsm_Subword.2000_fam_CNN.log open...
[2022-04-13 19:16:22.471] corpus.train_file_list: 1
[2022-04-13 19:16:22.471]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 19:16:22.472] corpus.valid_file_list: 1
[2022-04-13 19:16:22.472]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 19:16:22.472] corpus.test_file_list: 2
[2022-04-13 19:16:22.472]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:16:22.472]         ../data/sample_500k/adult_test.txt
[2022-04-13 19:16:22.472] corpus.subword_vocab_size: 0
[2022-04-13 19:16:22.472] corpus.subword_model = None. Corpus will not use subword.
[2022-04-13 19:16:22.472] corpus tokenize...
[2022-04-13 19:16:23.528]         train tokens: 467267  ../data/sample_500k/adolescent_train.txt
[2022-04-13 19:16:23.756]         valid tokens: 112256  ../data/sample_500k/adolescent_valid.txt
[2022-04-13 19:16:23.900]         test  tokens: 115417  ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:16:24.548]         test  tokens: 506878  ../data/sample_500k/adult_test.txt
[2022-04-13 19:16:24.548] corpus.ntokens      : 95521
[2022-04-13 19:16:24.548] corpus.char_count   : 166
[2022-04-13 19:16:24.548] corpus.char_cnt_dict: 166
[2022-04-13 19:16:24.549] corpus.char_id_dict : 166
[2022-04-13 19:16:24.552] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 19:16:24.552]         tokens_all: 467267
[2022-04-13 19:16:24.552]         batched   :  23363
[2022-04-13 19:16:24.552]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 19:16:24.554] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 19:16:24.554]         tokens_all: 112256
[2022-04-13 19:16:24.554]         batched   :   5612
[2022-04-13 19:16:24.554]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 19:16:24.556] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 19:16:24.556]         tokens_all: 115417
[2022-04-13 19:16:24.556]         batched   :   5770
[2022-04-13 19:16:24.556]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:16:24.560] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 19:16:24.560]         tokens_all: 506878
[2022-04-13 19:16:24.560]         batched   :  25343
[2022-04-13 19:16:24.560]         ../data/sample_500k/adult_test.txt
[2022-04-13 19:16:24.561] subword_adapter will be generated due to word_split_mode='Subword.2000'
[2022-04-13 19:16:24.561] SubwordAdapter.file_list: 2
[2022-04-13 19:16:24.561]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 19:16:24.561]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 19:16:24.561] SubwordAdapter.subword_vocab_size: 2000
[2022-04-13 19:16:24.561] SubwordAdapter.subword_model.train(2 files)...
[2022-04-13 19:16:25.250] SubwordAdapter.subword_model.train(2 files)...Done
[2022-04-13 19:16:25.957] RNNModel.rnn_type: LSTM
[2022-04-13 19:16:25.957] RNNModel.ntoken  : 95521
[2022-04-13 19:16:25.957] RNNModel.ninp    : 200
[2022-04-13 19:16:25.957] RNNModel.nhid    : 200
[2022-04-13 19:16:25.957] RNNModel.nlayers : 2
[2022-04-13 19:16:25.958] RNNModel.dropout : 0.2
[2022-04-13 19:16:25.958] RNNModel.tie_weights: False
[2022-04-13 19:16:25.958] RNNModel.fragment_aggregate_mode: CNN
[2022-04-13 19:16:25.958] RNNModel.fragment_cnt           : 2002
[2022-04-13 19:16:25.958] RNNModel.fragment_emsize        : 25
[2022-04-13 19:16:25.958] RNNModel.fragment_nhid          : 200
[2022-04-13 19:16:25.959] RNNModel.fragment_embeds     : created
[2022-04-13 19:16:25.960] RNNModel.fragment_cnn3       : created
[2022-04-13 19:16:26.032] Epoch 001/20 ==================================================
[2022-04-13 19:16:43.872] E001 |   200/667 batches | lr 20.0000 | loss  8.537 | ppl   5097.73 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:17:01.704] E001 |   400/667 batches | lr 20.0000 | loss  7.677 | ppl   2158.70 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:17:19.461] E001 |   600/667 batches | lr 20.0000 | loss  7.099 | ppl   1211.19 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:17:25.455] E001 |   667/667 batches | lr 20.0000 | loss  6.771 | ppl    872.48 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:17:31.363] End E001 | valid loss  6.809; ppl    905.83 | accu 0.1406 = 15779/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:17:37.183] End E001 |  test loss  7.287; ppl   1461.30 | accu 0.0962 = 11104/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:18:03.653] End E001 |  test loss  8.408; ppl   4481.12 | accu 0.0275 = 13936/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:18:03.653] Save: model.pt... 
[2022-04-13 19:18:04.247] Save: model.pt...Done. best_val_loss: 6.8088
[2022-04-13 19:18:04.247] Epoch 002/20 ==================================================
[2022-04-13 19:18:21.883] E002 |   200/667 batches | lr 20.0000 | loss  6.578 | ppl    719.38 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:18:39.744] E002 |   400/667 batches | lr 20.0000 | loss  6.416 | ppl    611.82 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:18:57.565] E002 |   600/667 batches | lr 20.0000 | loss  6.208 | ppl    496.73 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:19:03.539] E002 |   667/667 batches | lr 20.0000 | loss  6.094 | ppl    443.16 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:19:09.474] End E002 | valid loss  6.202; ppl    493.60 | accu 0.1941 = 21786/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:19:15.317] End E002 |  test loss  7.830; ppl   2514.56 | accu 0.0664 = 7666/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:19:41.791] End E002 |  test loss  9.650; ppl  15514.71 | accu 0.0074 = 3758/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:19:41.791] Save: model.pt... 
[2022-04-13 19:19:42.388] Save: model.pt...Done. best_val_loss: 6.2017
[2022-04-13 19:19:42.388] Epoch 003/20 ==================================================
[2022-04-13 19:20:00.479] E003 |   200/667 batches | lr 20.0000 | loss  6.039 | ppl    419.67 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:20:18.340] E003 |   400/667 batches | lr 20.0000 | loss  5.993 | ppl    400.62 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:20:36.236] E003 |   600/667 batches | lr 20.0000 | loss  5.868 | ppl    353.47 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:20:42.451] E003 |   667/667 batches | lr 20.0000 | loss  5.771 | ppl    320.92 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:20:48.378] End E003 | valid loss  6.144; ppl    465.77 | accu 0.1914 = 21482/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:20:54.227] End E003 |  test loss  7.563; ppl   1926.39 | accu 0.0785 = 9057/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:21:20.798] End E003 |  test loss  9.179; ppl   9690.06 | accu 0.0148 = 7501/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:21:20.798] Save: model.pt... 
[2022-04-13 19:21:21.414] Save: model.pt...Done. best_val_loss: 6.1437
[2022-04-13 19:21:21.414] Epoch 004/20 ==================================================
[2022-04-13 19:21:39.193] E004 |   200/667 batches | lr 20.0000 | loss  5.769 | ppl    320.12 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:21:57.200] E004 |   400/667 batches | lr 20.0000 | loss  5.747 | ppl    313.11 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:22:15.335] E004 |   600/667 batches | lr 20.0000 | loss  5.636 | ppl    280.36 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:22:21.349] E004 |   667/667 batches | lr 20.0000 | loss  5.549 | ppl    256.89 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:22:27.310] End E004 | valid loss  6.010; ppl    407.62 | accu 0.2071 = 23239/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:22:33.215] End E004 |  test loss  8.285; ppl   3963.11 | accu 0.0734 = 8466/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:22:59.980] End E004 |  test loss 10.918; ppl  55158.85 | accu 0.0049 = 2493/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:22:59.980] Save: model.pt... 
[2022-04-13 19:23:00.582] Save: model.pt...Done. best_val_loss: 6.0103
[2022-04-13 19:23:00.583] Epoch 005/20 ==================================================
[2022-04-13 19:23:18.466] E005 |   200/667 batches | lr 20.0000 | loss  5.548 | ppl    256.80 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:23:36.424] E005 |   400/667 batches | lr 20.0000 | loss  5.551 | ppl    257.53 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:23:54.403] E005 |   600/667 batches | lr 20.0000 | loss  5.454 | ppl    233.79 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:24:00.401] E005 |   667/667 batches | lr 20.0000 | loss  5.384 | ppl    217.83 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:24:06.313] End E005 | valid loss  5.970; ppl    391.68 | accu 0.2104 = 23615/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:24:12.126] End E005 |  test loss  8.442; ppl   4637.84 | accu 0.0699 = 8068/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:24:38.504] End E005 |  test loss 10.324; ppl  30467.00 | accu 0.0065 = 3316/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:24:38.504] Save: model.pt... 
[2022-04-13 19:24:39.095] Save: model.pt...Done. best_val_loss: 5.9704
[2022-04-13 19:24:39.096] Epoch 006/20 ==================================================
[2022-04-13 19:24:56.973] E006 |   200/667 batches | lr 20.0000 | loss  5.391 | ppl    219.34 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:25:14.946] E006 |   400/667 batches | lr 20.0000 | loss  5.394 | ppl    220.06 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:25:32.884] E006 |   600/667 batches | lr 20.0000 | loss  5.307 | ppl    201.68 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:25:38.907] E006 |   667/667 batches | lr 20.0000 | loss  5.235 | ppl    187.77 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:25:44.811] End E006 | valid loss  5.992; ppl    400.22 | accu 0.2024 = 22710/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:25:50.651] End E006 |  test loss  8.618; ppl   5530.11 | accu 0.0688 = 7939/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:26:17.066] End E006 |  test loss 10.737; ppl  46031.88 | accu 0.0058 = 2946/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:26:17.066] Epoch 007/20 ==================================================
[2022-04-13 19:26:34.889] E007 |   200/667 batches | lr 10.0000 | loss  5.151 | ppl    172.63 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:26:52.872] E007 |   400/667 batches | lr 10.0000 | loss  5.113 | ppl    166.17 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:27:10.831] E007 |   600/667 batches | lr 10.0000 | loss  5.001 | ppl    148.59 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:27:16.832] E007 |   667/667 batches | lr 10.0000 | loss  4.915 | ppl    136.27 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:27:22.730] End E007 | valid loss  5.899; ppl    364.52 | accu 0.2203 = 24717/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:27:28.547] End E007 |  test loss  9.065; ppl   8649.20 | accu 0.0762 = 8796/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:27:54.845] End E007 |  test loss 10.980; ppl  58702.46 | accu 0.0074 = 3755/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:27:54.845] Save: model.pt... 
[2022-04-13 19:27:55.453] Save: model.pt...Done. best_val_loss: 5.8986
[2022-04-13 19:27:55.453] Epoch 008/20 ==================================================
[2022-04-13 19:28:13.311] E008 |   200/667 batches | lr 10.0000 | loss  5.007 | ppl    149.52 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:28:31.362] E008 |   400/667 batches | lr 10.0000 | loss  4.999 | ppl    148.33 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:28:49.333] E008 |   600/667 batches | lr 10.0000 | loss  4.905 | ppl    134.90 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:28:55.339] E008 |   667/667 batches | lr 10.0000 | loss  4.831 | ppl    125.35 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:29:01.278] End E008 | valid loss  5.917; ppl    371.37 | accu 0.2187 = 24537/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:29:07.109] End E008 |  test loss  9.371; ppl  11746.44 | accu 0.0728 = 8396/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:29:33.509] End E008 |  test loss 11.194; ppl  72664.69 | accu 0.0066 = 3330/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:29:33.510] Epoch 009/20 ==================================================
[2022-04-13 19:29:51.293] E009 |   200/667 batches | lr 5.0000 | loss  4.881 | ppl    131.77 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:30:09.217] E009 |   400/667 batches | lr 5.0000 | loss  4.848 | ppl    127.44 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:30:27.187] E009 |   600/667 batches | lr 5.0000 | loss  4.734 | ppl    113.79 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:30:33.202] E009 |   667/667 batches | lr 5.0000 | loss  4.649 | ppl    104.52 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:30:39.110] End E009 | valid loss  5.892; ppl    362.30 | accu 0.2245 = 25188/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:30:45.000] End E009 |  test loss  9.706; ppl  16417.00 | accu 0.0771 = 8899/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:31:11.507] End E009 |  test loss 11.239; ppl  76044.20 | accu 0.0076 = 3842/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:31:11.507] Save: model.pt... 
[2022-04-13 19:31:12.117] Save: model.pt...Done. best_val_loss: 5.8925
[2022-04-13 19:31:12.117] Epoch 010/20 ==================================================
[2022-04-13 19:31:30.022] E010 |   200/667 batches | lr 5.0000 | loss  4.798 | ppl    121.21 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:31:47.950] E010 |   400/667 batches | lr 5.0000 | loss  4.782 | ppl    119.29 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:32:05.913] E010 |   600/667 batches | lr 5.0000 | loss  4.687 | ppl    108.50 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:32:11.914] E010 |   667/667 batches | lr 5.0000 | loss  4.611 | ppl    100.57 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:32:17.892] End E010 | valid loss  5.894; ppl    362.72 | accu 0.2238 = 25118/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:32:23.745] End E010 |  test loss  9.842; ppl  18801.45 | accu 0.0789 = 9106/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:32:50.277] End E010 |  test loss 11.945; ppl 154062.30 | accu 0.0064 = 3265/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:32:50.278] Epoch 011/20 ==================================================
[2022-04-13 19:33:08.102] E011 |   200/667 batches | lr 2.5000 | loss  4.731 | ppl    113.40 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:33:26.029] E011 |   400/667 batches | lr 2.5000 | loss  4.700 | ppl    109.95 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:33:43.794] E011 |   600/667 batches | lr 2.5000 | loss  4.590 | ppl     98.54 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:33:49.654] E011 |   667/667 batches | lr 2.5000 | loss  4.509 | ppl     90.83 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:33:55.548] End E011 | valid loss  5.892; ppl    362.27 | accu 0.2262 = 25389/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:34:01.383] End E011 |  test loss 10.107; ppl  24506.78 | accu 0.0781 = 9013/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:34:27.890] End E011 |  test loss 11.737; ppl 125058.03 | accu 0.0069 = 3497/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:34:27.890] Save: model.pt... 
[2022-04-13 19:34:28.485] Save: model.pt...Done. best_val_loss: 5.8924
[2022-04-13 19:34:28.485] Epoch 012/20 ==================================================
[2022-04-13 19:34:46.277] E012 |   200/667 batches | lr 2.5000 | loss  4.681 | ppl    107.92 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:35:04.213] E012 |   400/667 batches | lr 2.5000 | loss  4.665 | ppl    106.12 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:35:22.191] E012 |   600/667 batches | lr 2.5000 | loss  4.567 | ppl     96.26 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:35:28.210] E012 |   667/667 batches | lr 2.5000 | loss  4.486 | ppl     88.74 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:35:34.115] End E012 | valid loss  5.892; ppl    362.23 | accu 0.2267 = 25443/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:35:39.949] End E012 |  test loss 10.205; ppl  27043.83 | accu 0.0783 = 9029/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:36:06.331] End E012 |  test loss 11.406; ppl  89901.62 | accu 0.0075 = 3817/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:36:06.332] Save: model.pt... 
[2022-04-13 19:36:06.927] Save: model.pt...Done. best_val_loss: 5.8923
[2022-04-13 19:36:06.927] Epoch 013/20 ==================================================
[2022-04-13 19:36:24.523] E013 |   200/667 batches | lr 2.5000 | loss  4.650 | ppl    104.57 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:36:42.460] E013 |   400/667 batches | lr 2.5000 | loss  4.634 | ppl    102.96 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:37:00.437] E013 |   600/667 batches | lr 2.5000 | loss  4.544 | ppl     94.06 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:37:06.449] E013 |   667/667 batches | lr 2.5000 | loss  4.468 | ppl     87.21 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:37:12.337] End E013 | valid loss  5.897; ppl    363.90 | accu 0.2264 = 25411/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:37:18.171] End E013 |  test loss 10.181; ppl  26404.55 | accu 0.0782 = 9021/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:37:44.627] End E013 |  test loss 11.594; ppl 108437.62 | accu 0.0077 = 3878/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:37:44.627] Epoch 014/20 ==================================================
[2022-04-13 19:38:02.442] E014 |   200/667 batches | lr 1.2500 | loss  4.622 | ppl    101.67 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:38:20.466] E014 |   400/667 batches | lr 1.2500 | loss  4.598 | ppl     99.31 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:38:38.419] E014 |   600/667 batches | lr 1.2500 | loss  4.495 | ppl     89.59 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:38:44.472] E014 |   667/667 batches | lr 1.2500 | loss  4.413 | ppl     82.49 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:38:50.360] End E014 | valid loss  5.898; ppl    364.26 | accu 0.2275 = 25535/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:38:56.165] End E014 |  test loss 10.210; ppl  27175.15 | accu 0.0780 = 8995/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:39:22.505] End E014 |  test loss 11.247; ppl  76674.95 | accu 0.0081 = 4108/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:39:22.505] Epoch 015/20 ==================================================
[2022-04-13 19:39:40.418] E015 |   200/667 batches | lr 0.6250 | loss  4.601 | ppl     99.56 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:39:58.374] E015 |   400/667 batches | lr 0.6250 | loss  4.576 | ppl     97.13 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:40:16.365] E015 |   600/667 batches | lr 0.6250 | loss  4.469 | ppl     87.27 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:40:22.470] E015 |   667/667 batches | lr 0.6250 | loss  4.386 | ppl     80.33 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:40:28.398] End E015 | valid loss  5.896; ppl    363.44 | accu 0.2285 = 25638/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:40:34.222] End E015 |  test loss 10.333; ppl  30731.50 | accu 0.0778 = 8974/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:41:00.620] End E015 |  test loss 11.160; ppl  70279.07 | accu 0.0083 = 4183/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:41:00.620] Epoch 016/20 ==================================================
[2022-04-13 19:41:18.544] E016 |   200/667 batches | lr 0.3125 | loss  4.588 | ppl     98.25 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:41:36.530] E016 |   400/667 batches | lr 0.3125 | loss  4.565 | ppl     96.06 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:41:54.464] E016 |   600/667 batches | lr 0.3125 | loss  4.455 | ppl     86.02 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:42:00.416] E016 |   667/667 batches | lr 0.3125 | loss  4.369 | ppl     78.95 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:42:06.335] End E016 | valid loss  5.895; ppl    363.12 | accu 0.2290 = 25699/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:42:12.149] End E016 |  test loss 10.333; ppl  30716.03 | accu 0.0782 = 9024/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:42:38.535] End E016 |  test loss 11.084; ppl  65094.85 | accu 0.0085 = 4306/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:42:38.535] Epoch 017/20 ==================================================
[2022-04-13 19:42:56.341] E017 |   200/667 batches | lr 0.1562 | loss  4.581 | ppl     97.65 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:43:14.244] E017 |   400/667 batches | lr 0.1562 | loss  4.559 | ppl     95.50 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:43:32.163] E017 |   600/667 batches | lr 0.1562 | loss  4.448 | ppl     85.48 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:43:38.159] E017 |   667/667 batches | lr 0.1562 | loss  4.366 | ppl     78.72 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:43:44.052] End E017 | valid loss  5.894; ppl    362.87 | accu 0.2291 = 25714/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:43:49.854] End E017 |  test loss 10.310; ppl  30036.93 | accu 0.0784 = 9044/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:44:16.187] End E017 |  test loss 10.924; ppl  55515.87 | accu 0.0087 = 4431/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:44:16.187] Epoch 018/20 ==================================================
[2022-04-13 19:44:33.835] E018 |   200/667 batches | lr 0.0781 | loss  4.578 | ppl     97.36 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:44:51.784] E018 |   400/667 batches | lr 0.0781 | loss  4.553 | ppl     94.87 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:45:09.697] E018 |   600/667 batches | lr 0.0781 | loss  4.447 | ppl     85.39 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:45:15.673] E018 |   667/667 batches | lr 0.0781 | loss  4.360 | ppl     78.24 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:45:21.554] End E018 | valid loss  5.895; ppl    363.25 | accu 0.2293 = 25729/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:45:27.338] End E018 |  test loss 10.313; ppl  30109.68 | accu 0.0784 = 9047/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:45:53.576] End E018 |  test loss 10.888; ppl  53506.91 | accu 0.0088 = 4478/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:45:53.576] Epoch 019/20 ==================================================
[2022-04-13 19:46:11.378] E019 |   200/667 batches | lr 0.0391 | loss  4.576 | ppl     97.15 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:46:29.299] E019 |   400/667 batches | lr 0.0391 | loss  4.552 | ppl     94.79 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:46:47.257] E019 |   600/667 batches | lr 0.0391 | loss  4.445 | ppl     85.24 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:46:53.254] E019 |   667/667 batches | lr 0.0391 | loss  4.358 | ppl     78.13 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:46:59.139] End E019 | valid loss  5.896; ppl    363.65 | accu 0.2294 = 25748/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:47:05.019] End E019 |  test loss 10.318; ppl  30283.81 | accu 0.0783 = 9033/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:47:31.310] End E019 |  test loss 10.931; ppl  55857.73 | accu 0.0088 = 4453/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:47:31.310] Epoch 020/20 ==================================================
[2022-04-13 19:47:49.062] E020 |   200/667 batches | lr 0.0195 | loss  4.575 | ppl     97.01 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:48:06.884] E020 |   400/667 batches | lr 0.0195 | loss  4.553 | ppl     94.96 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:48:24.850] E020 |   600/667 batches | lr 0.0195 | loss  4.444 | ppl     85.11 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:48:30.825] E020 |   667/667 batches | lr 0.0195 | loss  4.361 | ppl     78.31 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:48:36.777] End E020 | valid loss  5.897; ppl    363.82 | accu 0.2294 = 25744/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:48:42.575] End E020 |  test loss 10.320; ppl  30341.75 | accu 0.0783 = 9035/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:49:08.913] End E020 |  test loss 10.937; ppl  56206.35 | accu 0.0088 = 4455/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:49:14.838] End. test loss 10.21; ppl 27043.83 | accu 0.0783 = 9029/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:49:41.113] End. test loss 11.41; ppl 89901.62 | accu 0.0075 = 3817/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:49:41.113] =========================================================================================
[2022-04-13 19:49:41.114] valid_loss
[2022-04-13 19:49:41.114]  6.81, 6.20, 6.14, 6.01, 5.97, 5.99, 5.90, 5.92, 5.89, 5.89, 5.89, 5.89, 5.90, 5.90, 5.90, 5.89, 5.89, 5.90, 5.90, 5.90
[2022-04-13 19:49:41.114] valid_loss ppl
[2022-04-13 19:49:41.114]   905.83,  493.60,  465.77,  407.62,  391.68,  400.22,  364.52,  371.37,  362.30,  362.72,  362.27,  362.23,  363.90,  364.26,  363.44,  363.12,  362.87,  363.25,  363.65,  363.82
[2022-04-13 19:49:41.114] test_loss of ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:49:41.114]  7.29, 7.83, 7.56, 8.28, 8.44, 8.62, 9.07, 9.37, 9.71, 9.84,10.11,10.21,10.18,10.21,10.33,10.33,10.31,10.31,10.32,10.32
[2022-04-13 19:49:41.114] test_loss of ../data/sample_500k/cbt_valid.txt ppl
[2022-04-13 19:49:41.114]  1461.30, 2514.56, 1926.39, 3963.11, 4637.84, 5530.11, 8649.20,11746.44,16417.00,18801.45,24506.78,27043.83,26404.55,27175.15,30731.50,30716.03,30036.93,30109.68,30283.81,30341.75
[2022-04-13 19:49:41.114] test_loss of ../data/sample_500k/adult_test.txt
[2022-04-13 19:49:41.114]  8.41, 9.65, 9.18,10.92,10.32,10.74,10.98,11.19,11.24,11.95,11.74,11.41,11.59,11.25,11.16,11.08,10.92,10.89,10.93,10.94
[2022-04-13 19:49:41.114] test_loss of ../data/sample_500k/adult_test.txt ppl
[2022-04-13 19:49:41.114]  4481.12,15514.71, 9690.06,55158.85,30467.00,46031.88,58702.46,72664.69,76044.20,154062.30,125058.03,89901.62,108437.62,76674.95,70279.07,65094.85,55515.87,53506.91,55857.73,56206.35
[2022-04-13 19:49:41.114] 
[2022-04-13 19:49:41.114] 
[2022-04-13 19:49:41.114] 
Log file: ./output_wsm_Subword.2000_fam_CNN.log closed.
Log file: ./output_wsm_Subword.2000_fam_LSTM.log open...
[2022-04-13 19:49:41.125] corpus.train_file_list: 1
[2022-04-13 19:49:41.125]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 19:49:41.125] corpus.valid_file_list: 1
[2022-04-13 19:49:41.125]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 19:49:41.125] corpus.test_file_list: 2
[2022-04-13 19:49:41.125]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:49:41.125]         ../data/sample_500k/adult_test.txt
[2022-04-13 19:49:41.125] corpus.subword_vocab_size: 0
[2022-04-13 19:49:41.126] corpus.subword_model = None. Corpus will not use subword.
[2022-04-13 19:49:41.126] corpus tokenize...
[2022-04-13 19:49:42.165]         train tokens: 467267  ../data/sample_500k/adolescent_train.txt
[2022-04-13 19:49:42.395]         valid tokens: 112256  ../data/sample_500k/adolescent_valid.txt
[2022-04-13 19:49:42.537]         test  tokens: 115417  ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:49:43.177]         test  tokens: 506878  ../data/sample_500k/adult_test.txt
[2022-04-13 19:49:43.177] corpus.ntokens      : 95521
[2022-04-13 19:49:43.177] corpus.char_count   : 166
[2022-04-13 19:49:43.177] corpus.char_cnt_dict: 166
[2022-04-13 19:49:43.178] corpus.char_id_dict : 166
[2022-04-13 19:49:43.183] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 19:49:43.184]         tokens_all: 467267
[2022-04-13 19:49:43.184]         batched   :  23363
[2022-04-13 19:49:43.184]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 19:49:43.188] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 19:49:43.188]         tokens_all: 112256
[2022-04-13 19:49:43.188]         batched   :   5612
[2022-04-13 19:49:43.188]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 19:49:43.193] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 19:49:43.193]         tokens_all: 115417
[2022-04-13 19:49:43.193]         batched   :   5770
[2022-04-13 19:49:43.193]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:49:43.202] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 19:49:43.202]         tokens_all: 506878
[2022-04-13 19:49:43.202]         batched   :  25343
[2022-04-13 19:49:43.202]         ../data/sample_500k/adult_test.txt
[2022-04-13 19:49:43.203] subword_adapter will be generated due to word_split_mode='Subword.2000'
[2022-04-13 19:49:43.203] SubwordAdapter.file_list: 2
[2022-04-13 19:49:43.203]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 19:49:43.203]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 19:49:43.203] SubwordAdapter.subword_vocab_size: 2000
[2022-04-13 19:49:43.203] SubwordAdapter.subword_model.train(2 files)...
[2022-04-13 19:49:43.859] SubwordAdapter.subword_model.train(2 files)...Done
[2022-04-13 19:49:44.572] RNNModel.rnn_type: LSTM
[2022-04-13 19:49:44.572] RNNModel.ntoken  : 95521
[2022-04-13 19:49:44.572] RNNModel.ninp    : 200
[2022-04-13 19:49:44.572] RNNModel.nhid    : 200
[2022-04-13 19:49:44.572] RNNModel.nlayers : 2
[2022-04-13 19:49:44.572] RNNModel.dropout : 0.2
[2022-04-13 19:49:44.573] RNNModel.tie_weights: False
[2022-04-13 19:49:44.573] RNNModel.fragment_aggregate_mode: LSTM
[2022-04-13 19:49:44.573] RNNModel.fragment_cnt           : 2002
[2022-04-13 19:49:44.573] RNNModel.fragment_emsize        : 25
[2022-04-13 19:49:44.573] RNNModel.fragment_nhid          : 200
[2022-04-13 19:49:44.574] RNNModel.fragment_embeds     : created
[2022-04-13 19:49:44.577] RNNModel.fragment_lstm       : created
[2022-04-13 19:49:44.577] RNNModel.fragment_lstm_linear: created
[2022-04-13 19:49:44.619] Epoch 001/20 ==================================================
[2022-04-13 19:50:45.012] E001 |   200/667 batches | lr 20.0000 | loss  8.570 | ppl   5272.91 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:51:46.710] E001 |   400/667 batches | lr 20.0000 | loss  7.797 | ppl   2432.95 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:52:48.520] E001 |   600/667 batches | lr 20.0000 | loss  7.241 | ppl   1395.12 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:53:10.466] E001 |   667/667 batches | lr 20.0000 | loss  6.926 | ppl   1018.82 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:53:24.733] End E001 | valid loss  6.953; ppl   1046.10 | accu 0.1181 = 13258/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:53:38.955] End E001 |  test loss  7.344; ppl   1547.18 | accu 0.0855 = 9869/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:54:43.532] End E001 |  test loss  8.325; ppl   4126.02 | accu 0.0473 = 23990/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:54:43.533] Save: model.pt... 
[2022-04-13 19:54:44.176] Save: model.pt...Done. best_val_loss: 6.9528
[2022-04-13 19:54:44.176] Epoch 002/20 ==================================================
[2022-04-13 19:55:45.596] E002 |   200/667 batches | lr 20.0000 | loss  6.731 | ppl    837.78 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 19:56:47.725] E002 |   400/667 batches | lr 20.0000 | loss  6.529 | ppl    685.00 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 19:57:50.397] E002 |   600/667 batches | lr 20.0000 | loss  6.298 | ppl    543.54 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 19:58:11.576] E002 |   667/667 batches | lr 20.0000 | loss  6.160 | ppl    473.36 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 19:58:26.142] End E002 | valid loss  6.260; ppl    523.40 | accu 0.1863 = 20907/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 19:58:40.837] End E002 |  test loss  7.347; ppl   1551.67 | accu 0.0826 = 9525/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 19:59:45.454] End E002 |  test loss  8.535; ppl   5088.73 | accu 0.0369 = 18706/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 19:59:45.454] Save: model.pt... 
[2022-04-13 19:59:46.052] Save: model.pt...Done. best_val_loss: 6.2603
[2022-04-13 19:59:46.052] Epoch 003/20 ==================================================
[2022-04-13 20:00:49.605] E003 |   200/667 batches | lr 20.0000 | loss  6.115 | ppl    452.65 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 20:01:54.498] E003 |   400/667 batches | lr 20.0000 | loss  6.048 | ppl    423.20 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 20:02:57.148] E003 |   600/667 batches | lr 20.0000 | loss  5.899 | ppl    364.56 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 20:03:18.329] E003 |   667/667 batches | lr 20.0000 | loss  5.811 | ppl    333.89 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 20:03:32.965] End E003 | valid loss  6.086; ppl    439.56 | accu 0.2067 = 23191/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 20:03:47.595] End E003 |  test loss  7.513; ppl   1832.20 | accu 0.0802 = 9254/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 20:04:53.039] End E003 |  test loss  8.817; ppl   6748.38 | accu 0.0279 = 14134/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 20:04:53.039] Save: model.pt... 
[2022-04-13 20:04:53.634] Save: model.pt...Done. best_val_loss: 6.0858
[2022-04-13 20:04:53.634] Epoch 004/20 ==================================================
[2022-04-13 20:05:56.723] E004 |   200/667 batches | lr 20.0000 | loss  5.788 | ppl    326.27 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 20:06:59.634] E004 |   400/667 batches | lr 20.0000 | loss  5.760 | ppl    317.45 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 20:08:03.155] E004 |   600/667 batches | lr 20.0000 | loss  5.637 | ppl    280.51 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 20:08:24.221] E004 |   667/667 batches | lr 20.0000 | loss  5.566 | ppl    261.34 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 20:08:38.745] End E004 | valid loss  6.002; ppl    404.10 | accu 0.2104 = 23612/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 20:08:53.269] End E004 |  test loss  7.510; ppl   1825.52 | accu 0.0846 = 9766/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 20:09:58.354] End E004 |  test loss  8.680; ppl   5882.66 | accu 0.0344 = 17433/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 20:09:58.354] Save: model.pt... 
[2022-04-13 20:09:58.954] Save: model.pt...Done. best_val_loss: 6.0017
[2022-04-13 20:09:58.954] Epoch 005/20 ==================================================
[2022-04-13 20:11:02.678] E005 |   200/667 batches | lr 20.0000 | loss  5.551 | ppl    257.58 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 20:12:05.487] E005 |   400/667 batches | lr 20.0000 | loss  5.541 | ppl    255.06 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 20:13:08.591] E005 |   600/667 batches | lr 20.0000 | loss  5.437 | ppl    229.70 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 20:13:29.728] E005 |   667/667 batches | lr 20.0000 | loss  5.361 | ppl    212.90 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 20:13:44.168] End E005 | valid loss  5.981; ppl    395.75 | accu 0.2096 = 23523/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 20:13:58.712] End E005 |  test loss  7.642; ppl   2083.87 | accu 0.0881 = 10167/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 20:15:03.096] End E005 |  test loss  8.728; ppl   6173.76 | accu 0.0320 = 16232/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 20:15:03.096] Save: model.pt... 
[2022-04-13 20:15:03.696] Save: model.pt...Done. best_val_loss: 5.9808
[2022-04-13 20:15:03.696] Epoch 006/20 ==================================================
[2022-04-13 20:16:05.198] E006 |   200/667 batches | lr 20.0000 | loss  5.358 | ppl    212.27 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 20:17:07.830] E006 |   400/667 batches | lr 20.0000 | loss  5.362 | ppl    213.24 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 20:18:11.540] E006 |   600/667 batches | lr 20.0000 | loss  5.265 | ppl    193.39 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 20:18:33.046] E006 |   667/667 batches | lr 20.0000 | loss  5.209 | ppl    182.84 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 20:18:47.734] End E006 | valid loss  5.988; ppl    398.75 | accu 0.2062 = 23139/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 20:19:02.383] End E006 |  test loss  7.165; ppl   1293.01 | accu 0.1020 = 11768/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 20:20:07.717] End E006 |  test loss  8.255; ppl   3847.25 | accu 0.0445 = 22570/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 20:20:07.717] Epoch 007/20 ==================================================
[2022-04-13 20:21:11.036] E007 |   200/667 batches | lr 10.0000 | loss  5.104 | ppl    164.72 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 20:22:15.271] E007 |   400/667 batches | lr 10.0000 | loss  5.065 | ppl    158.36 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 20:23:18.396] E007 |   600/667 batches | lr 10.0000 | loss  4.944 | ppl    140.39 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 20:23:40.246] E007 |   667/667 batches | lr 10.0000 | loss  4.869 | ppl    130.22 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 20:23:54.552] End E007 | valid loss  5.931; ppl    376.36 | accu 0.2177 = 24430/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 20:24:09.213] End E007 |  test loss  7.420; ppl   1668.74 | accu 0.0934 = 10774/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 20:25:13.566] End E007 |  test loss  8.643; ppl   5669.53 | accu 0.0265 = 13435/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 20:25:13.566] Save: model.pt... 
[2022-04-13 20:25:14.156] Save: model.pt...Done. best_val_loss: 5.9305
[2022-04-13 20:25:14.156] Epoch 008/20 ==================================================
[2022-04-13 20:26:16.944] E008 |   200/667 batches | lr 10.0000 | loss  4.958 | ppl    142.28 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 20:27:19.743] E008 |   400/667 batches | lr 10.0000 | loss  4.943 | ppl    140.22 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 20:28:23.333] E008 |   600/667 batches | lr 10.0000 | loss  4.844 | ppl    126.95 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 20:28:44.570] E008 |   667/667 batches | lr 10.0000 | loss  4.778 | ppl    118.87 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 20:28:59.089] End E008 | valid loss  5.946; ppl    382.05 | accu 0.2173 = 24390/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 20:29:13.841] End E008 |  test loss  7.380; ppl   1603.47 | accu 0.0943 = 10879/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 20:30:18.897] End E008 |  test loss  8.917; ppl   7454.55 | accu 0.0211 = 10688/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 20:30:18.897] Epoch 009/20 ==================================================
[2022-04-13 20:31:21.312] E009 |   200/667 batches | lr 5.0000 | loss  4.829 | ppl    125.05 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 20:32:24.464] E009 |   400/667 batches | lr 5.0000 | loss  4.789 | ppl    120.20 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 20:33:27.982] E009 |   600/667 batches | lr 5.0000 | loss  4.670 | ppl    106.65 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 20:33:48.879] E009 |   667/667 batches | lr 5.0000 | loss  4.592 | ppl     98.70 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 20:34:03.321] End E009 | valid loss  5.920; ppl    372.48 | accu 0.2213 = 24831/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 20:34:17.629] End E009 |  test loss  7.368; ppl   1584.98 | accu 0.1020 = 11772/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 20:35:22.281] End E009 |  test loss  8.660; ppl   5766.25 | accu 0.0257 = 13051/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 20:35:22.281] Save: model.pt... 
[2022-04-13 20:35:22.915] Save: model.pt...Done. best_val_loss: 5.9202
[2022-04-13 20:35:22.915] Epoch 010/20 ==================================================
[2022-04-13 20:36:23.918] E010 |   200/667 batches | lr 5.0000 | loss  4.747 | ppl    115.27 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 20:37:27.586] E010 |   400/667 batches | lr 5.0000 | loss  4.719 | ppl    112.03 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 20:38:32.410] E010 |   600/667 batches | lr 5.0000 | loss  4.622 | ppl    101.73 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 20:38:54.186] E010 |   667/667 batches | lr 5.0000 | loss  4.551 | ppl     94.75 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 20:39:08.476] End E010 | valid loss  5.929; ppl    375.68 | accu 0.2219 = 24901/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 20:39:22.812] End E010 |  test loss  7.382; ppl   1607.21 | accu 0.0983 = 11345/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 20:40:28.147] End E010 |  test loss  8.612; ppl   5499.02 | accu 0.0265 = 13452/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 20:40:28.147] Epoch 011/20 ==================================================
[2022-04-13 20:41:30.389] E011 |   200/667 batches | lr 2.5000 | loss  4.681 | ppl    107.88 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 20:42:33.396] E011 |   400/667 batches | lr 2.5000 | loss  4.641 | ppl    103.69 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 20:43:36.904] E011 |   600/667 batches | lr 2.5000 | loss  4.533 | ppl     92.99 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 20:43:58.122] E011 |   667/667 batches | lr 2.5000 | loss  4.451 | ppl     85.71 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 20:44:12.670] End E011 | valid loss  5.931; ppl    376.58 | accu 0.2245 = 25192/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 20:44:27.396] End E011 |  test loss  7.372; ppl   1591.57 | accu 0.1003 = 11572/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 20:45:32.075] End E011 |  test loss  8.651; ppl   5713.07 | accu 0.0260 = 13195/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 20:45:32.075] Epoch 012/20 ==================================================
[2022-04-13 20:46:33.305] E012 |   200/667 batches | lr 1.2500 | loss  4.638 | ppl    103.35 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 20:47:38.119] E012 |   400/667 batches | lr 1.2500 | loss  4.597 | ppl     99.17 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 20:48:42.217] E012 |   600/667 batches | lr 1.2500 | loss  4.481 | ppl     88.36 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 20:49:03.904] E012 |   667/667 batches | lr 1.2500 | loss  4.398 | ppl     81.29 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 20:49:18.382] End E012 | valid loss  5.932; ppl    377.02 | accu 0.2261 = 25376/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 20:49:32.893] End E012 |  test loss  7.393; ppl   1624.50 | accu 0.1004 = 11579/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 20:50:38.412] End E012 |  test loss  8.688; ppl   5930.50 | accu 0.0238 = 12044/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 20:50:38.412] Epoch 013/20 ==================================================
[2022-04-13 20:51:39.830] E013 |   200/667 batches | lr 0.6250 | loss  4.614 | ppl    100.87 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 20:52:43.498] E013 |   400/667 batches | lr 0.6250 | loss  4.574 | ppl     96.93 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 20:53:45.889] E013 |   600/667 batches | lr 0.6250 | loss  4.458 | ppl     86.33 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 20:54:07.523] E013 |   667/667 batches | lr 0.6250 | loss  4.378 | ppl     79.65 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 20:54:22.147] End E013 | valid loss  5.932; ppl    377.02 | accu 0.2270 = 25477/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 20:54:36.984] End E013 |  test loss  7.390; ppl   1619.02 | accu 0.1015 = 11710/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 20:55:41.120] End E013 |  test loss  8.705; ppl   6034.54 | accu 0.0240 = 12171/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 20:55:41.120] Epoch 014/20 ==================================================
[2022-04-13 20:56:43.976] E014 |   200/667 batches | lr 0.3125 | loss  4.596 | ppl     99.09 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 20:57:47.530] E014 |   400/667 batches | lr 0.3125 | loss  4.563 | ppl     95.91 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 20:58:50.789] E014 |   600/667 batches | lr 0.3125 | loss  4.444 | ppl     85.12 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 20:59:12.115] E014 |   667/667 batches | lr 0.3125 | loss  4.361 | ppl     78.37 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 20:59:26.808] End E014 | valid loss  5.932; ppl    377.04 | accu 0.2274 = 25524/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 20:59:41.303] End E014 |  test loss  7.391; ppl   1622.10 | accu 0.1008 = 11635/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:00:46.699] End E014 |  test loss  8.721; ppl   6133.22 | accu 0.0234 = 11838/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:00:46.700] Epoch 015/20 ==================================================
[2022-04-13 21:01:47.884] E015 |   200/667 batches | lr 0.1562 | loss  4.591 | ppl     98.62 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 21:02:50.749] E015 |   400/667 batches | lr 0.1562 | loss  4.553 | ppl     94.94 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 21:03:54.063] E015 |   600/667 batches | lr 0.1562 | loss  4.436 | ppl     84.43 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 21:04:14.837] E015 |   667/667 batches | lr 0.1562 | loss  4.351 | ppl     77.53 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 21:04:29.189] End E015 | valid loss  5.933; ppl    377.31 | accu 0.2277 = 25554/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 21:04:43.705] End E015 |  test loss  7.379; ppl   1601.98 | accu 0.0999 = 11521/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:05:47.889] End E015 |  test loss  8.729; ppl   6177.60 | accu 0.0229 = 11623/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:05:47.890] Epoch 016/20 ==================================================
[2022-04-13 21:06:48.027] E016 |   200/667 batches | lr 0.0781 | loss  4.589 | ppl     98.37 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 21:07:50.227] E016 |   400/667 batches | lr 0.0781 | loss  4.550 | ppl     94.68 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 21:08:53.432] E016 |   600/667 batches | lr 0.0781 | loss  4.433 | ppl     84.18 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 21:09:14.214] E016 |   667/667 batches | lr 0.0781 | loss  4.353 | ppl     77.72 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 21:09:28.476] End E016 | valid loss  5.933; ppl    377.40 | accu 0.2278 = 25559/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 21:09:42.930] End E016 |  test loss  7.379; ppl   1602.49 | accu 0.1000 = 11541/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:10:47.713] End E016 |  test loss  8.727; ppl   6169.39 | accu 0.0230 = 11667/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:10:47.713] Epoch 017/20 ==================================================
[2022-04-13 21:11:49.902] E017 |   200/667 batches | lr 0.0391 | loss  4.586 | ppl     98.09 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 21:12:52.995] E017 |   400/667 batches | lr 0.0391 | loss  4.551 | ppl     94.69 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 21:13:56.264] E017 |   600/667 batches | lr 0.0391 | loss  4.432 | ppl     84.06 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 21:14:18.035] E017 |   667/667 batches | lr 0.0391 | loss  4.348 | ppl     77.29 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 21:14:32.410] End E017 | valid loss  5.934; ppl    377.79 | accu 0.2277 = 25548/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 21:14:47.112] End E017 |  test loss  7.381; ppl   1605.40 | accu 0.0999 = 11528/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:15:51.716] End E017 |  test loss  8.728; ppl   6173.89 | accu 0.0229 = 11623/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:15:51.716] Epoch 018/20 ==================================================
[2022-04-13 21:16:52.315] E018 |   200/667 batches | lr 0.0195 | loss  4.585 | ppl     97.97 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 21:17:54.370] E018 |   400/667 batches | lr 0.0195 | loss  4.549 | ppl     94.56 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 21:18:57.169] E018 |   600/667 batches | lr 0.0195 | loss  4.430 | ppl     83.89 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 21:19:18.294] E018 |   667/667 batches | lr 0.0195 | loss  4.343 | ppl     76.96 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 21:19:32.544] End E018 | valid loss  5.935; ppl    378.19 | accu 0.2277 = 25556/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 21:19:47.005] End E018 |  test loss  7.385; ppl   1611.21 | accu 0.0998 = 11519/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:20:50.977] End E018 |  test loss  8.733; ppl   6206.79 | accu 0.0228 = 11557/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:20:50.978] Epoch 019/20 ==================================================
[2022-04-13 21:21:51.632] E019 |   200/667 batches | lr 0.0098 | loss  4.586 | ppl     98.08 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 21:22:54.490] E019 |   400/667 batches | lr 0.0098 | loss  4.548 | ppl     94.43 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 21:23:59.183] E019 |   600/667 batches | lr 0.0098 | loss  4.430 | ppl     83.94 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 21:24:19.808] E019 |   667/667 batches | lr 0.0098 | loss  4.348 | ppl     77.32 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 21:24:34.427] End E019 | valid loss  5.936; ppl    378.25 | accu 0.2278 = 25563/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 21:24:49.179] End E019 |  test loss  7.384; ppl   1610.52 | accu 0.0998 = 11514/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:25:53.731] End E019 |  test loss  8.732; ppl   6200.62 | accu 0.0228 = 11557/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:25:53.731] Epoch 020/20 ==================================================
[2022-04-13 21:26:54.873] E020 |   200/667 batches | lr 0.0049 | loss  4.584 | ppl     97.88 frag_cnt/word_cnt=1.997=279613/140000
[2022-04-13 21:27:58.042] E020 |   400/667 batches | lr 0.0049 | loss  4.548 | ppl     94.48 frag_cnt/word_cnt=2.024=283418/140000
[2022-04-13 21:29:00.344] E020 |   600/667 batches | lr 0.0049 | loss  4.431 | ppl     83.99 frag_cnt/word_cnt=2.013=281770/140000
[2022-04-13 21:29:21.083] E020 |   667/667 batches | lr 0.0049 | loss  4.352 | ppl     77.63 frag_cnt/word_cnt=2.008=94189/46900
[2022-04-13 21:29:35.855] End E020 | valid loss  5.936; ppl    378.26 | accu 0.2278 = 25566/112220 | w_len 1.9387 = 217561/112220
[2022-04-13 21:29:50.192] End E020 |  test loss  7.384; ppl   1610.78 | accu 0.0998 = 11510/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:30:54.380] End E020 |  test loss  8.732; ppl   6198.49 | accu 0.0228 = 11559/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:31:10.681] End. test loss  7.37; ppl  1584.98 | accu 0.1020 = 11772/115380 | w_len 1.4314 = 165159/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:32:15.430] End. test loss  8.66; ppl  5766.25 | accu 0.0257 = 13051/506840 | w_len 1.9384 = 982436/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:32:15.430] =========================================================================================
[2022-04-13 21:32:15.430] valid_loss
[2022-04-13 21:32:15.430]  6.95, 6.26, 6.09, 6.00, 5.98, 5.99, 5.93, 5.95, 5.92, 5.93, 5.93, 5.93, 5.93, 5.93, 5.93, 5.93, 5.93, 5.94, 5.94, 5.94
[2022-04-13 21:32:15.430] valid_loss ppl
[2022-04-13 21:32:15.430]  1046.10,  523.40,  439.56,  404.10,  395.75,  398.75,  376.36,  382.05,  372.48,  375.68,  376.58,  377.02,  377.02,  377.04,  377.31,  377.40,  377.79,  378.19,  378.25,  378.26
[2022-04-13 21:32:15.430] test_loss of ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:32:15.430]  7.34, 7.35, 7.51, 7.51, 7.64, 7.16, 7.42, 7.38, 7.37, 7.38, 7.37, 7.39, 7.39, 7.39, 7.38, 7.38, 7.38, 7.38, 7.38, 7.38
[2022-04-13 21:32:15.430] test_loss of ../data/sample_500k/cbt_valid.txt ppl
[2022-04-13 21:32:15.430]  1547.18, 1551.67, 1832.20, 1825.52, 2083.87, 1293.01, 1668.74, 1603.47, 1584.98, 1607.21, 1591.57, 1624.50, 1619.02, 1622.10, 1601.98, 1602.49, 1605.40, 1611.21, 1610.52, 1610.78
[2022-04-13 21:32:15.430] test_loss of ../data/sample_500k/adult_test.txt
[2022-04-13 21:32:15.431]  8.33, 8.53, 8.82, 8.68, 8.73, 8.26, 8.64, 8.92, 8.66, 8.61, 8.65, 8.69, 8.71, 8.72, 8.73, 8.73, 8.73, 8.73, 8.73, 8.73
[2022-04-13 21:32:15.431] test_loss of ../data/sample_500k/adult_test.txt ppl
[2022-04-13 21:32:15.431]  4126.02, 5088.73, 6748.38, 5882.66, 6173.76, 3847.25, 5669.53, 7454.55, 5766.25, 5499.02, 5713.07, 5930.50, 6034.54, 6133.22, 6177.60, 6169.39, 6173.89, 6206.79, 6200.62, 6198.49
[2022-04-13 21:32:15.431] 
[2022-04-13 21:32:15.431] 
[2022-04-13 21:32:15.431] 
Log file: ./output_wsm_Subword.2000_fam_LSTM.log closed.
Log file: ./output_wsm_Subword.5000_fam_CNN.log open...
[2022-04-13 21:32:15.442] corpus.train_file_list: 1
[2022-04-13 21:32:15.442]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 21:32:15.442] corpus.valid_file_list: 1
[2022-04-13 21:32:15.443]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 21:32:15.443] corpus.test_file_list: 2
[2022-04-13 21:32:15.443]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:32:15.443]         ../data/sample_500k/adult_test.txt
[2022-04-13 21:32:15.443] corpus.subword_vocab_size: 0
[2022-04-13 21:32:15.443] corpus.subword_model = None. Corpus will not use subword.
[2022-04-13 21:32:15.443] corpus tokenize...
[2022-04-13 21:32:16.526]         train tokens: 467267  ../data/sample_500k/adolescent_train.txt
[2022-04-13 21:32:16.755]         valid tokens: 112256  ../data/sample_500k/adolescent_valid.txt
[2022-04-13 21:32:16.912]         test  tokens: 115417  ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:32:17.569]         test  tokens: 506878  ../data/sample_500k/adult_test.txt
[2022-04-13 21:32:17.570] corpus.ntokens      : 95521
[2022-04-13 21:32:17.570] corpus.char_count   : 166
[2022-04-13 21:32:17.570] corpus.char_cnt_dict: 166
[2022-04-13 21:32:17.570] corpus.char_id_dict : 166
[2022-04-13 21:32:17.575] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 21:32:17.575]         tokens_all: 467267
[2022-04-13 21:32:17.576]         batched   :  23363
[2022-04-13 21:32:17.576]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 21:32:17.578] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 21:32:17.578]         tokens_all: 112256
[2022-04-13 21:32:17.579]         batched   :   5612
[2022-04-13 21:32:17.579]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 21:32:17.581] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 21:32:17.581]         tokens_all: 115417
[2022-04-13 21:32:17.581]         batched   :   5770
[2022-04-13 21:32:17.581]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:32:17.587] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 21:32:17.587]         tokens_all: 506878
[2022-04-13 21:32:17.587]         batched   :  25343
[2022-04-13 21:32:17.587]         ../data/sample_500k/adult_test.txt
[2022-04-13 21:32:17.588] subword_adapter will be generated due to word_split_mode='Subword.5000'
[2022-04-13 21:32:17.588] SubwordAdapter.file_list: 2
[2022-04-13 21:32:17.588]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 21:32:17.588]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 21:32:17.588] SubwordAdapter.subword_vocab_size: 5000
[2022-04-13 21:32:17.588] SubwordAdapter.subword_model.train(2 files)...
[2022-04-13 21:32:18.514] SubwordAdapter.subword_model.train(2 files)...Done
[2022-04-13 21:32:19.176] RNNModel.rnn_type: LSTM
[2022-04-13 21:32:19.176] RNNModel.ntoken  : 95521
[2022-04-13 21:32:19.176] RNNModel.ninp    : 200
[2022-04-13 21:32:19.176] RNNModel.nhid    : 200
[2022-04-13 21:32:19.176] RNNModel.nlayers : 2
[2022-04-13 21:32:19.176] RNNModel.dropout : 0.2
[2022-04-13 21:32:19.176] RNNModel.tie_weights: False
[2022-04-13 21:32:19.176] RNNModel.fragment_aggregate_mode: CNN
[2022-04-13 21:32:19.177] RNNModel.fragment_cnt           : 5002
[2022-04-13 21:32:19.177] RNNModel.fragment_emsize        : 25
[2022-04-13 21:32:19.177] RNNModel.fragment_nhid          : 200
[2022-04-13 21:32:19.179] RNNModel.fragment_embeds     : created
[2022-04-13 21:32:19.179] RNNModel.fragment_cnn3       : created
[2022-04-13 21:32:19.219] Epoch 001/20 ==================================================
[2022-04-13 21:32:36.870] E001 |   200/667 batches | lr 20.0000 | loss  8.525 | ppl   5038.00 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 21:32:54.780] E001 |   400/667 batches | lr 20.0000 | loss  7.582 | ppl   1962.44 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 21:33:12.562] E001 |   600/667 batches | lr 20.0000 | loss  6.991 | ppl   1087.18 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 21:33:18.567] E001 |   667/667 batches | lr 20.0000 | loss  6.693 | ppl    806.82 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 21:33:24.471] End E001 | valid loss  6.644; ppl    768.10 | accu 0.1630 = 18289/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 21:33:30.308] End E001 |  test loss  7.496; ppl   1800.95 | accu 0.0782 = 9023/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:33:56.729] End E001 |  test loss  8.652; ppl   5723.69 | accu 0.0221 = 11203/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:33:56.729] Save: model.pt... 
[2022-04-13 21:33:57.348] Save: model.pt...Done. best_val_loss: 6.6439
[2022-04-13 21:33:57.349] Epoch 002/20 ==================================================
[2022-04-13 21:34:15.102] E002 |   200/667 batches | lr 20.0000 | loss  6.543 | ppl    694.17 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 21:34:32.966] E002 |   400/667 batches | lr 20.0000 | loss  6.388 | ppl    594.71 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 21:34:50.921] E002 |   600/667 batches | lr 20.0000 | loss  6.172 | ppl    479.16 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 21:34:56.952] E002 |   667/667 batches | lr 20.0000 | loss  6.054 | ppl    425.93 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 21:35:02.919] End E002 | valid loss  6.194; ppl    490.00 | accu 0.1965 = 22050/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 21:35:08.749] End E002 |  test loss  8.079; ppl   3225.34 | accu 0.0651 = 7511/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:35:35.153] End E002 |  test loss  9.854; ppl  19036.25 | accu 0.0061 = 3071/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:35:35.153] Save: model.pt... 
[2022-04-13 21:35:35.752] Save: model.pt...Done. best_val_loss: 6.1944
[2022-04-13 21:35:35.752] Epoch 003/20 ==================================================
[2022-04-13 21:35:53.543] E003 |   200/667 batches | lr 20.0000 | loss  6.014 | ppl    409.29 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 21:36:11.392] E003 |   400/667 batches | lr 20.0000 | loss  5.974 | ppl    393.12 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 21:36:29.321] E003 |   600/667 batches | lr 20.0000 | loss  5.832 | ppl    340.97 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 21:36:35.275] E003 |   667/667 batches | lr 20.0000 | loss  5.744 | ppl    312.29 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 21:36:41.181] End E003 | valid loss  6.083; ppl    438.45 | accu 0.2033 = 22819/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 21:36:47.038] End E003 |  test loss  7.907; ppl   2716.18 | accu 0.0723 = 8339/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:37:13.464] End E003 |  test loss  9.677; ppl  15950.57 | accu 0.0044 = 2255/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:37:13.464] Save: model.pt... 
[2022-04-13 21:37:14.062] Save: model.pt...Done. best_val_loss: 6.0832
[2022-04-13 21:37:14.062] Epoch 004/20 ==================================================
[2022-04-13 21:37:31.929] E004 |   200/667 batches | lr 20.0000 | loss  5.728 | ppl    307.40 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 21:37:49.841] E004 |   400/667 batches | lr 20.0000 | loss  5.716 | ppl    303.77 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 21:38:07.625] E004 |   600/667 batches | lr 20.0000 | loss  5.604 | ppl    271.38 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 21:38:13.498] E004 |   667/667 batches | lr 20.0000 | loss  5.521 | ppl    249.94 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 21:38:19.453] End E004 | valid loss  6.024; ppl    413.16 | accu 0.2071 = 23236/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 21:38:25.342] End E004 |  test loss  7.742; ppl   2301.99 | accu 0.0737 = 8499/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:38:51.765] End E004 |  test loss  9.186; ppl   9758.62 | accu 0.0108 = 5499/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:38:51.765] Save: model.pt... 
[2022-04-13 21:38:52.363] Save: model.pt...Done. best_val_loss: 6.0238
[2022-04-13 21:38:52.363] Epoch 005/20 ==================================================
[2022-04-13 21:39:10.220] E005 |   200/667 batches | lr 20.0000 | loss  5.514 | ppl    248.07 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 21:39:28.158] E005 |   400/667 batches | lr 20.0000 | loss  5.516 | ppl    248.58 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 21:39:46.149] E005 |   600/667 batches | lr 20.0000 | loss  5.417 | ppl    225.32 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 21:39:52.181] E005 |   667/667 batches | lr 20.0000 | loss  5.348 | ppl    210.18 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 21:39:58.138] End E005 | valid loss  5.976; ppl    393.94 | accu 0.2103 = 23597/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 21:40:04.036] End E005 |  test loss  8.096; ppl   3282.12 | accu 0.0705 = 8140/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:40:30.548] End E005 |  test loss  9.652; ppl  15550.77 | accu 0.0080 = 4030/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:40:30.548] Save: model.pt... 
[2022-04-13 21:40:31.139] Save: model.pt...Done. best_val_loss: 5.9762
[2022-04-13 21:40:31.139] Epoch 006/20 ==================================================
[2022-04-13 21:40:48.836] E006 |   200/667 batches | lr 20.0000 | loss  5.342 | ppl    208.96 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 21:41:06.718] E006 |   400/667 batches | lr 20.0000 | loss  5.358 | ppl    212.20 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 21:41:24.742] E006 |   600/667 batches | lr 20.0000 | loss  5.270 | ppl    194.46 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 21:41:30.753] E006 |   667/667 batches | lr 20.0000 | loss  5.203 | ppl    181.88 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 21:41:36.687] End E006 | valid loss  6.005; ppl    405.38 | accu 0.2088 = 23429/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 21:41:42.551] End E006 |  test loss  8.063; ppl   3174.99 | accu 0.0755 = 8712/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:42:09.093] End E006 |  test loss  9.490; ppl  13229.08 | accu 0.0136 = 6887/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:42:09.093] Epoch 007/20 ==================================================
[2022-04-13 21:42:26.933] E007 |   200/667 batches | lr 10.0000 | loss  5.111 | ppl    165.78 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 21:42:44.905] E007 |   400/667 batches | lr 10.0000 | loss  5.074 | ppl    159.81 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 21:43:02.850] E007 |   600/667 batches | lr 10.0000 | loss  4.956 | ppl    142.01 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 21:43:08.846] E007 |   667/667 batches | lr 10.0000 | loss  4.880 | ppl    131.66 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 21:43:14.838] End E007 | valid loss  5.934; ppl    377.48 | accu 0.2159 = 24232/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 21:43:20.689] End E007 |  test loss  7.843; ppl   2546.89 | accu 0.0778 = 8975/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:43:47.328] End E007 |  test loss  8.808; ppl   6684.81 | accu 0.0197 = 9986/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:43:47.328] Save: model.pt... 
[2022-04-13 21:43:47.930] Save: model.pt...Done. best_val_loss: 5.9335
[2022-04-13 21:43:47.930] Epoch 008/20 ==================================================
[2022-04-13 21:44:05.868] E008 |   200/667 batches | lr 10.0000 | loss  4.966 | ppl    143.42 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 21:44:23.907] E008 |   400/667 batches | lr 10.0000 | loss  4.956 | ppl    142.02 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 21:44:41.886] E008 |   600/667 batches | lr 10.0000 | loss  4.864 | ppl    129.49 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 21:44:47.923] E008 |   667/667 batches | lr 10.0000 | loss  4.802 | ppl    121.78 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 21:44:53.885] End E008 | valid loss  5.939; ppl    379.57 | accu 0.2162 = 24257/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 21:44:59.747] End E008 |  test loss  7.820; ppl   2490.71 | accu 0.0793 = 9150/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:45:26.423] End E008 |  test loss  8.461; ppl   4726.80 | accu 0.0341 = 17269/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:45:26.424] Epoch 009/20 ==================================================
[2022-04-13 21:45:44.219] E009 |   200/667 batches | lr 5.0000 | loss  4.841 | ppl    126.65 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 21:46:02.233] E009 |   400/667 batches | lr 5.0000 | loss  4.807 | ppl    122.32 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 21:46:20.197] E009 |   600/667 batches | lr 5.0000 | loss  4.692 | ppl    109.02 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 21:46:26.222] E009 |   667/667 batches | lr 5.0000 | loss  4.615 | ppl    100.97 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 21:46:32.122] End E009 | valid loss  5.924; ppl    373.98 | accu 0.2214 = 24851/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 21:46:37.977] End E009 |  test loss  7.853; ppl   2572.93 | accu 0.0819 = 9454/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:47:04.296] End E009 |  test loss  8.354; ppl   4248.27 | accu 0.0345 = 17475/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:47:04.297] Save: model.pt... 
[2022-04-13 21:47:04.889] Save: model.pt...Done. best_val_loss: 5.9242
[2022-04-13 21:47:04.889] Epoch 010/20 ==================================================
[2022-04-13 21:47:22.673] E010 |   200/667 batches | lr 5.0000 | loss  4.759 | ppl    116.63 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 21:47:40.583] E010 |   400/667 batches | lr 5.0000 | loss  4.737 | ppl    114.13 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 21:47:58.342] E010 |   600/667 batches | lr 5.0000 | loss  4.640 | ppl    103.50 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 21:48:04.338] E010 |   667/667 batches | lr 5.0000 | loss  4.571 | ppl     96.63 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 21:48:10.294] End E010 | valid loss  5.924; ppl    374.08 | accu 0.2214 = 24846/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 21:48:16.157] End E010 |  test loss  7.960; ppl   2864.51 | accu 0.0818 = 9433/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:48:42.568] End E010 |  test loss  8.531; ppl   5067.73 | accu 0.0295 = 14972/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:48:42.568] Epoch 011/20 ==================================================
[2022-04-13 21:49:00.386] E011 |   200/667 batches | lr 2.5000 | loss  4.691 | ppl    109.00 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 21:49:18.382] E011 |   400/667 batches | lr 2.5000 | loss  4.657 | ppl    105.31 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 21:49:36.299] E011 |   600/667 batches | lr 2.5000 | loss  4.550 | ppl     94.60 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 21:49:42.321] E011 |   667/667 batches | lr 2.5000 | loss  4.474 | ppl     87.75 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 21:49:48.207] End E011 | valid loss  5.917; ppl    371.20 | accu 0.2249 = 25234/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 21:49:54.039] End E011 |  test loss  7.888; ppl   2663.99 | accu 0.0826 = 9535/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:50:20.430] End E011 |  test loss  8.478; ppl   4808.30 | accu 0.0280 = 14198/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:50:20.430] Save: model.pt... 
[2022-04-13 21:50:21.064] Save: model.pt...Done. best_val_loss: 5.9168
[2022-04-13 21:50:21.064] Epoch 012/20 ==================================================
[2022-04-13 21:50:38.864] E012 |   200/667 batches | lr 2.5000 | loss  4.647 | ppl    104.29 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 21:50:56.826] E012 |   400/667 batches | lr 2.5000 | loss  4.623 | ppl    101.75 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 21:51:14.711] E012 |   600/667 batches | lr 2.5000 | loss  4.526 | ppl     92.41 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 21:51:20.733] E012 |   667/667 batches | lr 2.5000 | loss  4.456 | ppl     86.15 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 21:51:26.612] End E012 | valid loss  5.924; ppl    373.89 | accu 0.2238 = 25120/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 21:51:32.440] End E012 |  test loss  7.816; ppl   2480.67 | accu 0.0838 = 9670/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:51:58.802] End E012 |  test loss  8.461; ppl   4725.12 | accu 0.0308 = 15616/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:51:58.802] Epoch 013/20 ==================================================
[2022-04-13 21:52:16.555] E013 |   200/667 batches | lr 1.2500 | loss  4.615 | ppl    100.99 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 21:52:34.538] E013 |   400/667 batches | lr 1.2500 | loss  4.581 | ppl     97.60 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 21:52:52.430] E013 |   600/667 batches | lr 1.2500 | loss  4.475 | ppl     87.80 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 21:52:58.391] E013 |   667/667 batches | lr 1.2500 | loss  4.397 | ppl     81.23 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 21:53:04.324] End E013 | valid loss  5.919; ppl    372.02 | accu 0.2253 = 25278/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 21:53:10.176] End E013 |  test loss  7.854; ppl   2576.78 | accu 0.0849 = 9792/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:53:36.514] End E013 |  test loss  8.425; ppl   4558.50 | accu 0.0347 = 17568/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:53:36.514] Epoch 014/20 ==================================================
[2022-04-13 21:53:54.216] E014 |   200/667 batches | lr 0.6250 | loss  4.590 | ppl     98.51 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 21:54:12.173] E014 |   400/667 batches | lr 0.6250 | loss  4.558 | ppl     95.43 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 21:54:30.137] E014 |   600/667 batches | lr 0.6250 | loss  4.450 | ppl     85.64 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 21:54:36.193] E014 |   667/667 batches | lr 0.6250 | loss  4.375 | ppl     79.46 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 21:54:42.092] End E014 | valid loss  5.918; ppl    371.84 | accu 0.2265 = 25417/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 21:54:47.898] End E014 |  test loss  7.913; ppl   2732.91 | accu 0.0854 = 9854/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:55:14.140] End E014 |  test loss  8.440; ppl   4626.73 | accu 0.0333 = 16853/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:55:14.141] Epoch 015/20 ==================================================
[2022-04-13 21:55:31.998] E015 |   200/667 batches | lr 0.3125 | loss  4.578 | ppl     97.34 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 21:55:49.956] E015 |   400/667 batches | lr 0.3125 | loss  4.543 | ppl     93.98 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 21:56:07.910] E015 |   600/667 batches | lr 0.3125 | loss  4.437 | ppl     84.55 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 21:56:13.881] E015 |   667/667 batches | lr 0.3125 | loss  4.357 | ppl     78.04 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 21:56:19.785] End E015 | valid loss  5.920; ppl    372.33 | accu 0.2268 = 25452/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 21:56:25.627] End E015 |  test loss  7.920; ppl   2753.09 | accu 0.0851 = 9824/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:56:51.926] End E015 |  test loss  8.462; ppl   4732.51 | accu 0.0310 = 15696/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:56:51.926] Epoch 016/20 ==================================================
[2022-04-13 21:57:09.710] E016 |   200/667 batches | lr 0.1562 | loss  4.569 | ppl     96.49 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 21:57:27.600] E016 |   400/667 batches | lr 0.1562 | loss  4.541 | ppl     93.80 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 21:57:45.461] E016 |   600/667 batches | lr 0.1562 | loss  4.428 | ppl     83.74 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 21:57:51.450] E016 |   667/667 batches | lr 0.1562 | loss  4.351 | ppl     77.56 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 21:57:57.322] End E016 | valid loss  5.920; ppl    372.41 | accu 0.2272 = 25491/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 21:58:03.137] End E016 |  test loss  7.915; ppl   2736.75 | accu 0.0848 = 9784/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 21:58:29.439] End E016 |  test loss  8.480; ppl   4819.76 | accu 0.0300 = 15200/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 21:58:29.439] Epoch 017/20 ==================================================
[2022-04-13 21:58:47.204] E017 |   200/667 batches | lr 0.0781 | loss  4.567 | ppl     96.29 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 21:59:05.285] E017 |   400/667 batches | lr 0.0781 | loss  4.536 | ppl     93.29 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 21:59:23.126] E017 |   600/667 batches | lr 0.0781 | loss  4.424 | ppl     83.41 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 21:59:29.044] E017 |   667/667 batches | lr 0.0781 | loss  4.351 | ppl     77.57 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 21:59:34.951] End E017 | valid loss  5.921; ppl    372.62 | accu 0.2272 = 25497/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 21:59:40.788] End E017 |  test loss  7.918; ppl   2746.33 | accu 0.0845 = 9749/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:00:07.301] End E017 |  test loss  8.492; ppl   4876.07 | accu 0.0291 = 14732/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 22:00:07.301] Epoch 018/20 ==================================================
[2022-04-13 22:00:24.782] E018 |   200/667 batches | lr 0.0391 | loss  4.568 | ppl     96.33 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 22:00:42.805] E018 |   400/667 batches | lr 0.0391 | loss  4.536 | ppl     93.29 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 22:01:00.389] E018 |   600/667 batches | lr 0.0391 | loss  4.427 | ppl     83.65 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 22:01:06.238] E018 |   667/667 batches | lr 0.0391 | loss  4.348 | ppl     77.29 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 22:01:12.180] End E018 | valid loss  5.922; ppl    373.02 | accu 0.2273 = 25513/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 22:01:18.031] End E018 |  test loss  7.923; ppl   2761.23 | accu 0.0846 = 9760/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:01:44.449] End E018 |  test loss  8.495; ppl   4887.91 | accu 0.0290 = 14720/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 22:01:44.449] Epoch 019/20 ==================================================
[2022-04-13 22:02:02.285] E019 |   200/667 batches | lr 0.0195 | loss  4.561 | ppl     95.71 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 22:02:20.231] E019 |   400/667 batches | lr 0.0195 | loss  4.535 | ppl     93.19 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 22:02:38.011] E019 |   600/667 batches | lr 0.0195 | loss  4.422 | ppl     83.27 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 22:02:44.027] E019 |   667/667 batches | lr 0.0195 | loss  4.347 | ppl     77.27 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 22:02:49.937] End E019 | valid loss  5.922; ppl    373.25 | accu 0.2273 = 25509/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 22:02:55.745] End E019 |  test loss  7.927; ppl   2771.33 | accu 0.0845 = 9745/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:03:21.958] End E019 |  test loss  8.498; ppl   4903.03 | accu 0.0289 = 14623/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 22:03:21.958] Epoch 020/20 ==================================================
[2022-04-13 22:03:39.444] E020 |   200/667 batches | lr 0.0098 | loss  4.567 | ppl     96.25 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 22:03:57.505] E020 |   400/667 batches | lr 0.0098 | loss  4.532 | ppl     92.95 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 22:04:15.526] E020 |   600/667 batches | lr 0.0098 | loss  4.420 | ppl     83.12 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 22:04:21.490] E020 |   667/667 batches | lr 0.0098 | loss  4.347 | ppl     77.26 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 22:04:27.468] End E020 | valid loss  5.923; ppl    373.42 | accu 0.2273 = 25505/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 22:04:33.324] End E020 |  test loss  7.930; ppl   2780.28 | accu 0.0843 = 9732/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:04:59.580] End E020 |  test loss  8.501; ppl   4917.64 | accu 0.0286 = 14508/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 22:05:05.554] End. test loss  7.89; ppl  2663.99 | accu 0.0826 = 9535/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:05:31.851] End. test loss  8.48; ppl  4808.30 | accu 0.0280 = 14198/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 22:05:31.851] =========================================================================================
[2022-04-13 22:05:31.852] valid_loss
[2022-04-13 22:05:31.852]  6.64, 6.19, 6.08, 6.02, 5.98, 6.00, 5.93, 5.94, 5.92, 5.92, 5.92, 5.92, 5.92, 5.92, 5.92, 5.92, 5.92, 5.92, 5.92, 5.92
[2022-04-13 22:05:31.852] valid_loss ppl
[2022-04-13 22:05:31.852]   768.10,  490.00,  438.45,  413.16,  393.94,  405.38,  377.48,  379.57,  373.98,  374.08,  371.20,  373.89,  372.02,  371.84,  372.33,  372.41,  372.62,  373.02,  373.25,  373.42
[2022-04-13 22:05:31.852] test_loss of ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:05:31.852]  7.50, 8.08, 7.91, 7.74, 8.10, 8.06, 7.84, 7.82, 7.85, 7.96, 7.89, 7.82, 7.85, 7.91, 7.92, 7.91, 7.92, 7.92, 7.93, 7.93
[2022-04-13 22:05:31.852] test_loss of ../data/sample_500k/cbt_valid.txt ppl
[2022-04-13 22:05:31.852]  1800.95, 3225.34, 2716.18, 2301.99, 3282.12, 3174.99, 2546.89, 2490.71, 2572.93, 2864.51, 2663.99, 2480.67, 2576.78, 2732.91, 2753.09, 2736.75, 2746.33, 2761.23, 2771.33, 2780.28
[2022-04-13 22:05:31.852] test_loss of ../data/sample_500k/adult_test.txt
[2022-04-13 22:05:31.852]  8.65, 9.85, 9.68, 9.19, 9.65, 9.49, 8.81, 8.46, 8.35, 8.53, 8.48, 8.46, 8.42, 8.44, 8.46, 8.48, 8.49, 8.49, 8.50, 8.50
[2022-04-13 22:05:31.852] test_loss of ../data/sample_500k/adult_test.txt ppl
[2022-04-13 22:05:31.852]  5723.69,19036.25,15950.57, 9758.62,15550.77,13229.08, 6684.81, 4726.80, 4248.27, 5067.73, 4808.30, 4725.12, 4558.50, 4626.73, 4732.51, 4819.76, 4876.07, 4887.91, 4903.03, 4917.64
[2022-04-13 22:05:31.852] 
[2022-04-13 22:05:31.852] 
[2022-04-13 22:05:31.852] 
Log file: ./output_wsm_Subword.5000_fam_CNN.log closed.
Log file: ./output_wsm_Subword.5000_fam_LSTM.log open...
[2022-04-13 22:05:31.864] corpus.train_file_list: 1
[2022-04-13 22:05:31.864]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 22:05:31.864] corpus.valid_file_list: 1
[2022-04-13 22:05:31.864]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 22:05:31.864] corpus.test_file_list: 2
[2022-04-13 22:05:31.864]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:05:31.864]         ../data/sample_500k/adult_test.txt
[2022-04-13 22:05:31.864] corpus.subword_vocab_size: 0
[2022-04-13 22:05:31.864] corpus.subword_model = None. Corpus will not use subword.
[2022-04-13 22:05:31.864] corpus tokenize...
[2022-04-13 22:05:32.942]         train tokens: 467267  ../data/sample_500k/adolescent_train.txt
[2022-04-13 22:05:33.180]         valid tokens: 112256  ../data/sample_500k/adolescent_valid.txt
[2022-04-13 22:05:33.317]         test  tokens: 115417  ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:05:33.951]         test  tokens: 506878  ../data/sample_500k/adult_test.txt
[2022-04-13 22:05:33.951] corpus.ntokens      : 95521
[2022-04-13 22:05:33.951] corpus.char_count   : 166
[2022-04-13 22:05:33.951] corpus.char_cnt_dict: 166
[2022-04-13 22:05:33.951] corpus.char_id_dict : 166
[2022-04-13 22:05:33.959] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 22:05:33.959]         tokens_all: 467267
[2022-04-13 22:05:33.959]         batched   :  23363
[2022-04-13 22:05:33.959]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 22:05:33.963] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 22:05:33.963]         tokens_all: 112256
[2022-04-13 22:05:33.963]         batched   :   5612
[2022-04-13 22:05:33.963]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 22:05:33.968] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 22:05:33.968]         tokens_all: 115417
[2022-04-13 22:05:33.968]         batched   :   5770
[2022-04-13 22:05:33.968]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:05:33.976] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 22:05:33.976]         tokens_all: 506878
[2022-04-13 22:05:33.977]         batched   :  25343
[2022-04-13 22:05:33.977]         ../data/sample_500k/adult_test.txt
[2022-04-13 22:05:33.977] subword_adapter will be generated due to word_split_mode='Subword.5000'
[2022-04-13 22:05:33.978] SubwordAdapter.file_list: 2
[2022-04-13 22:05:33.978]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 22:05:33.978]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 22:05:33.978] SubwordAdapter.subword_vocab_size: 5000
[2022-04-13 22:05:33.978] SubwordAdapter.subword_model.train(2 files)...
[2022-04-13 22:05:34.897] SubwordAdapter.subword_model.train(2 files)...Done
[2022-04-13 22:05:35.585] RNNModel.rnn_type: LSTM
[2022-04-13 22:05:35.586] RNNModel.ntoken  : 95521
[2022-04-13 22:05:35.586] RNNModel.ninp    : 200
[2022-04-13 22:05:35.586] RNNModel.nhid    : 200
[2022-04-13 22:05:35.586] RNNModel.nlayers : 2
[2022-04-13 22:05:35.586] RNNModel.dropout : 0.2
[2022-04-13 22:05:35.586] RNNModel.tie_weights: False
[2022-04-13 22:05:35.586] RNNModel.fragment_aggregate_mode: LSTM
[2022-04-13 22:05:35.586] RNNModel.fragment_cnt           : 5002
[2022-04-13 22:05:35.586] RNNModel.fragment_emsize        : 25
[2022-04-13 22:05:35.586] RNNModel.fragment_nhid          : 200
[2022-04-13 22:05:35.588] RNNModel.fragment_embeds     : created
[2022-04-13 22:05:35.592] RNNModel.fragment_lstm       : created
[2022-04-13 22:05:35.592] RNNModel.fragment_lstm_linear: created
[2022-04-13 22:05:35.634] Epoch 001/20 ==================================================
[2022-04-13 22:06:38.046] E001 |   200/667 batches | lr 20.0000 | loss  8.534 | ppl   5083.27 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 22:07:38.404] E001 |   400/667 batches | lr 20.0000 | loss  7.751 | ppl   2324.75 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 22:08:39.897] E001 |   600/667 batches | lr 20.0000 | loss  7.178 | ppl   1310.26 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 22:09:01.321] E001 |   667/667 batches | lr 20.0000 | loss  6.867 | ppl    959.86 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 22:09:15.812] End E001 | valid loss  6.755; ppl    858.71 | accu 0.1753 = 19670/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 22:09:30.243] End E001 |  test loss  7.863; ppl   2599.77 | accu 0.0640 = 7385/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:10:35.563] End E001 |  test loss  9.188; ppl   9781.06 | accu 0.0088 = 4469/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 22:10:35.564] Save: model.pt... 
[2022-04-13 22:10:36.161] Save: model.pt...Done. best_val_loss: 6.7554
[2022-04-13 22:10:36.162] Epoch 002/20 ==================================================
[2022-04-13 22:11:36.099] E002 |   200/667 batches | lr 20.0000 | loss  6.659 | ppl    779.50 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 22:12:38.414] E002 |   400/667 batches | lr 20.0000 | loss  6.486 | ppl    655.76 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 22:13:39.643] E002 |   600/667 batches | lr 20.0000 | loss  6.262 | ppl    524.48 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 22:13:59.815] E002 |   667/667 batches | lr 20.0000 | loss  6.135 | ppl    461.90 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 22:14:14.041] End E002 | valid loss  6.254; ppl    520.32 | accu 0.1876 = 21056/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 22:14:28.513] End E002 |  test loss  7.495; ppl   1798.14 | accu 0.0802 = 9253/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:15:32.812] End E002 |  test loss  9.216; ppl  10060.92 | accu 0.0101 = 5094/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 22:15:32.813] Save: model.pt... 
[2022-04-13 22:15:33.401] Save: model.pt...Done. best_val_loss: 6.2544
[2022-04-13 22:15:33.402] Epoch 003/20 ==================================================
[2022-04-13 22:16:33.696] E003 |   200/667 batches | lr 20.0000 | loss  6.082 | ppl    438.03 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 22:17:34.775] E003 |   400/667 batches | lr 20.0000 | loss  6.023 | ppl    412.99 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 22:18:39.037] E003 |   600/667 batches | lr 20.0000 | loss  5.877 | ppl    356.91 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 22:19:00.533] E003 |   667/667 batches | lr 20.0000 | loss  5.786 | ppl    325.82 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 22:19:14.940] End E003 | valid loss  6.081; ppl    437.30 | accu 0.2052 = 23028/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 22:19:29.675] End E003 |  test loss  7.833; ppl   2523.17 | accu 0.0723 = 8337/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:20:33.984] End E003 |  test loss  9.087; ppl   8835.86 | accu 0.0099 = 5019/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 22:20:33.984] Save: model.pt... 
[2022-04-13 22:20:34.582] Save: model.pt...Done. best_val_loss: 6.0806
[2022-04-13 22:20:34.582] Epoch 004/20 ==================================================
[2022-04-13 22:21:35.407] E004 |   200/667 batches | lr 20.0000 | loss  5.748 | ppl    313.59 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 22:22:38.701] E004 |   400/667 batches | lr 20.0000 | loss  5.727 | ppl    307.00 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 22:23:40.462] E004 |   600/667 batches | lr 20.0000 | loss  5.613 | ppl    273.97 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 22:24:01.223] E004 |   667/667 batches | lr 20.0000 | loss  5.540 | ppl    254.78 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 22:24:15.763] End E004 | valid loss  6.061; ppl    428.80 | accu 0.2084 = 23392/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 22:24:30.527] End E004 |  test loss  7.824; ppl   2500.21 | accu 0.0734 = 8468/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:25:34.626] End E004 |  test loss  9.334; ppl  11318.95 | accu 0.0107 = 5412/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 22:25:34.627] Save: model.pt... 
[2022-04-13 22:25:35.230] Save: model.pt...Done. best_val_loss: 6.0610
[2022-04-13 22:25:35.230] Epoch 005/20 ==================================================
[2022-04-13 22:26:34.889] E005 |   200/667 batches | lr 20.0000 | loss  5.514 | ppl    248.18 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 22:27:38.130] E005 |   400/667 batches | lr 20.0000 | loss  5.526 | ppl    251.15 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 22:28:40.907] E005 |   600/667 batches | lr 20.0000 | loss  5.415 | ppl    224.66 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 22:29:01.609] E005 |   667/667 batches | lr 20.0000 | loss  5.344 | ppl    209.25 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 22:29:16.150] End E005 | valid loss  6.054; ppl    425.84 | accu 0.2011 = 22571/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 22:29:30.701] End E005 |  test loss  7.325; ppl   1518.06 | accu 0.0777 = 8968/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:30:35.018] End E005 |  test loss  8.824; ppl   6798.75 | accu 0.0166 = 8434/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 22:30:35.019] Save: model.pt... 
[2022-04-13 22:30:35.609] Save: model.pt...Done. best_val_loss: 6.0541
[2022-04-13 22:30:35.609] Epoch 006/20 ==================================================
[2022-04-13 22:31:37.901] E006 |   200/667 batches | lr 20.0000 | loss  5.326 | ppl    205.62 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 22:32:41.520] E006 |   400/667 batches | lr 20.0000 | loss  5.331 | ppl    206.75 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 22:33:44.317] E006 |   600/667 batches | lr 20.0000 | loss  5.238 | ppl    188.25 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 22:34:05.286] E006 |   667/667 batches | lr 20.0000 | loss  5.174 | ppl    176.71 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 22:34:19.909] End E006 | valid loss  6.060; ppl    428.31 | accu 0.2056 = 23078/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 22:34:34.595] End E006 |  test loss  7.443; ppl   1707.62 | accu 0.0751 = 8660/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:35:38.944] End E006 |  test loss  8.900; ppl   7329.25 | accu 0.0108 = 5477/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 22:35:38.944] Epoch 007/20 ==================================================
[2022-04-13 22:36:40.847] E007 |   200/667 batches | lr 10.0000 | loss  5.077 | ppl    160.22 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 22:37:45.774] E007 |   400/667 batches | lr 10.0000 | loss  5.037 | ppl    153.93 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 22:38:49.431] E007 |   600/667 batches | lr 10.0000 | loss  4.922 | ppl    137.32 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 22:39:09.948] E007 |   667/667 batches | lr 10.0000 | loss  4.844 | ppl    126.96 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 22:39:24.355] End E007 | valid loss  5.983; ppl    396.57 | accu 0.2135 = 23963/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 22:39:38.898] End E007 |  test loss  7.413; ppl   1658.11 | accu 0.0761 = 8779/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:40:43.042] End E007 |  test loss  9.052; ppl   8538.16 | accu 0.0119 = 6009/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 22:40:43.043] Save: model.pt... 
[2022-04-13 22:40:43.650] Save: model.pt...Done. best_val_loss: 5.9829
[2022-04-13 22:40:43.650] Epoch 008/20 ==================================================
[2022-04-13 22:41:45.232] E008 |   200/667 batches | lr 10.0000 | loss  4.924 | ppl    137.49 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 22:42:47.425] E008 |   400/667 batches | lr 10.0000 | loss  4.913 | ppl    136.06 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 22:43:50.654] E008 |   600/667 batches | lr 10.0000 | loss  4.821 | ppl    124.08 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 22:44:11.670] E008 |   667/667 batches | lr 10.0000 | loss  4.754 | ppl    116.09 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 22:44:26.234] End E008 | valid loss  5.998; ppl    402.63 | accu 0.2143 = 24049/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 22:44:40.614] End E008 |  test loss  7.435; ppl   1693.48 | accu 0.0786 = 9065/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:45:44.818] End E008 |  test loss  9.129; ppl   9219.52 | accu 0.0147 = 7456/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 22:45:44.818] Epoch 009/20 ==================================================
[2022-04-13 22:46:47.742] E009 |   200/667 batches | lr 5.0000 | loss  4.799 | ppl    121.42 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 22:47:51.129] E009 |   400/667 batches | lr 5.0000 | loss  4.760 | ppl    116.70 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 22:48:54.298] E009 |   600/667 batches | lr 5.0000 | loss  4.647 | ppl    104.23 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 22:49:14.878] E009 |   667/667 batches | lr 5.0000 | loss  4.564 | ppl     96.01 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 22:49:29.579] End E009 | valid loss  5.963; ppl    388.94 | accu 0.2193 = 24607/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 22:49:43.989] End E009 |  test loss  7.313; ppl   1500.18 | accu 0.0824 = 9512/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:50:48.368] End E009 |  test loss  9.030; ppl   8353.37 | accu 0.0144 = 7276/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 22:50:48.368] Save: model.pt... 
[2022-04-13 22:50:48.996] Save: model.pt...Done. best_val_loss: 5.9634
[2022-04-13 22:50:48.996] Epoch 010/20 ==================================================
[2022-04-13 22:51:49.954] E010 |   200/667 batches | lr 5.0000 | loss  4.712 | ppl    111.29 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 22:52:51.384] E010 |   400/667 batches | lr 5.0000 | loss  4.694 | ppl    109.29 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 22:53:54.114] E010 |   600/667 batches | lr 5.0000 | loss  4.594 | ppl     98.90 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 22:54:14.789] E010 |   667/667 batches | lr 5.0000 | loss  4.522 | ppl     92.01 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 22:54:29.341] End E010 | valid loss  5.987; ppl    398.03 | accu 0.2181 = 24470/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 22:54:43.917] End E010 |  test loss  7.333; ppl   1529.35 | accu 0.0840 = 9697/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 22:55:49.051] End E010 |  test loss  9.161; ppl   9514.98 | accu 0.0168 = 8502/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 22:55:49.051] Epoch 011/20 ==================================================
[2022-04-13 22:56:51.319] E011 |   200/667 batches | lr 2.5000 | loss  4.647 | ppl    104.23 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 22:57:54.560] E011 |   400/667 batches | lr 2.5000 | loss  4.611 | ppl    100.58 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 22:58:57.531] E011 |   600/667 batches | lr 2.5000 | loss  4.500 | ppl     89.98 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 22:59:18.638] E011 |   667/667 batches | lr 2.5000 | loss  4.428 | ppl     83.80 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 22:59:33.526] End E011 | valid loss  5.974; ppl    393.17 | accu 0.2198 = 24662/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 22:59:48.426] End E011 |  test loss  7.210; ppl   1352.52 | accu 0.0878 = 10130/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:00:53.090] End E011 |  test loss  8.975; ppl   7899.13 | accu 0.0194 = 9826/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 23:00:53.090] Epoch 012/20 ==================================================
[2022-04-13 23:01:52.703] E012 |   200/667 batches | lr 1.2500 | loss  4.606 | ppl    100.04 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 23:02:53.768] E012 |   400/667 batches | lr 1.2500 | loss  4.569 | ppl     96.44 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 23:03:55.694] E012 |   600/667 batches | lr 1.2500 | loss  4.450 | ppl     85.59 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 23:04:16.578] E012 |   667/667 batches | lr 1.2500 | loss  4.373 | ppl     79.29 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 23:04:31.244] End E012 | valid loss  5.973; ppl    392.78 | accu 0.2213 = 24838/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 23:04:45.884] End E012 |  test loss  7.204; ppl   1345.01 | accu 0.0872 = 10061/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:05:52.063] End E012 |  test loss  9.040; ppl   8435.63 | accu 0.0173 = 8755/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 23:05:52.063] Epoch 013/20 ==================================================
[2022-04-13 23:06:51.631] E013 |   200/667 batches | lr 0.6250 | loss  4.580 | ppl     97.51 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 23:07:52.570] E013 |   400/667 batches | lr 0.6250 | loss  4.545 | ppl     94.14 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 23:08:54.345] E013 |   600/667 batches | lr 0.6250 | loss  4.428 | ppl     83.79 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 23:09:14.771] E013 |   667/667 batches | lr 0.6250 | loss  4.346 | ppl     77.20 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 23:09:29.544] End E013 | valid loss  5.976; ppl    393.90 | accu 0.2227 = 24997/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 23:09:44.308] End E013 |  test loss  7.196; ppl   1334.24 | accu 0.0884 = 10204/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:10:49.424] End E013 |  test loss  9.059; ppl   8598.90 | accu 0.0179 = 9058/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 23:10:49.425] Epoch 014/20 ==================================================
[2022-04-13 23:11:50.321] E014 |   200/667 batches | lr 0.3125 | loss  4.569 | ppl     96.49 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 23:12:52.016] E014 |   400/667 batches | lr 0.3125 | loss  4.530 | ppl     92.79 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 23:13:52.729] E014 |   600/667 batches | lr 0.3125 | loss  4.416 | ppl     82.80 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 23:14:13.206] E014 |   667/667 batches | lr 0.3125 | loss  4.328 | ppl     75.81 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 23:14:27.799] End E014 | valid loss  5.975; ppl    393.48 | accu 0.2228 = 25008/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 23:14:42.571] End E014 |  test loss  7.198; ppl   1336.89 | accu 0.0873 = 10078/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:15:48.174] End E014 |  test loss  9.052; ppl   8533.70 | accu 0.0178 = 9045/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 23:15:48.174] Epoch 015/20 ==================================================
[2022-04-13 23:16:47.297] E015 |   200/667 batches | lr 0.1562 | loss  4.562 | ppl     95.73 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 23:17:47.503] E015 |   400/667 batches | lr 0.1562 | loss  4.524 | ppl     92.25 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 23:18:49.210] E015 |   600/667 batches | lr 0.1562 | loss  4.409 | ppl     82.21 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 23:19:09.513] E015 |   667/667 batches | lr 0.1562 | loss  4.326 | ppl     75.61 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 23:19:23.861] End E015 | valid loss  5.975; ppl    393.44 | accu 0.2229 = 25011/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 23:19:38.224] End E015 |  test loss  7.185; ppl   1320.04 | accu 0.0875 = 10099/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:20:43.729] End E015 |  test loss  9.032; ppl   8365.53 | accu 0.0181 = 9159/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 23:20:43.729] Epoch 016/20 ==================================================
[2022-04-13 23:21:45.342] E016 |   200/667 batches | lr 0.0781 | loss  4.559 | ppl     95.47 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 23:22:46.788] E016 |   400/667 batches | lr 0.0781 | loss  4.522 | ppl     92.06 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 23:23:47.659] E016 |   600/667 batches | lr 0.0781 | loss  4.403 | ppl     81.66 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 23:24:08.072] E016 |   667/667 batches | lr 0.0781 | loss  4.322 | ppl     75.33 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 23:24:22.840] End E016 | valid loss  5.975; ppl    393.44 | accu 0.2231 = 25038/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 23:24:37.406] End E016 |  test loss  7.193; ppl   1330.27 | accu 0.0871 = 10052/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:25:41.510] End E016 |  test loss  9.051; ppl   8527.83 | accu 0.0178 = 9016/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 23:25:41.510] Epoch 017/20 ==================================================
[2022-04-13 23:26:42.644] E017 |   200/667 batches | lr 0.0391 | loss  4.555 | ppl     95.10 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 23:27:44.222] E017 |   400/667 batches | lr 0.0391 | loss  4.521 | ppl     91.96 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 23:28:46.249] E017 |   600/667 batches | lr 0.0391 | loss  4.400 | ppl     81.47 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 23:29:06.802] E017 |   667/667 batches | lr 0.0391 | loss  4.321 | ppl     75.23 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 23:29:21.587] End E017 | valid loss  5.976; ppl    393.85 | accu 0.2230 = 25030/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 23:29:36.528] End E017 |  test loss  7.194; ppl   1331.77 | accu 0.0869 = 10025/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:30:41.708] End E017 |  test loss  9.056; ppl   8569.08 | accu 0.0176 = 8945/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 23:30:41.708] Epoch 018/20 ==================================================
[2022-04-13 23:31:42.414] E018 |   200/667 batches | lr 0.0195 | loss  4.555 | ppl     95.14 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 23:32:43.629] E018 |   400/667 batches | lr 0.0195 | loss  4.519 | ppl     91.75 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 23:33:45.527] E018 |   600/667 batches | lr 0.0195 | loss  4.401 | ppl     81.52 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 23:34:06.014] E018 |   667/667 batches | lr 0.0195 | loss  4.318 | ppl     75.04 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 23:34:20.219] End E018 | valid loss  5.977; ppl    394.19 | accu 0.2232 = 25044/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 23:34:34.720] End E018 |  test loss  7.199; ppl   1337.70 | accu 0.0866 = 9992/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:35:39.666] End E018 |  test loss  9.064; ppl   8641.20 | accu 0.0175 = 8868/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 23:35:39.666] Epoch 019/20 ==================================================
[2022-04-13 23:36:39.814] E019 |   200/667 batches | lr 0.0098 | loss  4.553 | ppl     94.94 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 23:37:41.371] E019 |   400/667 batches | lr 0.0098 | loss  4.516 | ppl     91.49 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 23:38:42.788] E019 |   600/667 batches | lr 0.0098 | loss  4.400 | ppl     81.42 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 23:39:03.164] E019 |   667/667 batches | lr 0.0098 | loss  4.322 | ppl     75.34 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 23:39:18.106] End E019 | valid loss  5.977; ppl    394.32 | accu 0.2232 = 25050/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 23:39:32.471] End E019 |  test loss  7.199; ppl   1338.56 | accu 0.0866 = 9987/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:40:36.624] End E019 |  test loss  9.064; ppl   8638.45 | accu 0.0175 = 8880/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 23:40:36.625] Epoch 020/20 ==================================================
[2022-04-13 23:41:38.657] E020 |   200/667 batches | lr 0.0049 | loss  4.550 | ppl     94.65 frag_cnt/word_cnt=1.798=251773/140000
[2022-04-13 23:42:40.376] E020 |   400/667 batches | lr 0.0049 | loss  4.517 | ppl     91.53 frag_cnt/word_cnt=1.823=255238/140000
[2022-04-13 23:43:42.018] E020 |   600/667 batches | lr 0.0049 | loss  4.399 | ppl     81.38 frag_cnt/word_cnt=1.815=254110/140000
[2022-04-13 23:44:02.654] E020 |   667/667 batches | lr 0.0049 | loss  4.322 | ppl     75.31 frag_cnt/word_cnt=1.821=85386/46900
[2022-04-13 23:44:17.393] End E020 | valid loss  5.977; ppl    394.30 | accu 0.2232 = 25048/112220 | w_len 1.7601 = 197513/112220
[2022-04-13 23:44:32.133] End E020 |  test loss  7.200; ppl   1338.78 | accu 0.0866 = 9989/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:45:37.385] End E020 |  test loss  9.064; ppl   8639.77 | accu 0.0175 = 8877/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 23:45:52.233] End. test loss  7.31; ppl  1500.18 | accu 0.0824 = 9512/115380 | w_len 1.3025 = 150286/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:46:59.591] End. test loss  9.03; ppl  8353.37 | accu 0.0144 = 7276/506840 | w_len 1.6811 = 852047/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 23:46:59.591] =========================================================================================
[2022-04-13 23:46:59.591] valid_loss
[2022-04-13 23:46:59.591]  6.76, 6.25, 6.08, 6.06, 6.05, 6.06, 5.98, 6.00, 5.96, 5.99, 5.97, 5.97, 5.98, 5.98, 5.97, 5.97, 5.98, 5.98, 5.98, 5.98
[2022-04-13 23:46:59.592] valid_loss ppl
[2022-04-13 23:46:59.592]   858.71,  520.32,  437.30,  428.80,  425.84,  428.31,  396.57,  402.63,  388.94,  398.03,  393.17,  392.78,  393.90,  393.48,  393.44,  393.44,  393.85,  394.19,  394.32,  394.30
[2022-04-13 23:46:59.592] test_loss of ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:46:59.592]  7.86, 7.49, 7.83, 7.82, 7.33, 7.44, 7.41, 7.43, 7.31, 7.33, 7.21, 7.20, 7.20, 7.20, 7.19, 7.19, 7.19, 7.20, 7.20, 7.20
[2022-04-13 23:46:59.592] test_loss of ../data/sample_500k/cbt_valid.txt ppl
[2022-04-13 23:46:59.592]  2599.77, 1798.14, 2523.17, 2500.21, 1518.06, 1707.62, 1658.11, 1693.48, 1500.18, 1529.35, 1352.52, 1345.01, 1334.24, 1336.89, 1320.04, 1330.27, 1331.77, 1337.70, 1338.56, 1338.78
[2022-04-13 23:46:59.592] test_loss of ../data/sample_500k/adult_test.txt
[2022-04-13 23:46:59.592]  9.19, 9.22, 9.09, 9.33, 8.82, 8.90, 9.05, 9.13, 9.03, 9.16, 8.97, 9.04, 9.06, 9.05, 9.03, 9.05, 9.06, 9.06, 9.06, 9.06
[2022-04-13 23:46:59.593] test_loss of ../data/sample_500k/adult_test.txt ppl
[2022-04-13 23:46:59.593]  9781.06,10060.92, 8835.86,11318.95, 6798.75, 7329.25, 8538.16, 9219.52, 8353.37, 9514.98, 7899.13, 8435.63, 8598.90, 8533.70, 8365.53, 8527.83, 8569.08, 8641.20, 8638.45, 8639.77
[2022-04-13 23:46:59.593] 
[2022-04-13 23:46:59.593] 
[2022-04-13 23:46:59.593] 
Log file: ./output_wsm_Subword.5000_fam_LSTM.log closed.
Log file: ./output_wsm_Subword.10000_fam_CNN.log open...
[2022-04-13 23:46:59.609] corpus.train_file_list: 1
[2022-04-13 23:46:59.610]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 23:46:59.610] corpus.valid_file_list: 1
[2022-04-13 23:46:59.610]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 23:46:59.610] corpus.test_file_list: 2
[2022-04-13 23:46:59.610]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:46:59.610]         ../data/sample_500k/adult_test.txt
[2022-04-13 23:46:59.610] corpus.subword_vocab_size: 0
[2022-04-13 23:46:59.610] corpus.subword_model = None. Corpus will not use subword.
[2022-04-13 23:46:59.610] corpus tokenize...
[2022-04-13 23:47:00.804]         train tokens: 467267  ../data/sample_500k/adolescent_train.txt
[2022-04-13 23:47:01.054]         valid tokens: 112256  ../data/sample_500k/adolescent_valid.txt
[2022-04-13 23:47:01.205]         test  tokens: 115417  ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:47:01.845]         test  tokens: 506878  ../data/sample_500k/adult_test.txt
[2022-04-13 23:47:01.845] corpus.ntokens      : 95521
[2022-04-13 23:47:01.846] corpus.char_count   : 166
[2022-04-13 23:47:01.846] corpus.char_cnt_dict: 166
[2022-04-13 23:47:01.846] corpus.char_id_dict : 166
[2022-04-13 23:47:01.851] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 23:47:01.851]         tokens_all: 467267
[2022-04-13 23:47:01.851]         batched   :  23363
[2022-04-13 23:47:01.851]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 23:47:01.853] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 23:47:01.853]         tokens_all: 112256
[2022-04-13 23:47:01.853]         batched   :   5612
[2022-04-13 23:47:01.853]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 23:47:01.855] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 23:47:01.855]         tokens_all: 115417
[2022-04-13 23:47:01.855]         batched   :   5770
[2022-04-13 23:47:01.855]         ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:47:01.861] corpus.batchify(1 files, batch_size=20)...
[2022-04-13 23:47:01.861]         tokens_all: 506878
[2022-04-13 23:47:01.861]         batched   :  25343
[2022-04-13 23:47:01.861]         ../data/sample_500k/adult_test.txt
[2022-04-13 23:47:01.862] subword_adapter will be generated due to word_split_mode='Subword.10000'
[2022-04-13 23:47:01.862] SubwordAdapter.file_list: 2
[2022-04-13 23:47:01.862]         ../data/sample_500k/adolescent_train.txt
[2022-04-13 23:47:01.862]         ../data/sample_500k/adolescent_valid.txt
[2022-04-13 23:47:01.862] SubwordAdapter.subword_vocab_size: 10000
[2022-04-13 23:47:01.862] SubwordAdapter.subword_model.train(2 files)...
[2022-04-13 23:47:03.145] SubwordAdapter.subword_model.train(2 files)...Done
[2022-04-13 23:47:03.819] RNNModel.rnn_type: LSTM
[2022-04-13 23:47:03.820] RNNModel.ntoken  : 95521
[2022-04-13 23:47:03.820] RNNModel.ninp    : 200
[2022-04-13 23:47:03.820] RNNModel.nhid    : 200
[2022-04-13 23:47:03.820] RNNModel.nlayers : 2
[2022-04-13 23:47:03.820] RNNModel.dropout : 0.2
[2022-04-13 23:47:03.820] RNNModel.tie_weights: False
[2022-04-13 23:47:03.820] RNNModel.fragment_aggregate_mode: CNN
[2022-04-13 23:47:03.820] RNNModel.fragment_cnt           : 10002
[2022-04-13 23:47:03.820] RNNModel.fragment_emsize        : 25
[2022-04-13 23:47:03.820] RNNModel.fragment_nhid          : 200
[2022-04-13 23:47:03.825] RNNModel.fragment_embeds     : created
[2022-04-13 23:47:03.825] RNNModel.fragment_cnn3       : created
[2022-04-13 23:47:03.872] Epoch 001/20 ==================================================
[2022-04-13 23:47:21.874] E001 |   200/667 batches | lr 20.0000 | loss  8.552 | ppl   5177.79 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-13 23:47:39.704] E001 |   400/667 batches | lr 20.0000 | loss  7.647 | ppl   2095.23 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-13 23:47:57.514] E001 |   600/667 batches | lr 20.0000 | loss  7.129 | ppl   1247.57 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-13 23:48:03.455] E001 |   667/667 batches | lr 20.0000 | loss  6.803 | ppl    900.27 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-13 23:48:09.369] End E001 | valid loss  6.665; ppl    784.63 | accu 0.1682 = 18876/112220 | w_len 1.6669 = 187056/112220
[2022-04-13 23:48:15.225] End E001 |  test loss  7.618; ppl   2035.27 | accu 0.0766 = 8837/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:48:41.694] End E001 |  test loss  8.807; ppl   6680.31 | accu 0.0409 = 20721/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 23:48:41.694] Save: model.pt... 
[2022-04-13 23:48:42.311] Save: model.pt...Done. best_val_loss: 6.6652
[2022-04-13 23:48:42.312] Epoch 002/20 ==================================================
[2022-04-13 23:48:59.957] E002 |   200/667 batches | lr 20.0000 | loss  6.661 | ppl    780.95 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-13 23:49:17.615] E002 |   400/667 batches | lr 20.0000 | loss  6.459 | ppl    638.55 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-13 23:49:35.359] E002 |   600/667 batches | lr 20.0000 | loss  6.241 | ppl    513.36 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-13 23:49:41.271] E002 |   667/667 batches | lr 20.0000 | loss  6.118 | ppl    454.09 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-13 23:49:47.203] End E002 | valid loss  6.240; ppl    512.82 | accu 0.1899 = 21309/112220 | w_len 1.6669 = 187056/112220
[2022-04-13 23:49:53.050] End E002 |  test loss  7.624; ppl   2046.30 | accu 0.0727 = 8387/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:50:19.479] End E002 |  test loss  9.269; ppl  10601.20 | accu 0.0092 = 4681/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 23:50:19.479] Save: model.pt... 
[2022-04-13 23:50:20.098] Save: model.pt...Done. best_val_loss: 6.2399
[2022-04-13 23:50:20.098] Epoch 003/20 ==================================================
[2022-04-13 23:50:37.734] E003 |   200/667 batches | lr 20.0000 | loss  6.060 | ppl    428.42 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-13 23:50:55.384] E003 |   400/667 batches | lr 20.0000 | loss  6.006 | ppl    405.87 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-13 23:51:13.161] E003 |   600/667 batches | lr 20.0000 | loss  5.861 | ppl    351.01 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-13 23:51:19.161] E003 |   667/667 batches | lr 20.0000 | loss  5.774 | ppl    321.74 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-13 23:51:25.088] End E003 | valid loss  6.123; ppl    456.33 | accu 0.2020 = 22663/112220 | w_len 1.6669 = 187056/112220
[2022-04-13 23:51:30.911] End E003 |  test loss  7.982; ppl   2929.01 | accu 0.0713 = 8232/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:51:57.251] End E003 |  test loss  9.927; ppl  20476.56 | accu 0.0064 = 3222/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 23:51:57.251] Save: model.pt... 
[2022-04-13 23:51:57.865] Save: model.pt...Done. best_val_loss: 6.1232
[2022-04-13 23:51:57.865] Epoch 004/20 ==================================================
[2022-04-13 23:52:15.589] E004 |   200/667 batches | lr 20.0000 | loss  5.769 | ppl    320.08 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-13 23:52:33.441] E004 |   400/667 batches | lr 20.0000 | loss  5.739 | ppl    310.88 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-13 23:52:51.386] E004 |   600/667 batches | lr 20.0000 | loss  5.628 | ppl    277.98 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-13 23:52:57.380] E004 |   667/667 batches | lr 20.0000 | loss  5.552 | ppl    257.71 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-13 23:53:03.296] End E004 | valid loss  6.030; ppl    415.78 | accu 0.2019 = 22654/112220 | w_len 1.6669 = 187056/112220
[2022-04-13 23:53:09.182] End E004 |  test loss  8.096; ppl   3280.40 | accu 0.0658 = 7591/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:53:35.615] End E004 |  test loss  9.905; ppl  20025.26 | accu 0.0073 = 3708/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 23:53:35.616] Save: model.pt... 
[2022-04-13 23:53:36.217] Save: model.pt...Done. best_val_loss: 6.0302
[2022-04-13 23:53:36.217] Epoch 005/20 ==================================================
[2022-04-13 23:53:54.095] E005 |   200/667 batches | lr 20.0000 | loss  5.542 | ppl    255.18 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-13 23:54:12.030] E005 |   400/667 batches | lr 20.0000 | loss  5.549 | ppl    256.86 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-13 23:54:29.956] E005 |   600/667 batches | lr 20.0000 | loss  5.443 | ppl    231.21 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-13 23:54:35.994] E005 |   667/667 batches | lr 20.0000 | loss  5.374 | ppl    215.81 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-13 23:54:41.891] End E005 | valid loss  6.020; ppl    411.56 | accu 0.2017 = 22632/112220 | w_len 1.6669 = 187056/112220
[2022-04-13 23:54:47.725] End E005 |  test loss  7.821; ppl   2492.41 | accu 0.0660 = 7613/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:55:14.058] End E005 |  test loss  9.268; ppl  10598.32 | accu 0.0092 = 4678/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 23:55:14.058] Save: model.pt... 
[2022-04-13 23:55:14.651] Save: model.pt...Done. best_val_loss: 6.0200
[2022-04-13 23:55:14.651] Epoch 006/20 ==================================================
[2022-04-13 23:55:32.477] E006 |   200/667 batches | lr 20.0000 | loss  5.370 | ppl    214.96 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-13 23:55:50.418] E006 |   400/667 batches | lr 20.0000 | loss  5.386 | ppl    218.25 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-13 23:56:08.316] E006 |   600/667 batches | lr 20.0000 | loss  5.298 | ppl    199.98 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-13 23:56:14.312] E006 |   667/667 batches | lr 20.0000 | loss  5.232 | ppl    187.14 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-13 23:56:20.208] End E006 | valid loss  6.027; ppl    414.53 | accu 0.2088 = 23436/112220 | w_len 1.6669 = 187056/112220
[2022-04-13 23:56:26.013] End E006 |  test loss  8.182; ppl   3574.45 | accu 0.0706 = 8146/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:56:52.225] End E006 |  test loss  9.351; ppl  11516.06 | accu 0.0116 = 5899/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 23:56:52.225] Epoch 007/20 ==================================================
[2022-04-13 23:57:10.063] E007 |   200/667 batches | lr 10.0000 | loss  5.138 | ppl    170.44 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-13 23:57:28.040] E007 |   400/667 batches | lr 10.0000 | loss  5.108 | ppl    165.39 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-13 23:57:45.995] E007 |   600/667 batches | lr 10.0000 | loss  4.988 | ppl    146.63 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-13 23:57:51.998] E007 |   667/667 batches | lr 10.0000 | loss  4.904 | ppl    134.82 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-13 23:57:57.958] End E007 | valid loss  5.945; ppl    381.74 | accu 0.2160 = 24234/112220 | w_len 1.6669 = 187056/112220
[2022-04-13 23:58:03.804] End E007 |  test loss  8.182; ppl   3577.24 | accu 0.0728 = 8396/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-13 23:58:30.331] End E007 |  test loss  9.213; ppl  10027.22 | accu 0.0121 = 6121/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-13 23:58:30.331] Save: model.pt... 
[2022-04-13 23:58:30.930] Save: model.pt...Done. best_val_loss: 5.9447
[2022-04-13 23:58:30.930] Epoch 008/20 ==================================================
[2022-04-13 23:58:48.672] E008 |   200/667 batches | lr 10.0000 | loss  4.998 | ppl    148.09 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-13 23:59:06.588] E008 |   400/667 batches | lr 10.0000 | loss  4.993 | ppl    147.31 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-13 23:59:24.598] E008 |   600/667 batches | lr 10.0000 | loss  4.895 | ppl    133.65 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-13 23:59:30.587] E008 |   667/667 batches | lr 10.0000 | loss  4.831 | ppl    125.32 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-13 23:59:36.509] End E008 | valid loss  5.944; ppl    381.27 | accu 0.2166 = 24304/112220 | w_len 1.6669 = 187056/112220
[2022-04-13 23:59:42.339] End E008 |  test loss  8.117; ppl   3349.61 | accu 0.0730 = 8426/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:00:08.765] End E008 |  test loss  9.288; ppl  10805.48 | accu 0.0111 = 5602/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:00:08.765] Save: model.pt... 
[2022-04-14 00:00:09.373] Save: model.pt...Done. best_val_loss: 5.9435
[2022-04-14 00:00:09.374] Epoch 009/20 ==================================================
[2022-04-14 00:00:27.251] E009 |   200/667 batches | lr 10.0000 | loss  4.899 | ppl    134.11 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:00:44.806] E009 |   400/667 batches | lr 10.0000 | loss  4.899 | ppl    134.10 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:01:02.697] E009 |   600/667 batches | lr 10.0000 | loss  4.813 | ppl    123.13 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:01:08.729] E009 |   667/667 batches | lr 10.0000 | loss  4.749 | ppl    115.44 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:01:14.630] End E009 | valid loss  5.963; ppl    388.77 | accu 0.2154 = 24176/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:01:20.496] End E009 |  test loss  8.022; ppl   3047.74 | accu 0.0732 = 8451/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:01:46.839] End E009 |  test loss  8.955; ppl   7746.89 | accu 0.0152 = 7697/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:01:46.840] Epoch 010/20 ==================================================
[2022-04-14 00:02:04.645] E010 |   200/667 batches | lr 5.0000 | loss  4.786 | ppl    119.77 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:02:22.213] E010 |   400/667 batches | lr 5.0000 | loss  4.754 | ppl    116.09 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:02:40.207] E010 |   600/667 batches | lr 5.0000 | loss  4.644 | ppl    103.95 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:02:46.133] E010 |   667/667 batches | lr 5.0000 | loss  4.568 | ppl     96.30 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:02:52.048] End E010 | valid loss  5.948; ppl    382.98 | accu 0.2202 = 24715/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:02:57.895] End E010 |  test loss  8.159; ppl   3493.10 | accu 0.0736 = 8487/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:03:24.350] End E010 |  test loss  9.016; ppl   8232.55 | accu 0.0157 = 7977/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:03:24.350] Epoch 011/20 ==================================================
[2022-04-14 00:03:42.181] E011 |   200/667 batches | lr 2.5000 | loss  4.696 | ppl    109.50 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:04:00.047] E011 |   400/667 batches | lr 2.5000 | loss  4.670 | ppl    106.70 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:04:18.028] E011 |   600/667 batches | lr 2.5000 | loss  4.556 | ppl     95.19 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:04:24.032] E011 |   667/667 batches | lr 2.5000 | loss  4.471 | ppl     87.42 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:04:30.006] End E011 | valid loss  5.935; ppl    378.07 | accu 0.2233 = 25056/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:04:35.983] End E011 |  test loss  8.038; ppl   3097.42 | accu 0.0751 = 8664/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:05:02.669] End E011 |  test loss  9.048; ppl   8504.26 | accu 0.0150 = 7589/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:05:02.670] Save: model.pt... 
[2022-04-14 00:05:03.280] Save: model.pt...Done. best_val_loss: 5.9351
[2022-04-14 00:05:03.280] Epoch 012/20 ==================================================
[2022-04-14 00:05:20.838] E012 |   200/667 batches | lr 2.5000 | loss  4.651 | ppl    104.74 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:05:38.754] E012 |   400/667 batches | lr 2.5000 | loss  4.631 | ppl    102.60 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:05:56.579] E012 |   600/667 batches | lr 2.5000 | loss  4.527 | ppl     92.53 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:06:02.636] E012 |   667/667 batches | lr 2.5000 | loss  4.452 | ppl     85.76 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:06:08.557] End E012 | valid loss  5.940; ppl    379.93 | accu 0.2229 = 25011/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:06:14.367] End E012 |  test loss  8.059; ppl   3160.84 | accu 0.0760 = 8774/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:06:40.838] End E012 |  test loss  9.005; ppl   8143.64 | accu 0.0166 = 8430/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:06:40.838] Epoch 013/20 ==================================================
[2022-04-14 00:06:58.550] E013 |   200/667 batches | lr 1.2500 | loss  4.618 | ppl    101.31 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:07:16.526] E013 |   400/667 batches | lr 1.2500 | loss  4.594 | ppl     98.89 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:07:34.478] E013 |   600/667 batches | lr 1.2500 | loss  4.484 | ppl     88.59 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:07:40.519] E013 |   667/667 batches | lr 1.2500 | loss  4.399 | ppl     81.38 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:07:46.451] End E013 | valid loss  5.942; ppl    380.59 | accu 0.2243 = 25173/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:07:52.304] End E013 |  test loss  8.002; ppl   2985.46 | accu 0.0767 = 8855/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:08:18.834] End E013 |  test loss  8.832; ppl   6852.29 | accu 0.0195 = 9883/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:08:18.834] Epoch 014/20 ==================================================
[2022-04-14 00:08:36.689] E014 |   200/667 batches | lr 0.6250 | loss  4.597 | ppl     99.18 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:08:54.703] E014 |   400/667 batches | lr 0.6250 | loss  4.570 | ppl     96.54 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:09:12.711] E014 |   600/667 batches | lr 0.6250 | loss  4.457 | ppl     86.20 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:09:18.766] E014 |   667/667 batches | lr 0.6250 | loss  4.374 | ppl     79.35 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:09:24.696] End E014 | valid loss  5.942; ppl    380.68 | accu 0.2254 = 25292/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:09:30.515] End E014 |  test loss  7.989; ppl   2949.81 | accu 0.0779 = 8985/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:09:56.918] End E014 |  test loss  8.918; ppl   7463.32 | accu 0.0188 = 9516/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:09:56.918] Epoch 015/20 ==================================================
[2022-04-14 00:10:14.754] E015 |   200/667 batches | lr 0.3125 | loss  4.581 | ppl     97.65 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:10:32.722] E015 |   400/667 batches | lr 0.3125 | loss  4.558 | ppl     95.36 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:10:50.515] E015 |   600/667 batches | lr 0.3125 | loss  4.440 | ppl     84.80 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:10:56.490] E015 |   667/667 batches | lr 0.3125 | loss  4.365 | ppl     78.66 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:11:02.429] End E015 | valid loss  5.940; ppl    379.90 | accu 0.2259 = 25356/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:11:08.244] End E015 |  test loss  7.981; ppl   2924.21 | accu 0.0777 = 8969/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:11:34.592] End E015 |  test loss  8.923; ppl   7504.86 | accu 0.0191 = 9672/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:11:34.592] Epoch 016/20 ==================================================
[2022-04-14 00:11:52.411] E016 |   200/667 batches | lr 0.1562 | loss  4.576 | ppl     97.10 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:12:10.406] E016 |   400/667 batches | lr 0.1562 | loss  4.548 | ppl     94.48 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:12:28.176] E016 |   600/667 batches | lr 0.1562 | loss  4.438 | ppl     84.61 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:12:34.228] E016 |   667/667 batches | lr 0.1562 | loss  4.352 | ppl     77.62 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:12:40.204] End E016 | valid loss  5.939; ppl    379.42 | accu 0.2260 = 25359/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:12:46.025] End E016 |  test loss  7.962; ppl   2870.75 | accu 0.0777 = 8964/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:13:12.336] End E016 |  test loss  8.893; ppl   7278.77 | accu 0.0200 = 10123/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:13:12.336] Epoch 017/20 ==================================================
[2022-04-14 00:13:30.069] E017 |   200/667 batches | lr 0.0781 | loss  4.573 | ppl     96.81 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:13:48.124] E017 |   400/667 batches | lr 0.0781 | loss  4.546 | ppl     94.29 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:14:06.099] E017 |   600/667 batches | lr 0.0781 | loss  4.431 | ppl     84.04 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:14:12.149] E017 |   667/667 batches | lr 0.0781 | loss  4.354 | ppl     77.76 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:14:18.046] End E017 | valid loss  5.942; ppl    380.63 | accu 0.2259 = 25346/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:14:23.878] End E017 |  test loss  7.989; ppl   2948.29 | accu 0.0776 = 8948/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:14:50.197] End E017 |  test loss  8.928; ppl   7539.11 | accu 0.0197 = 9984/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:14:50.197] Epoch 018/20 ==================================================
[2022-04-14 00:15:07.990] E018 |   200/667 batches | lr 0.0391 | loss  4.571 | ppl     96.68 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:15:25.981] E018 |   400/667 batches | lr 0.0391 | loss  4.542 | ppl     93.91 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:15:43.931] E018 |   600/667 batches | lr 0.0391 | loss  4.428 | ppl     83.74 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:15:49.973] E018 |   667/667 batches | lr 0.0391 | loss  4.348 | ppl     77.29 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:15:55.914] End E018 | valid loss  5.942; ppl    380.62 | accu 0.2259 = 25356/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:16:01.729] End E018 |  test loss  7.990; ppl   2950.93 | accu 0.0776 = 8955/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:16:28.019] End E018 |  test loss  8.923; ppl   7505.16 | accu 0.0199 = 10069/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:16:28.019] Epoch 019/20 ==================================================
[2022-04-14 00:16:45.856] E019 |   200/667 batches | lr 0.0195 | loss  4.570 | ppl     96.52 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:17:03.751] E019 |   400/667 batches | lr 0.0195 | loss  4.544 | ppl     94.03 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:17:21.556] E019 |   600/667 batches | lr 0.0195 | loss  4.430 | ppl     83.97 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:17:27.584] E019 |   667/667 batches | lr 0.0195 | loss  4.347 | ppl     77.26 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:17:33.474] End E019 | valid loss  5.943; ppl    381.02 | accu 0.2260 = 25358/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:17:39.309] End E019 |  test loss  7.999; ppl   2978.91 | accu 0.0775 = 8947/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:18:05.731] End E019 |  test loss  8.931; ppl   7564.00 | accu 0.0198 = 10024/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:18:05.731] Epoch 020/20 ==================================================
[2022-04-14 00:18:23.581] E020 |   200/667 batches | lr 0.0098 | loss  4.568 | ppl     96.33 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:18:41.523] E020 |   400/667 batches | lr 0.0098 | loss  4.542 | ppl     93.91 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:18:59.495] E020 |   600/667 batches | lr 0.0098 | loss  4.430 | ppl     83.90 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:19:05.517] E020 |   667/667 batches | lr 0.0098 | loss  4.344 | ppl     77.03 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:19:11.405] End E020 | valid loss  5.943; ppl    381.20 | accu 0.2261 = 25373/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:19:17.208] End E020 |  test loss  8.000; ppl   2981.13 | accu 0.0775 = 8942/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:19:43.346] End E020 |  test loss  8.934; ppl   7582.72 | accu 0.0197 = 10010/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:19:49.359] End. test loss  8.04; ppl  3097.42 | accu 0.0751 = 8664/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:20:15.586] End. test loss  9.05; ppl  8504.26 | accu 0.0150 = 7589/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:20:15.586] =========================================================================================
[2022-04-14 00:20:15.586] valid_loss
[2022-04-14 00:20:15.586]  6.67, 6.24, 6.12, 6.03, 6.02, 6.03, 5.94, 5.94, 5.96, 5.95, 5.94, 5.94, 5.94, 5.94, 5.94, 5.94, 5.94, 5.94, 5.94, 5.94
[2022-04-14 00:20:15.586] valid_loss ppl
[2022-04-14 00:20:15.587]   784.63,  512.82,  456.33,  415.78,  411.56,  414.53,  381.74,  381.27,  388.77,  382.98,  378.07,  379.93,  380.59,  380.68,  379.90,  379.42,  380.63,  380.62,  381.02,  381.20
[2022-04-14 00:20:15.587] test_loss of ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:20:15.587]  7.62, 7.62, 7.98, 8.10, 7.82, 8.18, 8.18, 8.12, 8.02, 8.16, 8.04, 8.06, 8.00, 7.99, 7.98, 7.96, 7.99, 7.99, 8.00, 8.00
[2022-04-14 00:20:15.587] test_loss of ../data/sample_500k/cbt_valid.txt ppl
[2022-04-14 00:20:15.587]  2035.27, 2046.30, 2929.01, 3280.40, 2492.41, 3574.45, 3577.24, 3349.61, 3047.74, 3493.10, 3097.42, 3160.84, 2985.46, 2949.81, 2924.21, 2870.75, 2948.29, 2950.93, 2978.91, 2981.13
[2022-04-14 00:20:15.587] test_loss of ../data/sample_500k/adult_test.txt
[2022-04-14 00:20:15.587]  8.81, 9.27, 9.93, 9.90, 9.27, 9.35, 9.21, 9.29, 8.96, 9.02, 9.05, 9.00, 8.83, 8.92, 8.92, 8.89, 8.93, 8.92, 8.93, 8.93
[2022-04-14 00:20:15.587] test_loss of ../data/sample_500k/adult_test.txt ppl
[2022-04-14 00:20:15.587]  6680.31,10601.20,20476.56,20025.26,10598.32,11516.06,10027.22,10805.48, 7746.89, 8232.55, 8504.26, 8143.64, 6852.29, 7463.32, 7504.86, 7278.77, 7539.11, 7505.16, 7564.00, 7582.72
[2022-04-14 00:20:15.587] 
[2022-04-14 00:20:15.587] 
[2022-04-14 00:20:15.587] 
Log file: ./output_wsm_Subword.10000_fam_CNN.log closed.
Log file: ./output_wsm_Subword.10000_fam_LSTM.log open...
[2022-04-14 00:20:15.600] corpus.train_file_list: 1
[2022-04-14 00:20:15.600]         ../data/sample_500k/adolescent_train.txt
[2022-04-14 00:20:15.600] corpus.valid_file_list: 1
[2022-04-14 00:20:15.600]         ../data/sample_500k/adolescent_valid.txt
[2022-04-14 00:20:15.600] corpus.test_file_list: 2
[2022-04-14 00:20:15.600]         ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:20:15.600]         ../data/sample_500k/adult_test.txt
[2022-04-14 00:20:15.600] corpus.subword_vocab_size: 0
[2022-04-14 00:20:15.600] corpus.subword_model = None. Corpus will not use subword.
[2022-04-14 00:20:15.600] corpus tokenize...
[2022-04-14 00:20:16.648]         train tokens: 467267  ../data/sample_500k/adolescent_train.txt
[2022-04-14 00:20:16.903]         valid tokens: 112256  ../data/sample_500k/adolescent_valid.txt
[2022-04-14 00:20:17.049]         test  tokens: 115417  ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:20:17.683]         test  tokens: 506878  ../data/sample_500k/adult_test.txt
[2022-04-14 00:20:17.683] corpus.ntokens      : 95521
[2022-04-14 00:20:17.684] corpus.char_count   : 166
[2022-04-14 00:20:17.684] corpus.char_cnt_dict: 166
[2022-04-14 00:20:17.684] corpus.char_id_dict : 166
[2022-04-14 00:20:17.693] corpus.batchify(1 files, batch_size=20)...
[2022-04-14 00:20:17.693]         tokens_all: 467267
[2022-04-14 00:20:17.693]         batched   :  23363
[2022-04-14 00:20:17.693]         ../data/sample_500k/adolescent_train.txt
[2022-04-14 00:20:17.697] corpus.batchify(1 files, batch_size=20)...
[2022-04-14 00:20:17.698]         tokens_all: 112256
[2022-04-14 00:20:17.698]         batched   :   5612
[2022-04-14 00:20:17.698]         ../data/sample_500k/adolescent_valid.txt
[2022-04-14 00:20:17.702] corpus.batchify(1 files, batch_size=20)...
[2022-04-14 00:20:17.702]         tokens_all: 115417
[2022-04-14 00:20:17.702]         batched   :   5770
[2022-04-14 00:20:17.702]         ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:20:17.711] corpus.batchify(1 files, batch_size=20)...
[2022-04-14 00:20:17.711]         tokens_all: 506878
[2022-04-14 00:20:17.711]         batched   :  25343
[2022-04-14 00:20:17.711]         ../data/sample_500k/adult_test.txt
[2022-04-14 00:20:17.712] subword_adapter will be generated due to word_split_mode='Subword.10000'
[2022-04-14 00:20:17.712] SubwordAdapter.file_list: 2
[2022-04-14 00:20:17.712]         ../data/sample_500k/adolescent_train.txt
[2022-04-14 00:20:17.712]         ../data/sample_500k/adolescent_valid.txt
[2022-04-14 00:20:17.712] SubwordAdapter.subword_vocab_size: 10000
[2022-04-14 00:20:17.712] SubwordAdapter.subword_model.train(2 files)...
[2022-04-14 00:20:18.878] SubwordAdapter.subword_model.train(2 files)...Done
[2022-04-14 00:20:19.536] RNNModel.rnn_type: LSTM
[2022-04-14 00:20:19.536] RNNModel.ntoken  : 95521
[2022-04-14 00:20:19.537] RNNModel.ninp    : 200
[2022-04-14 00:20:19.537] RNNModel.nhid    : 200
[2022-04-14 00:20:19.537] RNNModel.nlayers : 2
[2022-04-14 00:20:19.537] RNNModel.dropout : 0.2
[2022-04-14 00:20:19.537] RNNModel.tie_weights: False
[2022-04-14 00:20:19.537] RNNModel.fragment_aggregate_mode: LSTM
[2022-04-14 00:20:19.537] RNNModel.fragment_cnt           : 10002
[2022-04-14 00:20:19.537] RNNModel.fragment_emsize        : 25
[2022-04-14 00:20:19.537] RNNModel.fragment_nhid          : 200
[2022-04-14 00:20:19.542] RNNModel.fragment_embeds     : created
[2022-04-14 00:20:19.545] RNNModel.fragment_lstm       : created
[2022-04-14 00:20:19.545] RNNModel.fragment_lstm_linear: created
[2022-04-14 00:20:19.589] Epoch 001/20 ==================================================
[2022-04-14 00:21:19.419] E001 |   200/667 batches | lr 20.0000 | loss  8.525 | ppl   5038.16 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:22:20.089] E001 |   400/667 batches | lr 20.0000 | loss  7.755 | ppl   2334.13 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:23:21.088] E001 |   600/667 batches | lr 20.0000 | loss  7.218 | ppl   1363.24 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:23:40.871] E001 |   667/667 batches | lr 20.0000 | loss  6.890 | ppl    982.56 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:23:54.898] End E001 | valid loss  6.761; ppl    863.80 | accu 0.1759 = 19737/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:24:09.186] End E001 |  test loss  7.880; ppl   2644.82 | accu 0.0665 = 7676/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:25:13.041] End E001 |  test loss  9.298; ppl  10916.57 | accu 0.0062 = 3134/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:25:13.041] Save: model.pt... 
[2022-04-14 00:25:13.661] Save: model.pt...Done. best_val_loss: 6.7613
[2022-04-14 00:25:13.661] Epoch 002/20 ==================================================
[2022-04-14 00:26:14.615] E002 |   200/667 batches | lr 20.0000 | loss  6.674 | ppl    791.34 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:27:17.678] E002 |   400/667 batches | lr 20.0000 | loss  6.535 | ppl    688.86 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:28:19.441] E002 |   600/667 batches | lr 20.0000 | loss  6.292 | ppl    540.21 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:28:39.841] E002 |   667/667 batches | lr 20.0000 | loss  6.156 | ppl    471.73 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:28:53.993] End E002 | valid loss  6.278; ppl    532.90 | accu 0.1938 = 21753/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:29:08.296] End E002 |  test loss  7.874; ppl   2628.63 | accu 0.0692 = 7983/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:30:11.701] End E002 |  test loss  9.701; ppl  16337.05 | accu 0.0072 = 3625/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:30:11.701] Save: model.pt... 
[2022-04-14 00:30:12.288] Save: model.pt...Done. best_val_loss: 6.2783
[2022-04-14 00:30:12.288] Epoch 003/20 ==================================================
[2022-04-14 00:31:13.213] E003 |   200/667 batches | lr 20.0000 | loss  6.112 | ppl    451.26 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:32:13.633] E003 |   400/667 batches | lr 20.0000 | loss  6.049 | ppl    423.75 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:33:13.648] E003 |   600/667 batches | lr 20.0000 | loss  5.905 | ppl    366.88 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:33:33.688] E003 |   667/667 batches | lr 20.0000 | loss  5.819 | ppl    336.51 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:33:48.125] End E003 | valid loss  6.095; ppl    443.51 | accu 0.2013 = 22589/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:34:02.390] End E003 |  test loss  7.743; ppl   2305.70 | accu 0.0762 = 8796/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:35:06.553] End E003 |  test loss  9.772; ppl  17531.71 | accu 0.0050 = 2527/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:35:06.554] Save: model.pt... 
[2022-04-14 00:35:07.138] Save: model.pt...Done. best_val_loss: 6.0947
[2022-04-14 00:35:07.138] Epoch 004/20 ==================================================
[2022-04-14 00:36:07.310] E004 |   200/667 batches | lr 20.0000 | loss  5.790 | ppl    327.15 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:37:07.531] E004 |   400/667 batches | lr 20.0000 | loss  5.772 | ppl    321.04 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:38:08.813] E004 |   600/667 batches | lr 20.0000 | loss  5.655 | ppl    285.78 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:38:29.045] E004 |   667/667 batches | lr 20.0000 | loss  5.571 | ppl    262.65 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:38:43.397] End E004 | valid loss  6.035; ppl    417.96 | accu 0.2037 = 22861/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:38:57.775] End E004 |  test loss  7.832; ppl   2520.85 | accu 0.0743 = 8570/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:40:02.043] End E004 |  test loss  9.445; ppl  12650.16 | accu 0.0047 = 2406/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:40:02.043] Save: model.pt... 
[2022-04-14 00:40:02.646] Save: model.pt...Done. best_val_loss: 6.0354
[2022-04-14 00:40:02.647] Epoch 005/20 ==================================================
[2022-04-14 00:41:01.801] E005 |   200/667 batches | lr 20.0000 | loss  5.563 | ppl    260.52 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:42:03.545] E005 |   400/667 batches | lr 20.0000 | loss  5.559 | ppl    259.55 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:43:05.478] E005 |   600/667 batches | lr 20.0000 | loss  5.452 | ppl    233.13 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:43:26.306] E005 |   667/667 batches | lr 20.0000 | loss  5.373 | ppl    215.59 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:43:40.604] End E005 | valid loss  6.011; ppl    407.78 | accu 0.2028 = 22753/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:43:55.364] End E005 |  test loss  7.913; ppl   2731.38 | accu 0.0711 = 8199/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:44:59.883] End E005 |  test loss  9.598; ppl  14731.26 | accu 0.0063 = 3168/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:44:59.883] Save: model.pt... 
[2022-04-14 00:45:00.483] Save: model.pt...Done. best_val_loss: 6.0107
[2022-04-14 00:45:00.483] Epoch 006/20 ==================================================
[2022-04-14 00:46:01.359] E006 |   200/667 batches | lr 20.0000 | loss  5.373 | ppl    215.53 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:47:02.733] E006 |   400/667 batches | lr 20.0000 | loss  5.371 | ppl    214.99 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:48:04.340] E006 |   600/667 batches | lr 20.0000 | loss  5.280 | ppl    196.34 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:48:24.674] E006 |   667/667 batches | lr 20.0000 | loss  5.209 | ppl    182.85 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:48:39.133] End E006 | valid loss  6.041; ppl    420.25 | accu 0.2015 = 22608/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:48:53.523] End E006 |  test loss  7.689; ppl   2184.52 | accu 0.0788 = 9090/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:49:58.188] End E006 |  test loss  9.183; ppl   9731.24 | accu 0.0076 = 3839/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:49:58.189] Epoch 007/20 ==================================================
[2022-04-14 00:50:58.334] E007 |   200/667 batches | lr 10.0000 | loss  5.117 | ppl    166.89 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:52:00.342] E007 |   400/667 batches | lr 10.0000 | loss  5.073 | ppl    159.64 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:53:02.785] E007 |   600/667 batches | lr 10.0000 | loss  4.959 | ppl    142.41 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:53:24.245] E007 |   667/667 batches | lr 10.0000 | loss  4.867 | ppl    129.99 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:53:39.083] End E007 | valid loss  5.959; ppl    387.12 | accu 0.2158 = 24220/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:53:53.510] End E007 |  test loss  8.248; ppl   3821.12 | accu 0.0765 = 8829/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:54:58.438] End E007 |  test loss 10.231; ppl  27759.22 | accu 0.0056 = 2855/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:54:58.439] Save: model.pt... 
[2022-04-14 00:54:59.029] Save: model.pt...Done. best_val_loss: 5.9587
[2022-04-14 00:54:59.029] Epoch 008/20 ==================================================
[2022-04-14 00:56:00.217] E008 |   200/667 batches | lr 10.0000 | loss  4.967 | ppl    143.57 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 00:57:01.587] E008 |   400/667 batches | lr 10.0000 | loss  4.951 | ppl    141.38 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 00:58:05.169] E008 |   600/667 batches | lr 10.0000 | loss  4.855 | ppl    128.35 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 00:58:26.113] E008 |   667/667 batches | lr 10.0000 | loss  4.780 | ppl    119.08 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 00:58:40.729] End E008 | valid loss  5.961; ppl    387.85 | accu 0.2151 = 24137/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 00:58:55.174] End E008 |  test loss  8.274; ppl   3921.10 | accu 0.0783 = 9029/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 00:59:59.354] End E008 |  test loss 10.278; ppl  29095.97 | accu 0.0058 = 2962/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 00:59:59.354] Epoch 009/20 ==================================================
[2022-04-14 01:01:01.367] E009 |   200/667 batches | lr 5.0000 | loss  4.838 | ppl    126.16 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 01:02:03.063] E009 |   400/667 batches | lr 5.0000 | loss  4.797 | ppl    121.13 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 01:03:05.182] E009 |   600/667 batches | lr 5.0000 | loss  4.683 | ppl    108.08 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 01:03:25.989] E009 |   667/667 batches | lr 5.0000 | loss  4.591 | ppl     98.63 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 01:03:40.485] End E009 | valid loss  5.971; ppl    391.87 | accu 0.2191 = 24582/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 01:03:55.182] End E009 |  test loss  8.349; ppl   4226.50 | accu 0.0793 = 9147/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 01:04:59.775] End E009 |  test loss 10.300; ppl  29724.66 | accu 0.0064 = 3263/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 01:04:59.775] Epoch 010/20 ==================================================
[2022-04-14 01:06:01.142] E010 |   200/667 batches | lr 2.5000 | loss  4.749 | ppl    115.43 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 01:07:02.103] E010 |   400/667 batches | lr 2.5000 | loss  4.706 | ppl    110.66 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 01:08:02.881] E010 |   600/667 batches | lr 2.5000 | loss  4.588 | ppl     98.30 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 01:08:23.167] E010 |   667/667 batches | lr 2.5000 | loss  4.502 | ppl     90.22 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 01:08:37.485] End E010 | valid loss  5.962; ppl    388.52 | accu 0.2212 = 24823/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 01:08:52.134] End E010 |  test loss  8.296; ppl   4008.95 | accu 0.0799 = 9216/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 01:09:56.685] End E010 |  test loss 10.337; ppl  30859.58 | accu 0.0052 = 2653/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 01:09:56.685] Epoch 011/20 ==================================================
[2022-04-14 01:10:57.495] E011 |   200/667 batches | lr 1.2500 | loss  4.698 | ppl    109.76 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 01:12:00.564] E011 |   400/667 batches | lr 1.2500 | loss  4.661 | ppl    105.76 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 01:13:02.509] E011 |   600/667 batches | lr 1.2500 | loss  4.541 | ppl     93.80 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 01:13:22.741] E011 |   667/667 batches | lr 1.2500 | loss  4.447 | ppl     85.37 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 01:13:37.141] End E011 | valid loss  5.958; ppl    386.73 | accu 0.2232 = 25044/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 01:13:51.592] End E011 |  test loss  8.228; ppl   3743.96 | accu 0.0808 = 9327/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 01:14:56.112] End E011 |  test loss 10.263; ppl  28661.74 | accu 0.0058 = 2947/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 01:14:56.113] Save: model.pt... 
[2022-04-14 01:14:56.778] Save: model.pt...Done. best_val_loss: 5.9577
[2022-04-14 01:14:56.779] Epoch 012/20 ==================================================
[2022-04-14 01:15:57.650] E012 |   200/667 batches | lr 1.2500 | loss  4.673 | ppl    106.97 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 01:16:58.018] E012 |   400/667 batches | lr 1.2500 | loss  4.640 | ppl    103.58 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 01:17:59.890] E012 |   600/667 batches | lr 1.2500 | loss  4.526 | ppl     92.36 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 01:18:21.241] E012 |   667/667 batches | lr 1.2500 | loss  4.442 | ppl     84.97 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 01:18:35.605] End E012 | valid loss  5.961; ppl    387.98 | accu 0.2232 = 25048/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 01:18:50.370] End E012 |  test loss  8.226; ppl   3735.46 | accu 0.0809 = 9337/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 01:19:54.716] End E012 |  test loss 10.274; ppl  28960.19 | accu 0.0061 = 3077/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 01:19:54.716] Epoch 013/20 ==================================================
[2022-04-14 01:20:54.450] E013 |   200/667 batches | lr 0.6250 | loss  4.652 | ppl    104.82 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 01:21:55.519] E013 |   400/667 batches | lr 0.6250 | loss  4.618 | ppl    101.25 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 01:22:58.018] E013 |   600/667 batches | lr 0.6250 | loss  4.501 | ppl     90.13 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 01:23:19.356] E013 |   667/667 batches | lr 0.6250 | loss  4.412 | ppl     82.41 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 01:23:33.650] End E013 | valid loss  5.958; ppl    386.72 | accu 0.2238 = 25110/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 01:23:48.194] End E013 |  test loss  8.199; ppl   3636.52 | accu 0.0810 = 9348/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 01:24:51.866] End E013 |  test loss 10.251; ppl  28318.51 | accu 0.0061 = 3069/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 01:24:51.866] Save: model.pt... 
[2022-04-14 01:24:52.608] Save: model.pt...Done. best_val_loss: 5.9577
[2022-04-14 01:24:52.609] Epoch 014/20 ==================================================
[2022-04-14 01:25:54.063] E014 |   200/667 batches | lr 0.6250 | loss  4.636 | ppl    103.13 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 01:26:55.077] E014 |   400/667 batches | lr 0.6250 | loss  4.604 | ppl     99.84 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 01:27:56.291] E014 |   600/667 batches | lr 0.6250 | loss  4.495 | ppl     89.54 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 01:28:16.825] E014 |   667/667 batches | lr 0.6250 | loss  4.408 | ppl     82.07 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 01:28:31.032] End E014 | valid loss  5.961; ppl    388.01 | accu 0.2238 = 25111/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 01:28:45.529] End E014 |  test loss  8.202; ppl   3648.75 | accu 0.0811 = 9363/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 01:29:49.178] End E014 |  test loss 10.257; ppl  28473.13 | accu 0.0064 = 3258/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 01:29:49.179] Epoch 015/20 ==================================================
[2022-04-14 01:30:50.402] E015 |   200/667 batches | lr 0.3125 | loss  4.629 | ppl    102.39 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 01:31:53.642] E015 |   400/667 batches | lr 0.3125 | loss  4.596 | ppl     99.07 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 01:32:55.662] E015 |   600/667 batches | lr 0.3125 | loss  4.480 | ppl     88.27 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 01:33:15.728] E015 |   667/667 batches | lr 0.3125 | loss  4.391 | ppl     80.68 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 01:33:29.934] End E015 | valid loss  5.958; ppl    386.77 | accu 0.2242 = 25155/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 01:33:44.628] End E015 |  test loss  8.196; ppl   3624.77 | accu 0.0809 = 9340/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 01:34:49.211] End E015 |  test loss 10.236; ppl  27898.68 | accu 0.0064 = 3268/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 01:34:49.211] Epoch 016/20 ==================================================
[2022-04-14 01:35:49.746] E016 |   200/667 batches | lr 0.1562 | loss  4.620 | ppl    101.54 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 01:36:52.230] E016 |   400/667 batches | lr 0.1562 | loss  4.588 | ppl     98.30 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 01:37:53.822] E016 |   600/667 batches | lr 0.1562 | loss  4.472 | ppl     87.53 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 01:38:13.885] E016 |   667/667 batches | lr 0.1562 | loss  4.383 | ppl     80.05 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 01:38:28.073] End E016 | valid loss  5.958; ppl    387.02 | accu 0.2247 = 25220/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 01:38:42.510] End E016 |  test loss  8.184; ppl   3581.44 | accu 0.0808 = 9328/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 01:39:46.506] End E016 |  test loss 10.211; ppl  27198.73 | accu 0.0067 = 3392/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 01:39:46.506] Epoch 017/20 ==================================================
[2022-04-14 01:40:48.478] E017 |   200/667 batches | lr 0.0781 | loss  4.618 | ppl    101.34 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 01:41:52.199] E017 |   400/667 batches | lr 0.0781 | loss  4.584 | ppl     97.87 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 01:42:52.836] E017 |   600/667 batches | lr 0.0781 | loss  4.472 | ppl     87.50 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 01:43:12.849] E017 |   667/667 batches | lr 0.0781 | loss  4.383 | ppl     80.04 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 01:43:26.970] End E017 | valid loss  5.960; ppl    387.64 | accu 0.2249 = 25234/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 01:43:41.597] End E017 |  test loss  8.196; ppl   3626.06 | accu 0.0807 = 9310/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 01:44:45.236] End E017 |  test loss 10.231; ppl  27748.51 | accu 0.0066 = 3343/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 01:44:45.236] Epoch 018/20 ==================================================
[2022-04-14 01:45:46.197] E018 |   200/667 batches | lr 0.0391 | loss  4.614 | ppl    100.94 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 01:46:47.432] E018 |   400/667 batches | lr 0.0391 | loss  4.582 | ppl     97.68 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 01:47:49.666] E018 |   600/667 batches | lr 0.0391 | loss  4.467 | ppl     87.12 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 01:48:10.410] E018 |   667/667 batches | lr 0.0391 | loss  4.377 | ppl     79.60 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 01:48:25.080] End E018 | valid loss  5.961; ppl    388.14 | accu 0.2246 = 25206/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 01:48:39.634] End E018 |  test loss  8.198; ppl   3634.38 | accu 0.0806 = 9295/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 01:49:43.741] End E018 |  test loss 10.232; ppl  27784.01 | accu 0.0066 = 3355/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 01:49:43.741] Epoch 019/20 ==================================================
[2022-04-14 01:50:44.932] E019 |   200/667 batches | lr 0.0195 | loss  4.617 | ppl    101.22 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 01:51:46.706] E019 |   400/667 batches | lr 0.0195 | loss  4.582 | ppl     97.74 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 01:52:49.488] E019 |   600/667 batches | lr 0.0195 | loss  4.466 | ppl     87.00 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 01:53:10.401] E019 |   667/667 batches | lr 0.0195 | loss  4.381 | ppl     79.89 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 01:53:24.977] End E019 | valid loss  5.961; ppl    388.05 | accu 0.2245 = 25196/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 01:53:39.336] End E019 |  test loss  8.198; ppl   3635.07 | accu 0.0806 = 9298/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 01:54:43.476] End E019 |  test loss 10.230; ppl  27730.72 | accu 0.0066 = 3352/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 01:54:43.476] Epoch 020/20 ==================================================
[2022-04-14 01:55:42.496] E020 |   200/667 batches | lr 0.0098 | loss  4.615 | ppl    100.98 frag_cnt/word_cnt=1.705=238644/140000
[2022-04-14 01:56:42.438] E020 |   400/667 batches | lr 0.0098 | loss  4.583 | ppl     97.79 frag_cnt/word_cnt=1.725=241550/140000
[2022-04-14 01:57:43.983] E020 |   600/667 batches | lr 0.0098 | loss  4.466 | ppl     87.01 frag_cnt/word_cnt=1.719=240603/140000
[2022-04-14 01:58:04.092] E020 |   667/667 batches | lr 0.0098 | loss  4.380 | ppl     79.81 frag_cnt/word_cnt=1.729=81105/46900
[2022-04-14 01:58:18.299] End E020 | valid loss  5.961; ppl    388.08 | accu 0.2246 = 25202/112220 | w_len 1.6669 = 187056/112220
[2022-04-14 01:58:33.126] End E020 |  test loss  8.197; ppl   3631.46 | accu 0.0806 = 9299/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 01:59:37.523] End E020 |  test loss 10.229; ppl  27687.88 | accu 0.0066 = 3350/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 01:59:52.209] End. test loss  8.20; ppl  3636.52 | accu 0.0810 = 9348/115380 | w_len 1.2338 = 142355/115380 ../data/sample_500k/cbt_valid.txt
[2022-04-14 02:00:56.608] End. test loss 10.25; ppl 28318.51 | accu 0.0061 = 3069/506840 | w_len 1.5287 = 774825/506840 ../data/sample_500k/adult_test.txt
[2022-04-14 02:00:56.608] =========================================================================================
[2022-04-14 02:00:56.608] valid_loss
[2022-04-14 02:00:56.608]  6.76, 6.28, 6.09, 6.04, 6.01, 6.04, 5.96, 5.96, 5.97, 5.96, 5.96, 5.96, 5.96, 5.96, 5.96, 5.96, 5.96, 5.96, 5.96, 5.96
[2022-04-14 02:00:56.608] valid_loss ppl
[2022-04-14 02:00:56.608]   863.80,  532.90,  443.51,  417.96,  407.78,  420.25,  387.12,  387.85,  391.87,  388.52,  386.73,  387.98,  386.72,  388.01,  386.77,  387.02,  387.64,  388.14,  388.05,  388.08
[2022-04-14 02:00:56.608] test_loss of ../data/sample_500k/cbt_valid.txt
[2022-04-14 02:00:56.608]  7.88, 7.87, 7.74, 7.83, 7.91, 7.69, 8.25, 8.27, 8.35, 8.30, 8.23, 8.23, 8.20, 8.20, 8.20, 8.18, 8.20, 8.20, 8.20, 8.20
[2022-04-14 02:00:56.608] test_loss of ../data/sample_500k/cbt_valid.txt ppl
[2022-04-14 02:00:56.608]  2644.82, 2628.63, 2305.70, 2520.85, 2731.38, 2184.52, 3821.12, 3921.10, 4226.50, 4008.95, 3743.96, 3735.46, 3636.52, 3648.75, 3624.77, 3581.44, 3626.06, 3634.38, 3635.07, 3631.46
[2022-04-14 02:00:56.608] test_loss of ../data/sample_500k/adult_test.txt
[2022-04-14 02:00:56.609]  9.30, 9.70, 9.77, 9.45, 9.60, 9.18,10.23,10.28,10.30,10.34,10.26,10.27,10.25,10.26,10.24,10.21,10.23,10.23,10.23,10.23
[2022-04-14 02:00:56.609] test_loss of ../data/sample_500k/adult_test.txt ppl
[2022-04-14 02:00:56.609] 10916.57,16337.05,17531.71,12650.16,14731.26, 9731.24,27759.22,29095.97,29724.66,30859.58,28661.74,28960.19,28318.51,28473.13,27898.68,27198.73,27748.51,27784.01,27730.72,27687.88
[2022-04-14 02:00:56.609] 
[2022-04-14 02:00:56.609] 
[2022-04-14 02:00:56.609] 
Log file: ./output_wsm_Subword.10000_fam_LSTM.log closed.
